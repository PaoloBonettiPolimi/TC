{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a023f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.1.5\n",
      "xarray: 0.11.3\n",
      "geopandas: 1.19.2\n",
      "tensorflow: 2.0.0\n",
      "Tensorflow/Keras: 2.2.4-tf\n",
      "pandas: 1.1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 0.24.2\n",
      "plotly: 5.6.0\n",
      "/Users/3rfanian/opt/anaconda3/envs/new_thesis/lib\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__)\n",
    "\n",
    "import xarray as xr\n",
    "print('xarray: %s' % xr.__version__)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_rows', 150)\n",
    "\n",
    "import numpy as np\n",
    "print('geopandas: %s' % np.__version__)\n",
    "\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "print('tensorflow: %s' % tf.__version__)\n",
    "\n",
    "# Tensorflow / Keras\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Dense # for creating regular densely-connected NN layer.\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "\n",
    "\n",
    "# Sklearn\n",
    "import sklearn # for model evaluation\n",
    "print('sklearn: %s' % sklearn.__version__) # print version\n",
    "from sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n",
    "from sklearn.metrics import classification_report # for model evaluation metrics\n",
    "\n",
    "# Visualization\n",
    "import plotly \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "print('plotly: %s' % plotly.__version__) # print version\n",
    "\n",
    "# Other utilities\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from numpy import * \n",
    "\n",
    "\n",
    "\n",
    "# Assign main directory to a variable\n",
    "main_dir=os.path.dirname(sys.path[0])\n",
    "print(main_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d43fea4",
   "metadata": {},
   "source": [
    "# Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c938e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('Real_Tomorrow/test_real_tom_target.csv')\n",
    "validation_set = pd.read_csv('Real_Tomorrow/validation_real_tom_target.csv')\n",
    "training_set = pd.read_csv('Real_Tomorrow/training_real_tom_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab537b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>80.761185</td>\n",
       "      <td>1.909660</td>\n",
       "      <td>-3.323872</td>\n",
       "      <td>1.687164</td>\n",
       "      <td>-1.823624</td>\n",
       "      <td>-247.54074</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>80.703650</td>\n",
       "      <td>1.165733</td>\n",
       "      <td>-2.844494</td>\n",
       "      <td>1.060593</td>\n",
       "      <td>-1.991425</td>\n",
       "      <td>-240.00592</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>78.231514</td>\n",
       "      <td>-1.311676</td>\n",
       "      <td>-2.125244</td>\n",
       "      <td>3.280617</td>\n",
       "      <td>-1.931789</td>\n",
       "      <td>-223.76889</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>79.631010</td>\n",
       "      <td>-3.777573</td>\n",
       "      <td>-1.122395</td>\n",
       "      <td>5.743889</td>\n",
       "      <td>-1.243538</td>\n",
       "      <td>-235.55556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>71.573875</td>\n",
       "      <td>-5.734505</td>\n",
       "      <td>-1.362953</td>\n",
       "      <td>6.514030</td>\n",
       "      <td>-0.954163</td>\n",
       "      <td>-254.03260</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268766</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>26.797535</td>\n",
       "      <td>25.075424</td>\n",
       "      <td>-3.653679</td>\n",
       "      <td>-1.221291</td>\n",
       "      <td>1.515594</td>\n",
       "      <td>-273.34204</td>\n",
       "      <td>296.89227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268767</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>27.766910</td>\n",
       "      <td>24.175919</td>\n",
       "      <td>-2.866638</td>\n",
       "      <td>-6.724304</td>\n",
       "      <td>0.861771</td>\n",
       "      <td>-280.37018</td>\n",
       "      <td>296.03314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268768</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>29.111805</td>\n",
       "      <td>24.655510</td>\n",
       "      <td>-2.809170</td>\n",
       "      <td>-10.138817</td>\n",
       "      <td>0.051220</td>\n",
       "      <td>-281.05167</td>\n",
       "      <td>295.36078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268769</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27.833050</td>\n",
       "      <td>25.088104</td>\n",
       "      <td>-2.730087</td>\n",
       "      <td>-11.036507</td>\n",
       "      <td>0.666927</td>\n",
       "      <td>-280.05610</td>\n",
       "      <td>295.10638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268770</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>15.843884</td>\n",
       "      <td>24.510345</td>\n",
       "      <td>-3.213837</td>\n",
       "      <td>-10.213325</td>\n",
       "      <td>-0.098499</td>\n",
       "      <td>-279.40427</td>\n",
       "      <td>294.44766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4268771 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time  latitude  longitude        vo          r      u_200  \\\n",
       "0        1980-01-01       0.0       20.0  0.000007  80.761185   1.909660   \n",
       "1        1980-01-01       0.0       22.5  0.000004  80.703650   1.165733   \n",
       "2        1980-01-01       0.0       25.0  0.000007  78.231514  -1.311676   \n",
       "3        1980-01-01       0.0       27.5  0.000010  79.631010  -3.777573   \n",
       "4        1980-01-01       0.0       30.0  0.000010  71.573875  -5.734505   \n",
       "...             ...       ...        ...       ...        ...        ...   \n",
       "4268766  2010-12-31     -30.0       80.0  0.000015  26.797535  25.075424   \n",
       "4268767  2010-12-31     -30.0       82.5 -0.000006  27.766910  24.175919   \n",
       "4268768  2010-12-31     -30.0       85.0  0.000010  29.111805  24.655510   \n",
       "4268769  2010-12-31     -30.0       87.5  0.000006  27.833050  25.088104   \n",
       "4268770  2010-12-31     -30.0       90.0  0.000007  15.843884  24.510345   \n",
       "\n",
       "            u_850      v_200     v_850        ttr        sst  lsm  \\\n",
       "0       -3.323872   1.687164 -1.823624 -247.54074    0.00000  0.0   \n",
       "1       -2.844494   1.060593 -1.991425 -240.00592    0.00000  0.0   \n",
       "2       -2.125244   3.280617 -1.931789 -223.76889    0.00000  0.0   \n",
       "3       -1.122395   5.743889 -1.243538 -235.55556    0.00000  0.0   \n",
       "4       -1.362953   6.514030 -0.954163 -254.03260    0.00000  0.0   \n",
       "...           ...        ...       ...        ...        ...  ...   \n",
       "4268766 -3.653679  -1.221291  1.515594 -273.34204  296.89227  0.0   \n",
       "4268767 -2.866638  -6.724304  0.861771 -280.37018  296.03314  0.0   \n",
       "4268768 -2.809170 -10.138817  0.051220 -281.05167  295.36078  0.0   \n",
       "4268769 -2.730087 -11.036507  0.666927 -280.05610  295.10638  0.0   \n",
       "4268770 -3.213837 -10.213325 -0.098499 -279.40427  294.44766  0.0   \n",
       "\n",
       "         Real_tom_lsm  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "4268766           0.0  \n",
       "4268767           0.0  \n",
       "4268768           0.0  \n",
       "4268769           0.0  \n",
       "4268770           0.0  \n",
       "\n",
       "[4268771 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data set\n",
    "new_training_set = training_set.drop(columns=['Unnamed: 0'])\n",
    "new_training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5878cb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>73.016390</td>\n",
       "      <td>-5.760780</td>\n",
       "      <td>-4.216808</td>\n",
       "      <td>6.860649</td>\n",
       "      <td>-4.352928</td>\n",
       "      <td>-212.59741</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>74.569660</td>\n",
       "      <td>-4.942451</td>\n",
       "      <td>-3.857407</td>\n",
       "      <td>6.459419</td>\n",
       "      <td>-3.991157</td>\n",
       "      <td>-198.23593</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>80.080090</td>\n",
       "      <td>-3.848740</td>\n",
       "      <td>-3.175144</td>\n",
       "      <td>6.303680</td>\n",
       "      <td>-3.446140</td>\n",
       "      <td>-195.83296</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>83.676704</td>\n",
       "      <td>0.330811</td>\n",
       "      <td>-2.526569</td>\n",
       "      <td>7.235268</td>\n",
       "      <td>-2.307594</td>\n",
       "      <td>-191.47444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>76.225440</td>\n",
       "      <td>3.678749</td>\n",
       "      <td>-1.027561</td>\n",
       "      <td>7.020271</td>\n",
       "      <td>-0.077572</td>\n",
       "      <td>-191.98111</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688397</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>70.662056</td>\n",
       "      <td>23.560066</td>\n",
       "      <td>1.655861</td>\n",
       "      <td>9.690376</td>\n",
       "      <td>3.621418</td>\n",
       "      <td>-271.57556</td>\n",
       "      <td>296.77530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688398</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>51.213654</td>\n",
       "      <td>22.381706</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>9.860390</td>\n",
       "      <td>-0.099480</td>\n",
       "      <td>-269.94592</td>\n",
       "      <td>296.44290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688399</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>46.678970</td>\n",
       "      <td>22.464828</td>\n",
       "      <td>0.851299</td>\n",
       "      <td>7.661758</td>\n",
       "      <td>-0.725330</td>\n",
       "      <td>-270.18890</td>\n",
       "      <td>295.73486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688400</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>59.362090</td>\n",
       "      <td>22.364807</td>\n",
       "      <td>0.543045</td>\n",
       "      <td>5.595253</td>\n",
       "      <td>-1.542034</td>\n",
       "      <td>-264.07333</td>\n",
       "      <td>295.24792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688401</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>65.915980</td>\n",
       "      <td>23.052147</td>\n",
       "      <td>0.048565</td>\n",
       "      <td>1.080147</td>\n",
       "      <td>-1.203087</td>\n",
       "      <td>-259.79480</td>\n",
       "      <td>295.79680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688402 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  latitude  longitude        vo          r      u_200  \\\n",
       "0       2011-01-01       0.0       20.0  0.000003  73.016390  -5.760780   \n",
       "1       2011-01-01       0.0       22.5  0.000003  74.569660  -4.942451   \n",
       "2       2011-01-01       0.0       25.0  0.000004  80.080090  -3.848740   \n",
       "3       2011-01-01       0.0       27.5  0.000012  83.676704   0.330811   \n",
       "4       2011-01-01       0.0       30.0  0.000011  76.225440   3.678749   \n",
       "...            ...       ...        ...       ...        ...        ...   \n",
       "688397  2015-12-31     -30.0       80.0  0.000014  70.662056  23.560066   \n",
       "688398  2015-12-31     -30.0       82.5 -0.000006  51.213654  22.381706   \n",
       "688399  2015-12-31     -30.0       85.0  0.000009  46.678970  22.464828   \n",
       "688400  2015-12-31     -30.0       87.5  0.000002  59.362090  22.364807   \n",
       "688401  2015-12-31     -30.0       90.0  0.000014  65.915980  23.052147   \n",
       "\n",
       "           u_850     v_200     v_850        ttr        sst  lsm  Real_tom_lsm  \n",
       "0      -4.216808  6.860649 -4.352928 -212.59741    0.00000  0.0           0.0  \n",
       "1      -3.857407  6.459419 -3.991157 -198.23593    0.00000  0.0           0.0  \n",
       "2      -3.175144  6.303680 -3.446140 -195.83296    0.00000  0.0           0.0  \n",
       "3      -2.526569  7.235268 -2.307594 -191.47444    0.00000  0.0           0.0  \n",
       "4      -1.027561  7.020271 -0.077572 -191.98111    0.00000  0.0           0.0  \n",
       "...          ...       ...       ...        ...        ...  ...           ...  \n",
       "688397  1.655861  9.690376  3.621418 -271.57556  296.77530  0.0           0.0  \n",
       "688398  0.321705  9.860390 -0.099480 -269.94592  296.44290  0.0           0.0  \n",
       "688399  0.851299  7.661758 -0.725330 -270.18890  295.73486  0.0           0.0  \n",
       "688400  0.543045  5.595253 -1.542034 -264.07333  295.24792  0.0           0.0  \n",
       "688401  0.048565  1.080147 -1.203087 -259.79480  295.79680  0.0           0.0  \n",
       "\n",
       "[688402 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation data set\n",
    "training_set_wt = validation_set.drop(columns=['Unnamed: 0'])\n",
    "training_set_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01638976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>73.016390</td>\n",
       "      <td>-5.760780</td>\n",
       "      <td>-4.216808</td>\n",
       "      <td>6.860649</td>\n",
       "      <td>-4.352928</td>\n",
       "      <td>-212.59741</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>74.569660</td>\n",
       "      <td>-4.942451</td>\n",
       "      <td>-3.857407</td>\n",
       "      <td>6.459419</td>\n",
       "      <td>-3.991157</td>\n",
       "      <td>-198.23593</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>80.080090</td>\n",
       "      <td>-3.848740</td>\n",
       "      <td>-3.175144</td>\n",
       "      <td>6.303680</td>\n",
       "      <td>-3.446140</td>\n",
       "      <td>-195.83296</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>83.676704</td>\n",
       "      <td>0.330811</td>\n",
       "      <td>-2.526569</td>\n",
       "      <td>7.235268</td>\n",
       "      <td>-2.307594</td>\n",
       "      <td>-191.47444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>76.225440</td>\n",
       "      <td>3.678749</td>\n",
       "      <td>-1.027561</td>\n",
       "      <td>7.020271</td>\n",
       "      <td>-0.077572</td>\n",
       "      <td>-191.98111</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688397</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>70.662056</td>\n",
       "      <td>23.560066</td>\n",
       "      <td>1.655861</td>\n",
       "      <td>9.690376</td>\n",
       "      <td>3.621418</td>\n",
       "      <td>-271.57556</td>\n",
       "      <td>296.77530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688398</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>51.213654</td>\n",
       "      <td>22.381706</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>9.860390</td>\n",
       "      <td>-0.099480</td>\n",
       "      <td>-269.94592</td>\n",
       "      <td>296.44290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688399</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>46.678970</td>\n",
       "      <td>22.464828</td>\n",
       "      <td>0.851299</td>\n",
       "      <td>7.661758</td>\n",
       "      <td>-0.725330</td>\n",
       "      <td>-270.18890</td>\n",
       "      <td>295.73486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688400</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>59.362090</td>\n",
       "      <td>22.364807</td>\n",
       "      <td>0.543045</td>\n",
       "      <td>5.595253</td>\n",
       "      <td>-1.542034</td>\n",
       "      <td>-264.07333</td>\n",
       "      <td>295.24792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688401</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>65.915980</td>\n",
       "      <td>23.052147</td>\n",
       "      <td>0.048565</td>\n",
       "      <td>1.080147</td>\n",
       "      <td>-1.203087</td>\n",
       "      <td>-259.79480</td>\n",
       "      <td>295.79680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688402 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  latitude  longitude        vo          r      u_200  \\\n",
       "0       2011-01-01       0.0       20.0  0.000003  73.016390  -5.760780   \n",
       "1       2011-01-01       0.0       22.5  0.000003  74.569660  -4.942451   \n",
       "2       2011-01-01       0.0       25.0  0.000004  80.080090  -3.848740   \n",
       "3       2011-01-01       0.0       27.5  0.000012  83.676704   0.330811   \n",
       "4       2011-01-01       0.0       30.0  0.000011  76.225440   3.678749   \n",
       "...            ...       ...        ...       ...        ...        ...   \n",
       "688397  2015-12-31     -30.0       80.0  0.000014  70.662056  23.560066   \n",
       "688398  2015-12-31     -30.0       82.5 -0.000006  51.213654  22.381706   \n",
       "688399  2015-12-31     -30.0       85.0  0.000009  46.678970  22.464828   \n",
       "688400  2015-12-31     -30.0       87.5  0.000002  59.362090  22.364807   \n",
       "688401  2015-12-31     -30.0       90.0  0.000014  65.915980  23.052147   \n",
       "\n",
       "           u_850     v_200     v_850        ttr        sst  lsm  Real_tom_lsm  \n",
       "0      -4.216808  6.860649 -4.352928 -212.59741    0.00000  0.0           0.0  \n",
       "1      -3.857407  6.459419 -3.991157 -198.23593    0.00000  0.0           0.0  \n",
       "2      -3.175144  6.303680 -3.446140 -195.83296    0.00000  0.0           0.0  \n",
       "3      -2.526569  7.235268 -2.307594 -191.47444    0.00000  0.0           0.0  \n",
       "4      -1.027561  7.020271 -0.077572 -191.98111    0.00000  0.0           0.0  \n",
       "...          ...       ...       ...        ...        ...  ...           ...  \n",
       "688397  1.655861  9.690376  3.621418 -271.57556  296.77530  0.0           0.0  \n",
       "688398  0.321705  9.860390 -0.099480 -269.94592  296.44290  0.0           0.0  \n",
       "688399  0.851299  7.661758 -0.725330 -270.18890  295.73486  0.0           0.0  \n",
       "688400  0.543045  5.595253 -1.542034 -264.07333  295.24792  0.0           0.0  \n",
       "688401  0.048565  1.080147 -1.203087 -259.79480  295.79680  0.0           0.0  \n",
       "\n",
       "[688402 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation data set\n",
    "validation_set_wt = validation_set.drop(columns=['Unnamed: 0'])\n",
    "validation_set_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0375e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>80.796135</td>\n",
       "      <td>-2.052292</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>4.996910</td>\n",
       "      <td>-1.678764</td>\n",
       "      <td>-272.04962</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>77.748420</td>\n",
       "      <td>-4.445312</td>\n",
       "      <td>0.740505</td>\n",
       "      <td>7.517281</td>\n",
       "      <td>0.792618</td>\n",
       "      <td>-250.63333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>71.178825</td>\n",
       "      <td>-3.778427</td>\n",
       "      <td>1.056324</td>\n",
       "      <td>9.333221</td>\n",
       "      <td>0.688252</td>\n",
       "      <td>-229.52519</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>73.585754</td>\n",
       "      <td>-4.695709</td>\n",
       "      <td>1.236446</td>\n",
       "      <td>9.589882</td>\n",
       "      <td>0.555519</td>\n",
       "      <td>-240.80815</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>72.382780</td>\n",
       "      <td>-4.002563</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>5.410950</td>\n",
       "      <td>-1.086350</td>\n",
       "      <td>-262.45557</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539482</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.637233</td>\n",
       "      <td>33.277840</td>\n",
       "      <td>5.379345</td>\n",
       "      <td>-0.286896</td>\n",
       "      <td>5.558327</td>\n",
       "      <td>-277.60870</td>\n",
       "      <td>294.14987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539483</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>23.660923</td>\n",
       "      <td>34.272537</td>\n",
       "      <td>6.438683</td>\n",
       "      <td>-13.026535</td>\n",
       "      <td>2.857349</td>\n",
       "      <td>-270.80573</td>\n",
       "      <td>294.23798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539484</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>46.051540</td>\n",
       "      <td>35.755882</td>\n",
       "      <td>7.248966</td>\n",
       "      <td>-18.870102</td>\n",
       "      <td>-3.349407</td>\n",
       "      <td>-249.43092</td>\n",
       "      <td>294.26890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539485</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>55.855648</td>\n",
       "      <td>34.069664</td>\n",
       "      <td>6.349327</td>\n",
       "      <td>-18.801796</td>\n",
       "      <td>-8.172478</td>\n",
       "      <td>-239.36870</td>\n",
       "      <td>294.36630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539486</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>61.602300</td>\n",
       "      <td>29.167267</td>\n",
       "      <td>4.805676</td>\n",
       "      <td>-15.093590</td>\n",
       "      <td>-9.708778</td>\n",
       "      <td>-251.60574</td>\n",
       "      <td>293.74924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539487 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  latitude  longitude        vo          r      u_200  \\\n",
       "0       2016-01-01       0.0       20.0  0.000011  80.796135  -2.052292   \n",
       "1       2016-01-01       0.0       22.5  0.000011  77.748420  -4.445312   \n",
       "2       2016-01-01       0.0       25.0 -0.000001  71.178825  -3.778427   \n",
       "3       2016-01-01       0.0       27.5 -0.000005  73.585754  -4.695709   \n",
       "4       2016-01-01       0.0       30.0 -0.000016  72.382780  -4.002563   \n",
       "...            ...       ...        ...       ...        ...        ...   \n",
       "539482  2019-12-01     -30.0       80.0  0.000006   2.637233  33.277840   \n",
       "539483  2019-12-01     -30.0       82.5 -0.000020  23.660923  34.272537   \n",
       "539484  2019-12-01     -30.0       85.0 -0.000019  46.051540  35.755882   \n",
       "539485  2019-12-01     -30.0       87.5 -0.000014  55.855648  34.069664   \n",
       "539486  2019-12-01     -30.0       90.0  0.000006  61.602300  29.167267   \n",
       "\n",
       "           u_850      v_200     v_850        ttr        sst  lsm  Real_tom_lsm  \n",
       "0       0.008678   4.996910 -1.678764 -272.04962    0.00000  0.0           0.0  \n",
       "1       0.740505   7.517281  0.792618 -250.63333    0.00000  0.0           0.0  \n",
       "2       1.056324   9.333221  0.688252 -229.52519    0.00000  0.0           0.0  \n",
       "3       1.236446   9.589882  0.555519 -240.80815    0.00000  0.0           0.0  \n",
       "4       0.734211   5.410950 -1.086350 -262.45557    0.00000  0.0           0.0  \n",
       "...          ...        ...       ...        ...        ...  ...           ...  \n",
       "539482  5.379345  -0.286896  5.558327 -277.60870  294.14987  0.0           0.0  \n",
       "539483  6.438683 -13.026535  2.857349 -270.80573  294.23798  0.0           0.0  \n",
       "539484  7.248966 -18.870102 -3.349407 -249.43092  294.26890  0.0           0.0  \n",
       "539485  6.349327 -18.801796 -8.172478 -239.36870  294.36630  0.0           0.0  \n",
       "539486  4.805676 -15.093590 -9.708778 -251.60574  293.74924  0.0           0.0  \n",
       "\n",
       "[539487 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data set\n",
    "test_set_wt = test_set.drop(columns=['Unnamed: 0'])\n",
    "test_set_wt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a2cfe",
   "metadata": {},
   "source": [
    "# extracting X,Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48baa029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******training features******\n",
      "              vo          r      u_200     u_850     v_200     v_850  \\\n",
      "0       0.000003  73.016390  -5.760780 -4.216808  6.860649 -4.352928   \n",
      "1       0.000003  74.569660  -4.942451 -3.857407  6.459419 -3.991157   \n",
      "2       0.000004  80.080090  -3.848740 -3.175144  6.303680 -3.446140   \n",
      "3       0.000012  83.676704   0.330811 -2.526569  7.235268 -2.307594   \n",
      "4       0.000011  76.225440   3.678749 -1.027561  7.020271 -0.077572   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "688397  0.000014  70.662056  23.560066  1.655861  9.690376  3.621418   \n",
      "688398 -0.000006  51.213654  22.381706  0.321705  9.860390 -0.099480   \n",
      "688399  0.000009  46.678970  22.464828  0.851299  7.661758 -0.725330   \n",
      "688400  0.000002  59.362090  22.364807  0.543045  5.595253 -1.542034   \n",
      "688401  0.000014  65.915980  23.052147  0.048565  1.080147 -1.203087   \n",
      "\n",
      "              ttr        sst  \n",
      "0      -212.59741    0.00000  \n",
      "1      -198.23593    0.00000  \n",
      "2      -195.83296    0.00000  \n",
      "3      -191.47444    0.00000  \n",
      "4      -191.98111    0.00000  \n",
      "...           ...        ...  \n",
      "688397 -271.57556  296.77530  \n",
      "688398 -269.94592  296.44290  \n",
      "688399 -270.18890  295.73486  \n",
      "688400 -264.07333  295.24792  \n",
      "688401 -259.79480  295.79680  \n",
      "\n",
      "[688402 rows x 8 columns]\n",
      "******training target******\n",
      "        Real_tom_lsm\n",
      "0                0.0\n",
      "1                0.0\n",
      "2                0.0\n",
      "3                0.0\n",
      "4                0.0\n",
      "...              ...\n",
      "688397           0.0\n",
      "688398           0.0\n",
      "688399           0.0\n",
      "688400           0.0\n",
      "688401           0.0\n",
      "\n",
      "[688402 rows x 1 columns]\n",
      "******test features******\n",
      "              vo          r      u_200     u_850      v_200     v_850  \\\n",
      "0       0.000011  80.796135  -2.052292  0.008678   4.996910 -1.678764   \n",
      "1       0.000011  77.748420  -4.445312  0.740505   7.517281  0.792618   \n",
      "2      -0.000001  71.178825  -3.778427  1.056324   9.333221  0.688252   \n",
      "3      -0.000005  73.585754  -4.695709  1.236446   9.589882  0.555519   \n",
      "4      -0.000016  72.382780  -4.002563  0.734211   5.410950 -1.086350   \n",
      "...          ...        ...        ...       ...        ...       ...   \n",
      "539482  0.000006   2.637233  33.277840  5.379345  -0.286896  5.558327   \n",
      "539483 -0.000020  23.660923  34.272537  6.438683 -13.026535  2.857349   \n",
      "539484 -0.000019  46.051540  35.755882  7.248966 -18.870102 -3.349407   \n",
      "539485 -0.000014  55.855648  34.069664  6.349327 -18.801796 -8.172478   \n",
      "539486  0.000006  61.602300  29.167267  4.805676 -15.093590 -9.708778   \n",
      "\n",
      "              ttr        sst  \n",
      "0      -272.04962    0.00000  \n",
      "1      -250.63333    0.00000  \n",
      "2      -229.52519    0.00000  \n",
      "3      -240.80815    0.00000  \n",
      "4      -262.45557    0.00000  \n",
      "...           ...        ...  \n",
      "539482 -277.60870  294.14987  \n",
      "539483 -270.80573  294.23798  \n",
      "539484 -249.43092  294.26890  \n",
      "539485 -239.36870  294.36630  \n",
      "539486 -251.60574  293.74924  \n",
      "\n",
      "[539487 rows x 8 columns]\n",
      "******test target******\n",
      "        Real_tom_lsm\n",
      "0                0.0\n",
      "1                0.0\n",
      "2                0.0\n",
      "3                0.0\n",
      "4                0.0\n",
      "...              ...\n",
      "539482           0.0\n",
      "539483           0.0\n",
      "539484           0.0\n",
      "539485           0.0\n",
      "539486           0.0\n",
      "\n",
      "[539487 rows x 1 columns]\n",
      "******validation features******\n",
      "              vo          r      u_200     u_850     v_200     v_850  \\\n",
      "0       0.000003  73.016390  -5.760780 -4.216808  6.860649 -4.352928   \n",
      "1       0.000003  74.569660  -4.942451 -3.857407  6.459419 -3.991157   \n",
      "2       0.000004  80.080090  -3.848740 -3.175144  6.303680 -3.446140   \n",
      "3       0.000012  83.676704   0.330811 -2.526569  7.235268 -2.307594   \n",
      "4       0.000011  76.225440   3.678749 -1.027561  7.020271 -0.077572   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "688397  0.000014  70.662056  23.560066  1.655861  9.690376  3.621418   \n",
      "688398 -0.000006  51.213654  22.381706  0.321705  9.860390 -0.099480   \n",
      "688399  0.000009  46.678970  22.464828  0.851299  7.661758 -0.725330   \n",
      "688400  0.000002  59.362090  22.364807  0.543045  5.595253 -1.542034   \n",
      "688401  0.000014  65.915980  23.052147  0.048565  1.080147 -1.203087   \n",
      "\n",
      "              ttr        sst  \n",
      "0      -212.59741    0.00000  \n",
      "1      -198.23593    0.00000  \n",
      "2      -195.83296    0.00000  \n",
      "3      -191.47444    0.00000  \n",
      "4      -191.98111    0.00000  \n",
      "...           ...        ...  \n",
      "688397 -271.57556  296.77530  \n",
      "688398 -269.94592  296.44290  \n",
      "688399 -270.18890  295.73486  \n",
      "688400 -264.07333  295.24792  \n",
      "688401 -259.79480  295.79680  \n",
      "\n",
      "[688402 rows x 8 columns]\n",
      "******validation target******\n",
      "        Real_tom_lsm\n",
      "0                0.0\n",
      "1                0.0\n",
      "2                0.0\n",
      "3                0.0\n",
      "4                0.0\n",
      "...              ...\n",
      "688397           0.0\n",
      "688398           0.0\n",
      "688399           0.0\n",
      "688400           0.0\n",
      "688401           0.0\n",
      "\n",
      "[688402 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "##### Step 2 - Split training data\n",
    "x_training = training_set_wt[[ 'vo', 'r', 'u_200', 'u_850', 'v_200','v_850', 'ttr','sst']]\n",
    "print (\"******training features******\")\n",
    "print (x_training)\n",
    "y_training = training_set_wt[['Real_tom_lsm']]\n",
    "print (\"******training target******\")\n",
    "print (y_training)\n",
    "\n",
    "##### Step 3 - Split test data\n",
    "x_test = test_set_wt[[ 'vo', 'r', 'u_200', 'u_850', 'v_200','v_850', 'ttr','sst']]\n",
    "print (\"******test features******\")\n",
    "print (x_test)\n",
    "y_test = test_set_wt[['Real_tom_lsm']]\n",
    "print (\"******test target******\")\n",
    "print (y_test)\n",
    "\n",
    "##### Step 4 - Split validation data\n",
    "x_validation = validation_set_wt[[ 'vo', 'r', 'u_200', 'u_850', 'v_200','v_850', 'ttr','sst']]\n",
    "print (\"******validation features******\")\n",
    "print (x_validation)\n",
    "y_validation = validation_set_wt[['Real_tom_lsm']]\n",
    "print (\"******validation target******\")\n",
    "print (y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d7f3d2",
   "metadata": {},
   "source": [
    "# Sample weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b8de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "##n_samples / (n_classes * np.bincount(y))\n",
    "sample_weights = compute_sample_weight(class_weight = 'balanced', \n",
    "                                                  y = y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec4848",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network model 8n 1l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df224ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 688402 samples, validate on 688402 samples\n",
      "Epoch 1/20\n",
      "688402/688402 [==============================] - 35s 51us/sample - loss: 0.7244 - accuracy: 0.5365 - val_loss: 0.7039 - val_accuracy: 0.0018\n",
      "Epoch 2/20\n",
      "688402/688402 [==============================] - 35s 51us/sample - loss: 0.6998 - accuracy: 0.5109 - val_loss: 0.6944 - val_accuracy: 0.0018\n",
      "Epoch 3/20\n",
      "688402/688402 [==============================] - 35s 50us/sample - loss: 0.6951 - accuracy: 0.4879 - val_loss: 0.6411 - val_accuracy: 0.9982\n",
      "Epoch 4/20\n",
      "688402/688402 [==============================] - 37s 53us/sample - loss: 0.6969 - accuracy: 0.5044 - val_loss: 0.6662 - val_accuracy: 0.9982\n",
      "Epoch 5/20\n",
      "688402/688402 [==============================] - 34s 50us/sample - loss: 0.6804 - accuracy: 0.5690 - val_loss: 0.5700 - val_accuracy: 0.8009\n",
      "Epoch 6/20\n",
      "688402/688402 [==============================] - 35s 50us/sample - loss: 0.5208 - accuracy: 0.7400 - val_loss: 0.4887 - val_accuracy: 0.9314\n",
      "Epoch 7/20\n",
      "688402/688402 [==============================] - 37s 53us/sample - loss: 0.5122 - accuracy: 0.7293 - val_loss: 0.4815 - val_accuracy: 0.8026\n",
      "Epoch 8/20\n",
      "688402/688402 [==============================] - 34s 50us/sample - loss: 0.5078 - accuracy: 0.7519 - val_loss: 0.4366 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "688402/688402 [==============================] - 34s 50us/sample - loss: 0.5041 - accuracy: 0.7678 - val_loss: 0.4853 - val_accuracy: 0.9657\n",
      "Epoch 10/20\n",
      "688402/688402 [==============================] - 34s 50us/sample - loss: 0.5402 - accuracy: 0.7500 - val_loss: 0.4761 - val_accuracy: 0.8957\n",
      "Epoch 11/20\n",
      "688402/688402 [==============================] - 35s 50us/sample - loss: 0.5024 - accuracy: 0.7407 - val_loss: 0.5352 - val_accuracy: 0.8657\n",
      "Epoch 12/20\n",
      "688402/688402 [==============================] - 35s 50us/sample - loss: 0.4939 - accuracy: 0.7382 - val_loss: 0.4017 - val_accuracy: 0.8349\n",
      "Epoch 13/20\n",
      "688402/688402 [==============================] - 35s 50us/sample - loss: 0.5134 - accuracy: 0.7559 - val_loss: 0.4302 - val_accuracy: 0.9023\n",
      "Epoch 14/20\n",
      "688402/688402 [==============================] - 35s 50us/sample - loss: 0.5288 - accuracy: 0.7643 - val_loss: 0.5320 - val_accuracy: 0.9468\n",
      "Epoch 15/20\n",
      "688402/688402 [==============================] - 34s 50us/sample - loss: 0.5115 - accuracy: 0.7567 - val_loss: 0.3050 - val_accuracy: 0.9799\n",
      "Epoch 16/20\n",
      "688402/688402 [==============================] - 34s 50us/sample - loss: 0.4989 - accuracy: 0.7424 - val_loss: 0.3674 - val_accuracy: 0.9348\n",
      "Epoch 17/20\n",
      "688402/688402 [==============================] - 41s 60us/sample - loss: 0.5066 - accuracy: 0.7439 - val_loss: 0.4207 - val_accuracy: 0.9164\n",
      "Epoch 18/20\n",
      "688402/688402 [==============================] - 34s 50us/sample - loss: 0.5030 - accuracy: 0.7563 - val_loss: 0.4887 - val_accuracy: 0.9417\n",
      "Epoch 19/20\n",
      "688402/688402 [==============================] - 36s 52us/sample - loss: 0.4978 - accuracy: 0.7571 - val_loss: 0.3786 - val_accuracy: 0.9618\n",
      "Epoch 20/20\n",
      "688402/688402 [==============================] - 42s 61us/sample - loss: 0.4992 - accuracy: 0.7579 - val_loss: 0.4159 - val_accuracy: 0.9836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fae90168d30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Step 5 - Specify the structure of a Neural Network\n",
    "model_Sample_Weighting = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(8,)),\n",
    "    tf.keras.layers.Dense(8, activation='tanh', name='Hidden-Layer1'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name='Output-Layer')\n",
    "])\n",
    "\n",
    "checkpoint_filepath = '/tmp/checkpointsamplewrighting'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "model_Sample_Weighting.compile(optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_Sample_Weighting.fit(x_training, y_training, sample_weight=sample_weights, epochs = 20 ,callbacks=[model_checkpoint_callback],   validation_data=(x_validation, y_validation))#*********more epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1eb96e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/3rfanian/opt/anaconda3/envs/new_thesis/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/model_Sample_Weighting8n_1n/assets\n"
     ]
    }
   ],
   "source": [
    "model_Sample_Weighting.save('models/model_Sample_Weighting8n_1n')\n",
    "model_Sample_Weighting.save('models/model_Sample_Weighting8n_1n.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a301c1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "-------------------- Model Summary --------------------\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "Hidden-Layer1 (Dense)        (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "Output-Layer (Dense)         (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "-------------------- Weights and Biases --------------------\n",
      "Layer:  flatten\n",
      "Layer:  Hidden-Layer1\n",
      "Layer:  dropout\n",
      "Layer:  Output-Layer\n",
      "\n",
      "---------- Evaluation on Training Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99    687163\n",
      "         1.0       0.06      0.53      0.10      1239\n",
      "\n",
      "    accuracy                           0.98    688402\n",
      "   macro avg       0.53      0.76      0.55    688402\n",
      "weighted avg       1.00      0.98      0.99    688402\n",
      "\n",
      "\n",
      "---------- Evaluation on Test Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99    538438\n",
      "         1.0       0.06      0.54      0.11      1049\n",
      "\n",
      "    accuracy                           0.98    539487\n",
      "   macro avg       0.53      0.76      0.55    539487\n",
      "weighted avg       1.00      0.98      0.99    539487\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7faf0203cdd8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Step 6 - Use model to make predictions\n",
    "modelz = model_Sample_Weighting\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = (modelz.predict(x_training)> 0.5).astype(int)\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = (modelz.predict(x_test)> 0.5).astype(int)\n",
    "#> 0.01).astype(int)\n",
    "\n",
    "\n",
    "##### Step 7 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('-------------------- Model Summary --------------------')\n",
    "modelz.summary() # print model summary\n",
    "print(\"\")\n",
    "print('-------------------- Weights and Biases --------------------')\n",
    "for layer in modelz.layers:\n",
    "    print(\"Layer: \", layer.name) # print layer name\n",
    "    \n",
    "print(\"\")\n",
    "print('---------- Evaluation on Training Data ----------')\n",
    "print(classification_report(y_training, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('---------- Evaluation on Test Data ----------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te)).plot(colorbar=False,cmap=plt.cm.Blues)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te,normalize='true')).plot(colorbar=False,cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93cd19e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7faf0228eef0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Step 6 - Use model to make predictions\n",
    "modelz = model_Sample_Weighting\n",
    "# Predict class labels on training data\n",
    "pred_prob_tr = (modelz.predict(x_training))\n",
    "# Predict class labels on a test data\n",
    "pred_prob_te = (modelz.predict(x_test))\n",
    "#> 0.01).astype(int)\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0).clf()\n",
    "\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, pred_prob_te)\n",
    "auc = round(metrics.roc_auc_score(y_test, pred_prob_te), 4)\n",
    "plt.plot(fpr,tpr,label=\"model_Sample_Weighting_8n_al, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#add legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c41b55",
   "metadata": {},
   "source": [
    "# Exporting data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04cfb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "os.makedirs('predictions/SMoote', exist_ok=True)  \n",
    "training_set_wt_predlables = training_set_wt\n",
    "training_set_wt_predlables['pred_lab_samweighting8n1l'] = pred_labels_tr\n",
    "training_set_wt_predlables['pred_prob_samweighting8n1l'] = pred_prob_tr\n",
    "training_set_wt_predlables.to_csv('predictions/SMoote/training_set_wt_predlables_samweighting_8n_1l.csv')  \n",
    "\n",
    "test_set_wt_predlables = test_set_wt\n",
    "test_set_wt_predlables['pred_lab_samweighting8n1l'] = pred_labels_te\n",
    "test_set_wt_predlables['pred_prob_samweighting8n1l'] = pred_prob_te\n",
    "test_set_wt_predlables.to_csv('predictions/SMoote/test_set_wt_predlables_samweighting_8n_1l.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a1f4940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "      <th>pred_lab_samweighting8n1l</th>\n",
       "      <th>pred_prob_samweighting8n1l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>73.016390</td>\n",
       "      <td>-5.760780</td>\n",
       "      <td>-4.216808</td>\n",
       "      <td>6.860649</td>\n",
       "      <td>-4.352928</td>\n",
       "      <td>-212.59741</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>74.569660</td>\n",
       "      <td>-4.942451</td>\n",
       "      <td>-3.857407</td>\n",
       "      <td>6.459419</td>\n",
       "      <td>-3.991157</td>\n",
       "      <td>-198.23593</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>80.080090</td>\n",
       "      <td>-3.848740</td>\n",
       "      <td>-3.175144</td>\n",
       "      <td>6.303680</td>\n",
       "      <td>-3.446140</td>\n",
       "      <td>-195.83296</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>83.676704</td>\n",
       "      <td>0.330811</td>\n",
       "      <td>-2.526569</td>\n",
       "      <td>7.235268</td>\n",
       "      <td>-2.307594</td>\n",
       "      <td>-191.47444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>76.225440</td>\n",
       "      <td>3.678749</td>\n",
       "      <td>-1.027561</td>\n",
       "      <td>7.020271</td>\n",
       "      <td>-0.077572</td>\n",
       "      <td>-191.98111</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688397</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>70.662056</td>\n",
       "      <td>23.560066</td>\n",
       "      <td>1.655861</td>\n",
       "      <td>9.690376</td>\n",
       "      <td>3.621418</td>\n",
       "      <td>-271.57556</td>\n",
       "      <td>296.77530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688398</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>51.213654</td>\n",
       "      <td>22.381706</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>9.860390</td>\n",
       "      <td>-0.099480</td>\n",
       "      <td>-269.94592</td>\n",
       "      <td>296.44290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688399</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>46.678970</td>\n",
       "      <td>22.464828</td>\n",
       "      <td>0.851299</td>\n",
       "      <td>7.661758</td>\n",
       "      <td>-0.725330</td>\n",
       "      <td>-270.18890</td>\n",
       "      <td>295.73486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688400</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>59.362090</td>\n",
       "      <td>22.364807</td>\n",
       "      <td>0.543045</td>\n",
       "      <td>5.595253</td>\n",
       "      <td>-1.542034</td>\n",
       "      <td>-264.07333</td>\n",
       "      <td>295.24792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688401</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>65.915980</td>\n",
       "      <td>23.052147</td>\n",
       "      <td>0.048565</td>\n",
       "      <td>1.080147</td>\n",
       "      <td>-1.203087</td>\n",
       "      <td>-259.79480</td>\n",
       "      <td>295.79680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688402 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  latitude  longitude        vo          r      u_200  \\\n",
       "0       2011-01-01       0.0       20.0  0.000003  73.016390  -5.760780   \n",
       "1       2011-01-01       0.0       22.5  0.000003  74.569660  -4.942451   \n",
       "2       2011-01-01       0.0       25.0  0.000004  80.080090  -3.848740   \n",
       "3       2011-01-01       0.0       27.5  0.000012  83.676704   0.330811   \n",
       "4       2011-01-01       0.0       30.0  0.000011  76.225440   3.678749   \n",
       "...            ...       ...        ...       ...        ...        ...   \n",
       "688397  2015-12-31     -30.0       80.0  0.000014  70.662056  23.560066   \n",
       "688398  2015-12-31     -30.0       82.5 -0.000006  51.213654  22.381706   \n",
       "688399  2015-12-31     -30.0       85.0  0.000009  46.678970  22.464828   \n",
       "688400  2015-12-31     -30.0       87.5  0.000002  59.362090  22.364807   \n",
       "688401  2015-12-31     -30.0       90.0  0.000014  65.915980  23.052147   \n",
       "\n",
       "           u_850     v_200     v_850        ttr        sst  lsm  Real_tom_lsm  \\\n",
       "0      -4.216808  6.860649 -4.352928 -212.59741    0.00000  0.0           0.0   \n",
       "1      -3.857407  6.459419 -3.991157 -198.23593    0.00000  0.0           0.0   \n",
       "2      -3.175144  6.303680 -3.446140 -195.83296    0.00000  0.0           0.0   \n",
       "3      -2.526569  7.235268 -2.307594 -191.47444    0.00000  0.0           0.0   \n",
       "4      -1.027561  7.020271 -0.077572 -191.98111    0.00000  0.0           0.0   \n",
       "...          ...       ...       ...        ...        ...  ...           ...   \n",
       "688397  1.655861  9.690376  3.621418 -271.57556  296.77530  0.0           0.0   \n",
       "688398  0.321705  9.860390 -0.099480 -269.94592  296.44290  0.0           0.0   \n",
       "688399  0.851299  7.661758 -0.725330 -270.18890  295.73486  0.0           0.0   \n",
       "688400  0.543045  5.595253 -1.542034 -264.07333  295.24792  0.0           0.0   \n",
       "688401  0.048565  1.080147 -1.203087 -259.79480  295.79680  0.0           0.0   \n",
       "\n",
       "        pred_lab_samweighting8n1l  pred_prob_samweighting8n1l  \n",
       "0                               0                    0.323778  \n",
       "1                               0                    0.323778  \n",
       "2                               0                    0.323778  \n",
       "3                               0                    0.323778  \n",
       "4                               0                    0.323778  \n",
       "...                           ...                         ...  \n",
       "688397                          0                    0.323778  \n",
       "688398                          0                    0.323778  \n",
       "688399                          0                    0.323778  \n",
       "688400                          0                    0.323778  \n",
       "688401                          0                    0.323778  \n",
       "\n",
       "[688402 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_wt_predlables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acd130ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "      <th>pred_lab_samweighting8n1l</th>\n",
       "      <th>pred_prob_samweighting8n1l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>80.796135</td>\n",
       "      <td>-2.052292</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>4.996910</td>\n",
       "      <td>-1.678764</td>\n",
       "      <td>-272.04962</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>77.748420</td>\n",
       "      <td>-4.445312</td>\n",
       "      <td>0.740505</td>\n",
       "      <td>7.517281</td>\n",
       "      <td>0.792618</td>\n",
       "      <td>-250.63333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>71.178825</td>\n",
       "      <td>-3.778427</td>\n",
       "      <td>1.056324</td>\n",
       "      <td>9.333221</td>\n",
       "      <td>0.688252</td>\n",
       "      <td>-229.52519</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>73.585754</td>\n",
       "      <td>-4.695709</td>\n",
       "      <td>1.236446</td>\n",
       "      <td>9.589882</td>\n",
       "      <td>0.555519</td>\n",
       "      <td>-240.80815</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>72.382780</td>\n",
       "      <td>-4.002563</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>5.410950</td>\n",
       "      <td>-1.086350</td>\n",
       "      <td>-262.45557</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539482</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.637233</td>\n",
       "      <td>33.277840</td>\n",
       "      <td>5.379345</td>\n",
       "      <td>-0.286896</td>\n",
       "      <td>5.558327</td>\n",
       "      <td>-277.60870</td>\n",
       "      <td>294.14987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539483</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>23.660923</td>\n",
       "      <td>34.272537</td>\n",
       "      <td>6.438683</td>\n",
       "      <td>-13.026535</td>\n",
       "      <td>2.857349</td>\n",
       "      <td>-270.80573</td>\n",
       "      <td>294.23798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539484</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>46.051540</td>\n",
       "      <td>35.755882</td>\n",
       "      <td>7.248966</td>\n",
       "      <td>-18.870102</td>\n",
       "      <td>-3.349407</td>\n",
       "      <td>-249.43092</td>\n",
       "      <td>294.26890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539485</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>55.855648</td>\n",
       "      <td>34.069664</td>\n",
       "      <td>6.349327</td>\n",
       "      <td>-18.801796</td>\n",
       "      <td>-8.172478</td>\n",
       "      <td>-239.36870</td>\n",
       "      <td>294.36630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539486</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>61.602300</td>\n",
       "      <td>29.167267</td>\n",
       "      <td>4.805676</td>\n",
       "      <td>-15.093590</td>\n",
       "      <td>-9.708778</td>\n",
       "      <td>-251.60574</td>\n",
       "      <td>293.74924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539487 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  latitude  longitude        vo          r      u_200  \\\n",
       "0       2016-01-01       0.0       20.0  0.000011  80.796135  -2.052292   \n",
       "1       2016-01-01       0.0       22.5  0.000011  77.748420  -4.445312   \n",
       "2       2016-01-01       0.0       25.0 -0.000001  71.178825  -3.778427   \n",
       "3       2016-01-01       0.0       27.5 -0.000005  73.585754  -4.695709   \n",
       "4       2016-01-01       0.0       30.0 -0.000016  72.382780  -4.002563   \n",
       "...            ...       ...        ...       ...        ...        ...   \n",
       "539482  2019-12-01     -30.0       80.0  0.000006   2.637233  33.277840   \n",
       "539483  2019-12-01     -30.0       82.5 -0.000020  23.660923  34.272537   \n",
       "539484  2019-12-01     -30.0       85.0 -0.000019  46.051540  35.755882   \n",
       "539485  2019-12-01     -30.0       87.5 -0.000014  55.855648  34.069664   \n",
       "539486  2019-12-01     -30.0       90.0  0.000006  61.602300  29.167267   \n",
       "\n",
       "           u_850      v_200     v_850        ttr        sst  lsm  \\\n",
       "0       0.008678   4.996910 -1.678764 -272.04962    0.00000  0.0   \n",
       "1       0.740505   7.517281  0.792618 -250.63333    0.00000  0.0   \n",
       "2       1.056324   9.333221  0.688252 -229.52519    0.00000  0.0   \n",
       "3       1.236446   9.589882  0.555519 -240.80815    0.00000  0.0   \n",
       "4       0.734211   5.410950 -1.086350 -262.45557    0.00000  0.0   \n",
       "...          ...        ...       ...        ...        ...  ...   \n",
       "539482  5.379345  -0.286896  5.558327 -277.60870  294.14987  0.0   \n",
       "539483  6.438683 -13.026535  2.857349 -270.80573  294.23798  0.0   \n",
       "539484  7.248966 -18.870102 -3.349407 -249.43092  294.26890  0.0   \n",
       "539485  6.349327 -18.801796 -8.172478 -239.36870  294.36630  0.0   \n",
       "539486  4.805676 -15.093590 -9.708778 -251.60574  293.74924  0.0   \n",
       "\n",
       "        Real_tom_lsm  pred_lab_samweighting8n1l  pred_prob_samweighting8n1l  \n",
       "0                0.0                          0                    0.323778  \n",
       "1                0.0                          0                    0.323778  \n",
       "2                0.0                          0                    0.323778  \n",
       "3                0.0                          0                    0.323778  \n",
       "4                0.0                          0                    0.323778  \n",
       "...              ...                        ...                         ...  \n",
       "539482           0.0                          0                    0.323778  \n",
       "539483           0.0                          0                    0.323778  \n",
       "539484           0.0                          0                    0.323778  \n",
       "539485           0.0                          0                    0.323778  \n",
       "539486           0.0                          0                    0.323778  \n",
       "\n",
       "[539487 rows x 15 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_wt_predlables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e972a7",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network model 512n 1l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42f91fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 688402 samples, validate on 688402 samples\n",
      "Epoch 1/20\n",
      "688402/688402 [==============================] - 123s 179us/sample - loss: 0.5377 - accuracy: 0.7909 - val_loss: 0.3094 - val_accuracy: 0.9309\n",
      "Epoch 2/20\n",
      "688402/688402 [==============================] - 119s 172us/sample - loss: 0.5345 - accuracy: 0.7941 - val_loss: 0.4427 - val_accuracy: 0.8902\n",
      "Epoch 3/20\n",
      "688402/688402 [==============================] - 120s 174us/sample - loss: 0.5549 - accuracy: 0.7918 - val_loss: 0.2704 - val_accuracy: 0.8727\n",
      "Epoch 4/20\n",
      "688402/688402 [==============================] - 118s 172us/sample - loss: 0.5496 - accuracy: 0.7896 - val_loss: 0.1443 - val_accuracy: 0.9622\n",
      "Epoch 5/20\n",
      "688402/688402 [==============================] - 128s 185us/sample - loss: 0.5505 - accuracy: 0.7853 - val_loss: 0.1181 - val_accuracy: 0.9603\n",
      "Epoch 6/20\n",
      "688402/688402 [==============================] - 122s 177us/sample - loss: 0.5621 - accuracy: 0.7896 - val_loss: 0.4609 - val_accuracy: 0.8678\n",
      "Epoch 7/20\n",
      "688402/688402 [==============================] - 120s 174us/sample - loss: 0.5381 - accuracy: 0.7947 - val_loss: 0.1222 - val_accuracy: 0.9789\n",
      "Epoch 8/20\n",
      "688402/688402 [==============================] - 124s 180us/sample - loss: 0.5431 - accuracy: 0.7855 - val_loss: 0.1097 - val_accuracy: 0.9759\n",
      "Epoch 9/20\n",
      "688402/688402 [==============================] - 120s 175us/sample - loss: 0.5622 - accuracy: 0.7867 - val_loss: 0.5701 - val_accuracy: 0.7580\n",
      "Epoch 10/20\n",
      "688402/688402 [==============================] - 121s 176us/sample - loss: 0.5537 - accuracy: 0.7823 - val_loss: 0.2970 - val_accuracy: 0.8622\n",
      "Epoch 11/20\n",
      "688402/688402 [==============================] - 119s 173us/sample - loss: 0.5526 - accuracy: 0.7896 - val_loss: 0.8316 - val_accuracy: 0.6025\n",
      "Epoch 12/20\n",
      "688402/688402 [==============================] - 122s 177us/sample - loss: 0.5260 - accuracy: 0.8016 - val_loss: 0.0959 - val_accuracy: 0.9731\n",
      "Epoch 13/20\n",
      "688402/688402 [==============================] - 120s 175us/sample - loss: 0.5263 - accuracy: 0.7980 - val_loss: 0.1772 - val_accuracy: 0.9170\n",
      "Epoch 14/20\n",
      "688402/688402 [==============================] - 121s 176us/sample - loss: 0.5172 - accuracy: 0.8059 - val_loss: 0.8104 - val_accuracy: 0.3580\n",
      "Epoch 15/20\n",
      "688402/688402 [==============================] - 138s 201us/sample - loss: 0.5319 - accuracy: 0.8057 - val_loss: 0.8547 - val_accuracy: 0.2818\n",
      "Epoch 16/20\n",
      "688402/688402 [==============================] - 184s 268us/sample - loss: 0.5269 - accuracy: 0.8055 - val_loss: 0.1377 - val_accuracy: 0.9469\n",
      "Epoch 17/20\n",
      "688402/688402 [==============================] - 227s 329us/sample - loss: 0.5448 - accuracy: 0.7925 - val_loss: 0.1479 - val_accuracy: 0.9573\n",
      "Epoch 18/20\n",
      "688402/688402 [==============================] - 143s 208us/sample - loss: 0.5539 - accuracy: 0.7890 - val_loss: 0.6436 - val_accuracy: 0.8112\n",
      "Epoch 19/20\n",
      "688402/688402 [==============================] - 159s 231us/sample - loss: 0.5198 - accuracy: 0.8040 - val_loss: 0.1380 - val_accuracy: 0.9795\n",
      "Epoch 20/20\n",
      "688402/688402 [==============================] - 138s 200us/sample - loss: 0.5362 - accuracy: 0.8044 - val_loss: 0.6917 - val_accuracy: 0.8412\n"
     ]
    }
   ],
   "source": [
    "##### Step 5 - Specify the structure of a Neural Network\n",
    "model_Sample_Weighting512n = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(8,)),\n",
    "    tf.keras.layers.Dense(512, activation='tanh', name='Hidden-Layer'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name='Output-Layer')\n",
    "])\n",
    "model_Sample_Weighting512n.compile(optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "#checkPoint\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "h_baselineFFN = model_Sample_Weighting512n.fit(x_training, y_training, sample_weight=sample_weights, epochs = 20 ,callbacks=[model_checkpoint_callback],   validation_data=(x_validation, y_validation))#*********more epochs = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8f670a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_Sample_Weighting512n_1n/assets\n"
     ]
    }
   ],
   "source": [
    "model_Sample_Weighting512n.save('models/model_Sample_Weighting512n_1n')\n",
    "model_Sample_Weighting512n.save('models/model_Sample_Weighting512n_1n.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e641372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "-------------------- Model Summary --------------------\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "Hidden-Layer (Dense)         (None, 512)               4608      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Output-Layer (Dense)         (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "-------------------- Weights and Biases --------------------\n",
      "Layer:  flatten_1\n",
      "Layer:  Hidden-Layer\n",
      "Layer:  dropout_1\n",
      "Layer:  Output-Layer\n",
      "\n",
      "---------- Evaluation on Training Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.84      0.91    687163\n",
      "         1.0       0.01      0.89      0.02      1239\n",
      "\n",
      "    accuracy                           0.84    688402\n",
      "   macro avg       0.50      0.86      0.47    688402\n",
      "weighted avg       1.00      0.84      0.91    688402\n",
      "\n",
      "\n",
      "---------- Evaluation on Test Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.84      0.91    538438\n",
      "         1.0       0.01      0.94      0.02      1049\n",
      "\n",
      "    accuracy                           0.84    539487\n",
      "   macro avg       0.51      0.89      0.47    539487\n",
      "weighted avg       1.00      0.84      0.91    539487\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7faef76bf438>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Step 6 - Use model to make predictions\n",
    "modelz = model_Sample_Weighting512n\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = (modelz.predict(x_training)> 0.5).astype(int)\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = (modelz.predict(x_test)> 0.5).astype(int)\n",
    "#> 0.01).astype(int)\n",
    "\n",
    "\n",
    "##### Step 7 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('-------------------- Model Summary --------------------')\n",
    "modelz.summary() # print model summary\n",
    "print(\"\")\n",
    "print('-------------------- Weights and Biases --------------------')\n",
    "for layer in modelz.layers:\n",
    "    print(\"Layer: \", layer.name) # print layer name\n",
    "    \n",
    "print(\"\")\n",
    "print('---------- Evaluation on Training Data ----------')\n",
    "print(classification_report(y_training, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('---------- Evaluation on Test Data ----------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te)).plot(colorbar=False,cmap=plt.cm.Blues)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te,normalize='true')).plot(colorbar=False,cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "720cd1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7faef7a58b00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Step 6 - Use model to make predictions\n",
    "modelz = model_Sample_Weighting512n\n",
    "# Predict class labels on training data\n",
    "pred_prob_tr = (modelz.predict(x_training))\n",
    "# Predict class labels on a test data\n",
    "pred_prob_te = (modelz.predict(x_test))\n",
    "#> 0.01).astype(int)\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0).clf()\n",
    "\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, pred_prob_te)\n",
    "auc = round(metrics.roc_auc_score(y_test, pred_prob_te), 4)\n",
    "plt.plot(fpr,tpr,label=\"samweight_512n_1l, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#add legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "627c0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('predictions/samweigh', exist_ok=True)  \n",
    "\n",
    "training_set_wt_predlables = training_set_wt\n",
    "training_set_wt_predlables['pred_lab_samweigh512n1l'] = pred_labels_tr\n",
    "training_set_wt_predlables['pred_prob_samweigh512n1l'] = pred_prob_tr\n",
    "training_set_wt_predlables.to_csv('predictions/samweigh/training_set_wt_predlables_samwe_512n_1l.csv')  \n",
    "\n",
    "test_set_wt_predlables = test_set_wt\n",
    "test_set_wt_predlables['pred_lab_samweigh512n1l'] = pred_labels_te\n",
    "test_set_wt_predlables['pred_prob_samweigh512n1l'] = pred_prob_te\n",
    "test_set_wt_predlables.to_csv('predictions/samweigh/test_set_wt_predlables_samwe_512n_1l.csv')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0765f6",
   "metadata": {},
   "source": [
    "# # Feed Forward Neural Network model 256n, 4l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce847b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 688402 samples, validate on 688402 samples\n",
      "Epoch 1/20\n",
      "688402/688402 [==============================] - 221s 321us/sample - loss: 0.6681 - accuracy: 0.6629 - val_loss: 0.4319 - val_accuracy: 0.9579\n",
      "Epoch 2/20\n",
      "688402/688402 [==============================] - 227s 329us/sample - loss: 0.5724 - accuracy: 0.7206 - val_loss: 0.3068 - val_accuracy: 0.9880\n",
      "Epoch 3/20\n",
      "688402/688402 [==============================] - 232s 337us/sample - loss: 0.5212 - accuracy: 0.8005 - val_loss: 0.2348 - val_accuracy: 0.9139\n",
      "Epoch 4/20\n",
      "688402/688402 [==============================] - 206s 299us/sample - loss: 0.5269 - accuracy: 0.8029 - val_loss: 0.2566 - val_accuracy: 0.9889\n",
      "Epoch 5/20\n",
      "688402/688402 [==============================] - 216s 314us/sample - loss: 0.5322 - accuracy: 0.7902 - val_loss: 0.2568 - val_accuracy: 0.8410\n",
      "Epoch 6/20\n",
      "688402/688402 [==============================] - 214s 311us/sample - loss: 0.5124 - accuracy: 0.8097 - val_loss: 0.2519 - val_accuracy: 0.9910\n",
      "Epoch 7/20\n",
      "688402/688402 [==============================] - 262s 380us/sample - loss: 0.5134 - accuracy: 0.8039 - val_loss: 0.2061 - val_accuracy: 0.9018\n",
      "Epoch 8/20\n",
      "688402/688402 [==============================] - 222s 323us/sample - loss: 0.5371 - accuracy: 0.7912 - val_loss: 0.8719 - val_accuracy: 0.7250\n",
      "Epoch 9/20\n",
      "688402/688402 [==============================] - 215s 313us/sample - loss: 0.5410 - accuracy: 0.7834 - val_loss: 0.6554 - val_accuracy: 0.2853\n",
      "Epoch 10/20\n",
      "688402/688402 [==============================] - 212s 307us/sample - loss: 0.5751 - accuracy: 0.7262 - val_loss: 0.0751 - val_accuracy: 0.9781\n",
      "Epoch 11/20\n",
      "688402/688402 [==============================] - 211s 307us/sample - loss: 0.5208 - accuracy: 0.8064 - val_loss: 0.9109 - val_accuracy: 0.2836\n",
      "Epoch 12/20\n",
      "688402/688402 [==============================] - 233s 338us/sample - loss: 0.5383 - accuracy: 0.7616 - val_loss: 0.2604 - val_accuracy: 0.9762\n",
      "Epoch 13/20\n",
      "688402/688402 [==============================] - 352s 512us/sample - loss: 0.5124 - accuracy: 0.8020 - val_loss: 0.3809 - val_accuracy: 0.8552\n",
      "Epoch 14/20\n",
      "688402/688402 [==============================] - 444s 645us/sample - loss: 0.5402 - accuracy: 0.7741 - val_loss: 0.2165 - val_accuracy: 0.9280\n",
      "Epoch 15/20\n",
      "688402/688402 [==============================] - 198s 287us/sample - loss: 0.5337 - accuracy: 0.7802 - val_loss: 0.6926 - val_accuracy: 0.2849\n",
      "Epoch 16/20\n",
      "688402/688402 [==============================] - 198s 288us/sample - loss: 0.5352 - accuracy: 0.7667 - val_loss: 0.3926 - val_accuracy: 0.9811\n",
      "Epoch 17/20\n",
      "688402/688402 [==============================] - 197s 286us/sample - loss: 0.5216 - accuracy: 0.7956 - val_loss: 0.3191 - val_accuracy: 0.9981\n",
      "Epoch 18/20\n",
      "688402/688402 [==============================] - 319s 463us/sample - loss: 0.5576 - accuracy: 0.7519 - val_loss: 0.5610 - val_accuracy: 0.9646\n",
      "Epoch 19/20\n",
      "688402/688402 [==============================] - 471s 684us/sample - loss: 0.5753 - accuracy: 0.7196 - val_loss: 0.3640 - val_accuracy: 0.9576\n",
      "Epoch 20/20\n",
      "688402/688402 [==============================] - 494s 717us/sample - loss: 0.5379 - accuracy: 0.7832 - val_loss: 0.2913 - val_accuracy: 0.9390\n"
     ]
    }
   ],
   "source": [
    "##### Step 5 - Specify the structure of a Neural Network\n",
    "model_FFNN_samweight_256n_4l = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(8,)),\n",
    "    tf.keras.layers.Dense(256, activation='tanh', name='Hidden-Layer1'),\n",
    "    tf.keras.layers.Dense(256, activation='tanh', name='Hidden-Layer2'),\n",
    "    tf.keras.layers.Dense(256, activation='tanh', name='Hidden-Layer3'),\n",
    "    tf.keras.layers.Dense(256, activation='tanh', name='Hidden-Layer4'),\n",
    "\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name='Output-Layer')\n",
    "])\n",
    "model_FFNN_samweight_256n_4l.compile(optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "#checkPoint\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "h_baselineFFN = model_FFNN_samweight_256n_4l.fit(x_training, y_training, sample_weight=sample_weights, epochs = 20 ,callbacks=[model_checkpoint_callback],   validation_data=(x_validation, y_validation))#*********more epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7759b27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_Smoote_baseline_256n_4l/assets\n"
     ]
    }
   ],
   "source": [
    "model_FFNN_samweight_256n_4l.save('models/model_samweight_256n_4l')\n",
    "model_FFNN_samweight_256n_4l.save('models/model_samweight_256n_4l.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e2b3351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "-------------------- Model Summary --------------------\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "Hidden-Layer1 (Dense)        (None, 256)               2304      \n",
      "_________________________________________________________________\n",
      "Hidden-Layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "Hidden-Layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "Hidden-Layer4 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Output-Layer (Dense)         (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 199,937\n",
      "Trainable params: 199,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "-------------------- Weights and Biases --------------------\n",
      "Layer:  flatten_2\n",
      "Layer:  Hidden-Layer1\n",
      "Layer:  Hidden-Layer2\n",
      "Layer:  Hidden-Layer3\n",
      "Layer:  Hidden-Layer4\n",
      "Layer:  dropout_2\n",
      "Layer:  Output-Layer\n",
      "\n",
      "---------- Evaluation on Training Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97    687163\n",
      "         1.0       0.02      0.74      0.04      1239\n",
      "\n",
      "    accuracy                           0.94    688402\n",
      "   macro avg       0.51      0.84      0.51    688402\n",
      "weighted avg       1.00      0.94      0.97    688402\n",
      "\n",
      "\n",
      "---------- Evaluation on Test Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97    538438\n",
      "         1.0       0.02      0.78      0.05      1049\n",
      "\n",
      "    accuracy                           0.94    539487\n",
      "   macro avg       0.51      0.86      0.51    539487\n",
      "weighted avg       1.00      0.94      0.97    539487\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7faf037353c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAEGCAYAAABhHPB4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVEklEQVR4nO3dd3gVZfrG8e+TxEBCAiEQSjAUqQaRugJioSwKCip2hJVdC1Z0YV3LroLlh6yua8WGyiqLgnihqxSxIIgKUqUIiAIivYTe4Rze3x/nJQaFcHCZcyDcn+vKxfR5JiF33nln5ow55xARSYh3ASJybFAYiAigMBART2EgIoDCQES8pHgXUJAlpThLTo93GXIETq+TE+8S5Ags++kn1q/Ps4PNO7bCIDmdYrWvjHcZcgQ++fypeJcgR6Dtuc0OOU+nCSICKAxExFMYiAigMBART2EgIoDCQEQ8hYGIAAoDEfEUBiICKAxExFMYiAigMBART2EgIoDCQEQ8hYGIAAoDEfEUBiICKAxExFMYiAigMBART2EgIoDCQEQ8hYGIAAoDEfEUBiICKAxExFMYiAigMBART2EgIoDCQEQ8hYGIAAoDEfEUBiICKAxExFMYiAigMBART2EgIoDCQEQ8hYGIAAoDEfEUBiICKAxExFMYiAigMBART2EgIoDCQEQ8hYGIAAoDEfEUBiICQFK8CzjWzXr/Ibbt2E143z5CoX207vY4GSVTGfjodVSumMnSVRv4032vsXnrTnIqZjJ52P0sXLoWgGlzltDrH0NJSy3G6Fd65m8zu1wGwz6cyt+eHE5OhdI817srZTPS2LhlBzf1foOVazdxVuOaPNrrsvx1alYpz/V//zejP58d8+/B8WjX7r1c0aM/e/aGCIXDXNCyPn+5rj19X/iATyfO5aSkRKpUKssT93amVHoKAPMXreS+J4axdfsuEiyBEQN6UrzYSfnbvO7eV1m6aj2fvnEPAJNnLuKh595j/uJV9O/zBy5s2SAeh3rUBBoGZtYOeAZIBF51zv0jyP0FpePNz7Bh8/b88Z7d2jJh6gKefuMT/tytLT27nceD/d8HYMmKPM7pcuBhbtux+4Bp4wbdzchxMwF4+M5ODB01haGjJnN2k1r0vu0ibu4ziC+n/5C/TkbJVGa824dxX88P+EiLjmLJSQx9+lZKpBZjbyjMZbc9S6ump3J2k1rc0/1CkpISefTFETw/+FP+dktHQqEwdz4ymKfv70JujUps3Lydk5IS87f34eezKZFa7IB9ZJcvzb/+dg0vDx0X68MLRGCnCWaWCDwPtAdygc5mlhvU/mKp/bmnM2TkZACGjJzMBS1Pj3rdU3KyyMpMZ+I3iwCofUpFJkxdAMAX076n/Tn1frXOxW0a8umkeezcvfcoVH9iMLP8X95QKEwoFMbMOOeMOiT5X/JGdauwet0mACZMXcCp1bPJrVEJgNKlSpCYGPn12L5jN68MG0+Pa9sesI+cipmcWj2bBLMYHVWwguwzOANY6Jxb7JzbAwwFLg5wf4FwzvFu/9sZN+huunVqAUC5zHTWrN8CwJr1W8gqnZ6/fOXsMnw++B5GvnwnzRtU/9X2Lju/Me9+MiN/fO73K+jYugEAHVrVp2RaCqVLlThgnUvbNmL4R9OP9qEVeeHwPtpd908aXvwAZzWpTcPcKgfMf3v0ZFo2OxWAxcvWgUHXv7zEBdc/wYtvjc1f7onXRtP9qpakFEuOaf2xFuRpQiVgWYHx5UDTXy5kZt2B7gCclBZgOb9NuxueYnXeZsqWTuO9/rfzw5LVh1x2Td4W6nXszcbN26lfJ4c3n+hO86v6snX7rvxlLm3bmJv7DMoff+CZ93j87iu4pkNTJn6zkBVrNhIOhfPnly9Tktwa2YydNC+YAyzCEhMTGDPwr2zeupPu9w9kweJV1D6lIgDPDfqEpMREOrVtDESCY9rsHxkxoCcpxZPp3PMF6tXOoXTJEixZkUefHp1YtmpDPA8ncEGGwcHaTu5XE5wbAAwASEgt96v58bY6bzMAeRu3MXL8bBrVrcraDVspX6Yka9ZvoXyZkqzbuBWAPXtD7NkcAmDWd8v4cXke1SuXY+b8pQCcVrMSSYmJzPpu2QHbv/buVwEokZJMx1YN2FIgPC5p24iR42cTCu+LyfEWRaXSU2jWoDrjJ39H7VMq8s6HUxg7aS5DnroV8038iuVK0bRBdTIzIn+QWjXL5dvvl1MipRhzFiznzCsfJhTex/qN27jyjv4Me/b2eB5SIII8TVgO5BQYPxlYGeD+jrrU4smk+fPO1OLJtG5Wh/mLVjJmwhw6d4g0cjp3aMqHvoe/TEYaCQmR/1xVKpXhlJwslqzIy9/eZec3ZvjH0w7YR2apEvn/IXv+8XzeHPH1AfMvO68xwz86cB05vPWbtrF5604Adu3ew5fTv6d6lXKMnzyfF9/6jNf63UBK8Z+b/eecUYfvFq1k5649hEJhvp65kJpVy/OHS1ow7b2HmDisN8P730G1nKwiGQQQbMtgKlDTzKoBK4CrgWsC3N9Rl1UmncGP3whAYlIiw8dMY+yk+cyYt5R/97uOrhc1Z/majfzx3tcAOLNhDe67+ULCoTDhfY6//GMom7bsyN/eJb9vxJV3vnjAPs5qXJPet12EczDxm4X89fFh+fNyKmZSqXxpvpqxMAZHW7SsXb+FXo++RTi8j33O0aFVA35/Zl3O7tyXPXtCdOkV+Tk0zK1Cv7uuJCM9lRuuakmH7k9iZrRqdiptmtctdB+z5i/lxvsHsnnrTj6dOJcnB45h7KB7Y3F4gTDngmuZm9kFwNNELi0OdM71LWz5hNRyrljtKwOrR46+pROeincJcgTantuMmTOmH/TyR6D3GTjnRgOjg9yHiBwduh1ZRACFgYh4CgMRARQGIuIpDEQEUBiIiKcwEBFAYSAinsJARACFgYh4CgMRARQGIuIpDEQEUBiIiKcwEBFAYSAinsJARACFgYh4CgMRARQGIuIpDEQEUBiIiKcwEBFAYSAinsJARACFgYh4h3y9mpk9x0Feob6fc+6OQCoSkbgo7F2Leg+4yAnkkGHgnHuj4LiZlXDObQ++JBGJh8P2GZhZczObB8z34/XN7IXAKxORmIqmA/Fp4HxgPYBzbhZwToA1iUgcRHU1wTm37BeTwgHUIiJxVFgH4n7LzOxMwJlZMnAH/pRBRIqOaFoGNwO3AZWAFUADPy4iRchhWwbOuTygSwxqEZE4iuZqwilmNsLM1pnZWjN738xOiUVxIhI70ZwmvAUMAyoC2cA7wJAgixKR2IsmDMw59x/nXMh/DaaQ25RF5PhU2LMJmX5wnJndCwwlEgJXAaNiUJuIxFBhHYjTifzymx+/qcA8BzwSVFEiEnuFPZtQLZaFiEh8RXPTEWZ2GpALFN8/zTk3KKiiRCT2DhsGZtYHaEkkDEYD7YEvAYWBSBESzdWEy4E2wGrn3J+A+kCxQKsSkZiLJgx2Ouf2ASEzKwmsBXTTkUgRE02fwTQzywBeIXKFYRswJciiRCT2onk24VY/+JKZjQFKOudmB1uWiMRaYTcdNSpsnnNuRjAliUg8FNYy+Fch8xzQ+ijXQsNTK/PV5P5He7Mi4iWaHXJeYTcdtQqkGhE5JuklKiICKAxExFMYiAgQ3ScdmZl1NbPefryymZ0RfGkiEkvRtAxeAJoDnf34VuD5wCoSkbiI5g7Eps65Rmb2DYBzbqP/yHQRKUKiaRnsNbNE/EedmVkWsC/QqkQk5qIJg2eB94ByZtaXyOPLjwZalYjEXDTPJrxpZtOJPMZswCXOOb1RSaSIiebDTSoDO4ARBac555YGWZiIxFY0HYij+PmDUYsD1YAFQN0A6xKRGIvmNKFewXH/NONNh1hcRI5TR3wHon90+XcB1CIicRRNn0GvAqMJQCNgXWAViUhcRNNnkF5gOESkD2F4MOWISLwUGgb+ZqM059xfY1SPiMTJIfsMzCzJORcmclogIkVcYS2DKUSCYKaZfUDkVezb9890zr0bcG0iEkPR9BlkAuuJfObh/vsNHKAwEClCCguDcv5Kwrcc+DZm/LiIFCGFhUEikMaBIbCfwkCkiCksDFY55x6OWSUiEleF3YF46A9YF5Eip7AwaBOzKkQk7g4ZBs65DbEsRETiSx+VLiKAwkBEPIWBiAAKAxHxFAYiAigMRMRTGIgIoDAQEU9hICKAwkBEPIWBiAAKAxHxFAYiAigMRMRTGIgIoDAQEU9hICKAwkBEPIWBiAAKAxHxFAYiAigMRMRTGIgIEN1bmKUQy1dv5JYHB7F2/RYSzOjWqQU3d25F3xdHMnrCbBLMyMpM5/k+XamYlQHAtz+soFe/IWzdtgtLMD57426KFzspvgdygnnhrc/4z38nghm5NbJ5vndXxnwxh8cGjGbBkjWMff0uGuZWAWD63CX8ue8QIPKS0XtvvIAOrerHsfpgmHPBvEPVzAYCHYC1zrnTolmnceMm7qvJ0wKpJyir8zazJm8L9evksHX7Llpd+xiD/9md7HIZlExLAeDloeP57sdVPHVfZ0KhMOf+4TFeeuha6tU6mQ2btlEqPZXERDXSYmXl2k20v/Epvn7776QUT+ZP971G2zPr0vi0qiSY0bPfEB65s1N+GOzYtYfkpESSkhJZnbeZs6/px/zRfUlKSozzkRy5Fk2bMH36tIO+OjHI/4GvA+0C3P4xoULZUtSvkwNAeoni1KpagVXrNuUHAcD2nbsxi3z/P5v8HXVrVKJerZMByMxIUxDEQSgUZtfuvYRCYXbs2kOFrFLUrlaBmlXL/2rZ1OLJ+b/4u3fvzf9ZFjWBnSY45yaYWdWgtn8sWrpyPbMXLKdx3aoAPPLCBwwdNYWSaSmMeOkOABb9tBYzuKxHf/I2buPS8xpz57Vt41j1iSe7XAY9urahXscHKF4smVZN69C62amFrjPt2yX0eHgwy1Zv4KWHuh2XrYLDifufJDPrbmbTzGzaurx18S7nN9u2YzfX3vMq/Xpdlt8qeODWi5g76v+4ol0TXhk2AYBQOMzXsxYz4JE/8uGrvRg1fhafT1kQz9JPOJu27GD0hDnMfP8h5n/Ylx279vD26CmFrtPktKpMGnY/Y9+4m6de/5hdu/fGqNrYiXsYOOcGOOeaOOeaZJXNinc5v8neUJhu97zCFe2a0LF1g1/Nv7zd7/jgs5kAZJfPoEXDGpTJSCO1eDJtz6zLrAXLYlvwCW78lO+okl2GsqXTOSkpkY6t6jNl9o9RrVu7WgVSU5KZv2hlwFXGXtzD4HjnnKPHI29Sq2oFbuvy81vsFy1dmz88ZsJsavlz0TbNcpm7cAU7du0hFArz1YyF1K5WIeZ1n8hOrpDJtDk/smPXHpxzfD51AbWr/bqvYL+fVuQRCoUBWLpqAwt/WkPl7DKxKjdmdGnxf/T1rMW8PXoKuTWyOfuafgA8cNtFDH5/Ij/8tJaEBCOnQiZP3nc1ABklU7n1mta0ufZxMKNti7qcf1ZUF1vkKGlyWlUuatOQll0fIzExgdNrn0y3Ti0YOW4W9zzxDnkbt3FVz5eoV6sSw5+7nUmzFvPM6x+TlJRIQoLxxD1XUSYjLd6HcdQFeWlxCNASKAusAfo4514rbJ3j8dKiyPGksEuLQV5N6BzUtkXk6FOfgYgACgMR8RQGIgIoDETEUxiICKAwEBFPYSAigMJARDyFgYgACgMR8RQGIgIoDETEUxiICKAwEBFPYSAigMJARDyFgYgACgMR8RQGIgIoDETEUxiICKAwEBFPYSAigMJARDyFgYgACgMR8RQGIgIoDETEUxiICKAwEBFPYSAigMJARDyFgYgACgMR8RQGIgIoDETEUxiICKAwEBFPYSAigMJARDyFgYgACgMR8RQGIgIoDETEUxiICKAwEBFPYSAigMJARDyFgYgAYM65eNeQz8zWAT/Fu44AlAXy4l2EHJGi+jOr4pzLOtiMYyoMiiozm+acaxLvOiR6J+LPTKcJIgIoDETEUxjExoB4FyBH7IT7manPQEQAtQxExFMYiAigMAiUmbUzswVmttDM7o13PXJ4ZjbQzNaa2bfxriXWFAYBMbNE4HmgPZALdDaz3PhWJVF4HWgX7yLiQWEQnDOAhc65xc65PcBQ4OI41ySH4ZybAGyIdx3xoDAITiVgWYHx5X6ayDFJYRAcO8g0XceVY5bCIDjLgZwC4ycDK+NUi8hhKQyCMxWoaWbVzCwZuBr4IM41iRySwiAgzrkQcDvwETAfGOacmxvfquRwzGwIMAmobWbLzez6eNcUK7odWUQAtQxExFMYiAigMBART2EgIoDCQEQ8hcFxxMzCZjbTzL41s3fMLPV/2NbrZna5H361sIeozKylmZ35G/axxMzKRjv9F8tsO8J9PWhmdx1pjfIzhcHxZadzroFz7jRgD3BzwZn+Sckj5py7wTk3r5BFWgJHHAZyfFEYHL++AGr4v9rjzOwtYI6ZJZrZP81sqpnNNrObACyiv5nNM7NRQLn9GzKz8WbWxA+3M7MZZjbLzMaaWVUiodPTt0rONrMsMxvu9zHVzFr4dcuY2cdm9o2ZvczBn884gJn918ymm9lcM+v+i3n/8rWMNbMsP626mY3x63xhZnWOyndTwDmnr+PkC9jm/00C3gduIfJXeztQzc/rDtzvh4sB04BqwKXAJ0AikA1sAi73y40HmgBZRJ603L+tTP/vg8BdBep4CzjLD1cG5vvhZ4HefvhCIg9mlT3IcSzZP73APlKAb4EyftwBXfxwb6C/Hx4L1PTDTYHPDlajvo78K+m3RYjESYqZzfTDXwCvEWm+T3HO/einnwecvr8/ACgF1ATOAYY458LASjP77CDbbwZM2L8t59yhnuv/PZBrlv+Hv6SZpft9XOrXHWVmG6M4pjvMrJMfzvG1rgf2AW/76YOBd80szR/vOwX2XSyKfUgUFAbHl53OuQYFJ/hfiu0FJwE9nHMf/WK5Czj8I9QWxTIQOb1s7pzbeZBaor6/3cxaEgmW5s65HWY2Hih+iMWd3++mX34P5OhQn0HR8xFwi5mdBGBmtcysBDABuNr3KVQEWh1k3UnAuWZWza+b6advBdILLPcxkYew8Ms18IMTgC5+Wnug9GFqLQVs9EFQh0jLZL8EYH/r5hrgS+fcFuBHM7vC78PMrP5h9iFRUhgUPa8C84AZ/kM9XybSAnwP+AGYA7wIfP7LFZ1z64j0ObxrZrP4uZk+Aui0vwMRuANo4jso5/HzVY2HgHPMbAaR05Wlh6l1DJBkZrOBR4CvC8zbDtQ1s+lAa+BhP70LcL2vby76KLmjRk8tigigloGIeAoDEQEUBiLiKQxEBFAYiIinMBARQGEgIt7/A8bO8LKTwpSfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Step 6 - Use model to make predictions\n",
    "modelz = model_FFNN_samweight_256n_4l\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = (modelz.predict(x_training)> 0.5).astype(int)\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = (modelz.predict(x_test)> 0.5).astype(int)\n",
    "#> 0.01).astype(int)\n",
    "\n",
    "\n",
    "##### Step 7 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('-------------------- Model Summary --------------------')\n",
    "modelz.summary() # print model summary\n",
    "print(\"\")\n",
    "print('-------------------- Weights and Biases --------------------')\n",
    "for layer in modelz.layers:\n",
    "    print(\"Layer: \", layer.name) # print layer name\n",
    "    \n",
    "print(\"\")\n",
    "print('---------- Evaluation on Training Data ----------')\n",
    "print(classification_report(y_training, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('---------- Evaluation on Test Data ----------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te)).plot(colorbar=False,cmap=plt.cm.Blues)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te,normalize='true')).plot(colorbar=False,cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75787b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7faf03253ef0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Step 6 - Use model to make predictions\n",
    "modelz = model_FFNN_samweight_256n_4l\n",
    "# Predict class labels on training data\n",
    "pred_prob_tr = (modelz.predict(x_training))\n",
    "# Predict class labels on a test data\n",
    "pred_prob_te = (modelz.predict(x_test))\n",
    "#> 0.01).astype(int)\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0).clf()\n",
    "\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, pred_prob_te)\n",
    "auc = round(metrics.roc_auc_score(y_test, pred_prob_te), 4)\n",
    "plt.plot(fpr,tpr,label=\"Samweight_256n_4l, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#add legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ffe8ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_wt_predlables = training_set_wt\n",
    "training_set_wt_predlables['pred_lab_samweight256n4l'] = pred_labels_tr\n",
    "training_set_wt_predlables['pred_prob_samweight256n4l'] = pred_prob_tr\n",
    "training_set_wt_predlables.to_csv('predictions/samweigh/training_set_wt_predlables_samwe_512n_1l.csv')  \n",
    "\n",
    "test_set_wt_predlables = test_set_wt\n",
    "test_set_wt_predlables['pred_lab_samweight256n4l'] = pred_labels_te\n",
    "test_set_wt_predlables['pred_prob_samweight256n4l'] = pred_prob_te\n",
    "test_set_wt_predlables.to_csv('predictions/samweigh/test_set_wt_predlables_samwe_512n_1l.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdb94225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "      <th>pred_lab_samweighting8n1l</th>\n",
       "      <th>pred_prob_samweighting8n1l</th>\n",
       "      <th>pred_lab_samweigh512n1l</th>\n",
       "      <th>pred_prob_samweigh512n1l</th>\n",
       "      <th>pred_lab_samweight256n4l</th>\n",
       "      <th>pred_prob_samweight256n4l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>80.796135</td>\n",
       "      <td>-2.052292</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>4.996910</td>\n",
       "      <td>-1.678764</td>\n",
       "      <td>-272.04962</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258765</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>77.748420</td>\n",
       "      <td>-4.445312</td>\n",
       "      <td>0.740505</td>\n",
       "      <td>7.517281</td>\n",
       "      <td>0.792618</td>\n",
       "      <td>-250.63333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258765</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>71.178825</td>\n",
       "      <td>-3.778427</td>\n",
       "      <td>1.056324</td>\n",
       "      <td>9.333221</td>\n",
       "      <td>0.688252</td>\n",
       "      <td>-229.52519</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258765</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>73.585754</td>\n",
       "      <td>-4.695709</td>\n",
       "      <td>1.236446</td>\n",
       "      <td>9.589882</td>\n",
       "      <td>0.555519</td>\n",
       "      <td>-240.80815</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258765</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>72.382780</td>\n",
       "      <td>-4.002563</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>5.410950</td>\n",
       "      <td>-1.086350</td>\n",
       "      <td>-262.45557</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258765</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539482</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.637233</td>\n",
       "      <td>33.277840</td>\n",
       "      <td>5.379345</td>\n",
       "      <td>-0.286896</td>\n",
       "      <td>5.558327</td>\n",
       "      <td>-277.60870</td>\n",
       "      <td>294.14987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364386</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539483</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>23.660923</td>\n",
       "      <td>34.272537</td>\n",
       "      <td>6.438683</td>\n",
       "      <td>-13.026535</td>\n",
       "      <td>2.857349</td>\n",
       "      <td>-270.80573</td>\n",
       "      <td>294.23798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364386</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539484</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>46.051540</td>\n",
       "      <td>35.755882</td>\n",
       "      <td>7.248966</td>\n",
       "      <td>-18.870102</td>\n",
       "      <td>-3.349407</td>\n",
       "      <td>-249.43092</td>\n",
       "      <td>294.26890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413754</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539485</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>55.855648</td>\n",
       "      <td>34.069664</td>\n",
       "      <td>6.349327</td>\n",
       "      <td>-18.801796</td>\n",
       "      <td>-8.172478</td>\n",
       "      <td>-239.36870</td>\n",
       "      <td>294.36630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539486</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>61.602300</td>\n",
       "      <td>29.167267</td>\n",
       "      <td>4.805676</td>\n",
       "      <td>-15.093590</td>\n",
       "      <td>-9.708778</td>\n",
       "      <td>-251.60574</td>\n",
       "      <td>293.74924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524851</td>\n",
       "      <td>0</td>\n",
       "      <td>0.227037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539487 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  latitude  longitude        vo          r      u_200  \\\n",
       "0       2016-01-01       0.0       20.0  0.000011  80.796135  -2.052292   \n",
       "1       2016-01-01       0.0       22.5  0.000011  77.748420  -4.445312   \n",
       "2       2016-01-01       0.0       25.0 -0.000001  71.178825  -3.778427   \n",
       "3       2016-01-01       0.0       27.5 -0.000005  73.585754  -4.695709   \n",
       "4       2016-01-01       0.0       30.0 -0.000016  72.382780  -4.002563   \n",
       "...            ...       ...        ...       ...        ...        ...   \n",
       "539482  2019-12-01     -30.0       80.0  0.000006   2.637233  33.277840   \n",
       "539483  2019-12-01     -30.0       82.5 -0.000020  23.660923  34.272537   \n",
       "539484  2019-12-01     -30.0       85.0 -0.000019  46.051540  35.755882   \n",
       "539485  2019-12-01     -30.0       87.5 -0.000014  55.855648  34.069664   \n",
       "539486  2019-12-01     -30.0       90.0  0.000006  61.602300  29.167267   \n",
       "\n",
       "           u_850      v_200     v_850        ttr        sst  lsm  \\\n",
       "0       0.008678   4.996910 -1.678764 -272.04962    0.00000  0.0   \n",
       "1       0.740505   7.517281  0.792618 -250.63333    0.00000  0.0   \n",
       "2       1.056324   9.333221  0.688252 -229.52519    0.00000  0.0   \n",
       "3       1.236446   9.589882  0.555519 -240.80815    0.00000  0.0   \n",
       "4       0.734211   5.410950 -1.086350 -262.45557    0.00000  0.0   \n",
       "...          ...        ...       ...        ...        ...  ...   \n",
       "539482  5.379345  -0.286896  5.558327 -277.60870  294.14987  0.0   \n",
       "539483  6.438683 -13.026535  2.857349 -270.80573  294.23798  0.0   \n",
       "539484  7.248966 -18.870102 -3.349407 -249.43092  294.26890  0.0   \n",
       "539485  6.349327 -18.801796 -8.172478 -239.36870  294.36630  0.0   \n",
       "539486  4.805676 -15.093590 -9.708778 -251.60574  293.74924  0.0   \n",
       "\n",
       "        Real_tom_lsm  pred_lab_samweighting8n1l  pred_prob_samweighting8n1l  \\\n",
       "0                0.0                          0                    0.323778   \n",
       "1                0.0                          0                    0.323778   \n",
       "2                0.0                          0                    0.323778   \n",
       "3                0.0                          0                    0.323778   \n",
       "4                0.0                          0                    0.323778   \n",
       "...              ...                        ...                         ...   \n",
       "539482           0.0                          0                    0.323778   \n",
       "539483           0.0                          0                    0.323778   \n",
       "539484           0.0                          0                    0.323778   \n",
       "539485           0.0                          0                    0.323778   \n",
       "539486           0.0                          0                    0.323778   \n",
       "\n",
       "        pred_lab_samweigh512n1l  pred_prob_samweigh512n1l  \\\n",
       "0                             0                  0.258765   \n",
       "1                             0                  0.258765   \n",
       "2                             0                  0.258765   \n",
       "3                             0                  0.258765   \n",
       "4                             0                  0.258765   \n",
       "...                         ...                       ...   \n",
       "539482                        0                  0.364386   \n",
       "539483                        0                  0.364386   \n",
       "539484                        0                  0.413754   \n",
       "539485                        1                  0.528403   \n",
       "539486                        1                  0.524851   \n",
       "\n",
       "        pred_lab_samweight256n4l  pred_prob_samweight256n4l  \n",
       "0                              0                   0.027421  \n",
       "1                              0                   0.027422  \n",
       "2                              0                   0.027421  \n",
       "3                              0                   0.027421  \n",
       "4                              0                   0.027419  \n",
       "...                          ...                        ...  \n",
       "539482                         0                   0.226935  \n",
       "539483                         0                   0.226935  \n",
       "539484                         0                   0.226935  \n",
       "539485                         0                   0.231441  \n",
       "539486                         0                   0.227037  \n",
       "\n",
       "[539487 rows x 19 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_wt_predlables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69156cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
