{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "051c21fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.4.4\n",
      "xarray: 0.20.1\n",
      "geopandas: 1.22.3\n",
      "Tensorflow/Keras: 2.9.0\n",
      "pandas: 1.4.4\n",
      "numpy: 1.22.3\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__)\n",
    "\n",
    "import xarray as xr\n",
    "print('xarray: %s' % xr.__version__)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_rows', 150)\n",
    "\n",
    "import numpy as np\n",
    "print('geopandas: %s' % np.__version__)\n",
    "\n",
    "# Tensorflow / Keras\n",
    "import tensorflow as tf # used to access argmax function\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Dense # for creating regular densely-connected NN layer.\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout # for adding Concolutional and densely-connected NN layers.\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "\n",
    "import decimal\n",
    "from decimal import Decimal\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout,BatchNormalization,Conv2D,MaxPooling2D,Dense,Flatten\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import callbacks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense # for creating regular densely-connected NN layer.\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout,MaxPooling2D # for adding Concolutional and densely-connected NN layers.\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from pathlib import Path  \n",
    "\n",
    "from sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n",
    "from sklearn.metrics import classification_report # for model evaluation metrics\n",
    "from sklearn.preprocessing import OrdinalEncoder # for encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89dcffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('Real_Tomorrow/test_real_tom_target.csv')\n",
    "validation_set = pd.read_csv('Real_Tomorrow/validation_real_tom_target.csv')\n",
    "training_set = pd.read_csv('Real_Tomorrow/training_real_tom_target.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eb9a5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>80.761185</td>\n",
       "      <td>1.909660</td>\n",
       "      <td>-3.323872</td>\n",
       "      <td>1.687164</td>\n",
       "      <td>-1.823624</td>\n",
       "      <td>-247.54074</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>80.703650</td>\n",
       "      <td>1.165733</td>\n",
       "      <td>-2.844494</td>\n",
       "      <td>1.060593</td>\n",
       "      <td>-1.991425</td>\n",
       "      <td>-240.00592</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>78.231514</td>\n",
       "      <td>-1.311676</td>\n",
       "      <td>-2.125244</td>\n",
       "      <td>3.280617</td>\n",
       "      <td>-1.931789</td>\n",
       "      <td>-223.76889</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>79.631010</td>\n",
       "      <td>-3.777573</td>\n",
       "      <td>-1.122395</td>\n",
       "      <td>5.743889</td>\n",
       "      <td>-1.243538</td>\n",
       "      <td>-235.55556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>71.573875</td>\n",
       "      <td>-5.734505</td>\n",
       "      <td>-1.362953</td>\n",
       "      <td>6.514030</td>\n",
       "      <td>-0.954163</td>\n",
       "      <td>-254.03260</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268766</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>26.797535</td>\n",
       "      <td>25.075424</td>\n",
       "      <td>-3.653679</td>\n",
       "      <td>-1.221291</td>\n",
       "      <td>1.515594</td>\n",
       "      <td>-273.34204</td>\n",
       "      <td>296.89227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268767</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>27.766910</td>\n",
       "      <td>24.175919</td>\n",
       "      <td>-2.866638</td>\n",
       "      <td>-6.724304</td>\n",
       "      <td>0.861771</td>\n",
       "      <td>-280.37018</td>\n",
       "      <td>296.03314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268768</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>29.111805</td>\n",
       "      <td>24.655510</td>\n",
       "      <td>-2.809170</td>\n",
       "      <td>-10.138817</td>\n",
       "      <td>0.051220</td>\n",
       "      <td>-281.05167</td>\n",
       "      <td>295.36078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268769</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27.833050</td>\n",
       "      <td>25.088104</td>\n",
       "      <td>-2.730087</td>\n",
       "      <td>-11.036507</td>\n",
       "      <td>0.666927</td>\n",
       "      <td>-280.05610</td>\n",
       "      <td>295.10638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268770</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>15.843884</td>\n",
       "      <td>24.510345</td>\n",
       "      <td>-3.213837</td>\n",
       "      <td>-10.213325</td>\n",
       "      <td>-0.098499</td>\n",
       "      <td>-279.40427</td>\n",
       "      <td>294.44766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4268771 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time  latitude  longitude        vo          r      u_200  \\\n",
       "0        1980-01-01       0.0       20.0  0.000007  80.761185   1.909660   \n",
       "1        1980-01-01       0.0       22.5  0.000004  80.703650   1.165733   \n",
       "2        1980-01-01       0.0       25.0  0.000007  78.231514  -1.311676   \n",
       "3        1980-01-01       0.0       27.5  0.000010  79.631010  -3.777573   \n",
       "4        1980-01-01       0.0       30.0  0.000010  71.573875  -5.734505   \n",
       "...             ...       ...        ...       ...        ...        ...   \n",
       "4268766  2010-12-31     -30.0       80.0  0.000015  26.797535  25.075424   \n",
       "4268767  2010-12-31     -30.0       82.5 -0.000006  27.766910  24.175919   \n",
       "4268768  2010-12-31     -30.0       85.0  0.000010  29.111805  24.655510   \n",
       "4268769  2010-12-31     -30.0       87.5  0.000006  27.833050  25.088104   \n",
       "4268770  2010-12-31     -30.0       90.0  0.000007  15.843884  24.510345   \n",
       "\n",
       "            u_850      v_200     v_850        ttr        sst  lsm  \\\n",
       "0       -3.323872   1.687164 -1.823624 -247.54074    0.00000  0.0   \n",
       "1       -2.844494   1.060593 -1.991425 -240.00592    0.00000  0.0   \n",
       "2       -2.125244   3.280617 -1.931789 -223.76889    0.00000  0.0   \n",
       "3       -1.122395   5.743889 -1.243538 -235.55556    0.00000  0.0   \n",
       "4       -1.362953   6.514030 -0.954163 -254.03260    0.00000  0.0   \n",
       "...           ...        ...       ...        ...        ...  ...   \n",
       "4268766 -3.653679  -1.221291  1.515594 -273.34204  296.89227  0.0   \n",
       "4268767 -2.866638  -6.724304  0.861771 -280.37018  296.03314  0.0   \n",
       "4268768 -2.809170 -10.138817  0.051220 -281.05167  295.36078  0.0   \n",
       "4268769 -2.730087 -11.036507  0.666927 -280.05610  295.10638  0.0   \n",
       "4268770 -3.213837 -10.213325 -0.098499 -279.40427  294.44766  0.0   \n",
       "\n",
       "         Real_tom_lsm  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "4268766           0.0  \n",
       "4268767           0.0  \n",
       "4268768           0.0  \n",
       "4268769           0.0  \n",
       "4268770           0.0  \n",
       "\n",
       "[4268771 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data set\n",
    "training_set_wt = training_set.drop(columns=['Unnamed: 0'])\n",
    "training_set_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e35108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>73.016390</td>\n",
       "      <td>-5.760780</td>\n",
       "      <td>-4.216808</td>\n",
       "      <td>6.860649</td>\n",
       "      <td>-4.352928</td>\n",
       "      <td>-212.59741</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>74.569660</td>\n",
       "      <td>-4.942451</td>\n",
       "      <td>-3.857407</td>\n",
       "      <td>6.459419</td>\n",
       "      <td>-3.991157</td>\n",
       "      <td>-198.23593</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>80.080090</td>\n",
       "      <td>-3.848740</td>\n",
       "      <td>-3.175144</td>\n",
       "      <td>6.303680</td>\n",
       "      <td>-3.446140</td>\n",
       "      <td>-195.83296</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>83.676704</td>\n",
       "      <td>0.330811</td>\n",
       "      <td>-2.526569</td>\n",
       "      <td>7.235268</td>\n",
       "      <td>-2.307594</td>\n",
       "      <td>-191.47444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>76.225440</td>\n",
       "      <td>3.678749</td>\n",
       "      <td>-1.027561</td>\n",
       "      <td>7.020271</td>\n",
       "      <td>-0.077572</td>\n",
       "      <td>-191.98111</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688397</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>70.662056</td>\n",
       "      <td>23.560066</td>\n",
       "      <td>1.655861</td>\n",
       "      <td>9.690376</td>\n",
       "      <td>3.621418</td>\n",
       "      <td>-271.57556</td>\n",
       "      <td>296.77530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688398</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>51.213654</td>\n",
       "      <td>22.381706</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>9.860390</td>\n",
       "      <td>-0.099480</td>\n",
       "      <td>-269.94592</td>\n",
       "      <td>296.44290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688399</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>46.678970</td>\n",
       "      <td>22.464828</td>\n",
       "      <td>0.851299</td>\n",
       "      <td>7.661758</td>\n",
       "      <td>-0.725330</td>\n",
       "      <td>-270.18890</td>\n",
       "      <td>295.73486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688400</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>59.362090</td>\n",
       "      <td>22.364807</td>\n",
       "      <td>0.543045</td>\n",
       "      <td>5.595253</td>\n",
       "      <td>-1.542034</td>\n",
       "      <td>-264.07333</td>\n",
       "      <td>295.24792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688401</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>65.915980</td>\n",
       "      <td>23.052147</td>\n",
       "      <td>0.048565</td>\n",
       "      <td>1.080147</td>\n",
       "      <td>-1.203087</td>\n",
       "      <td>-259.79480</td>\n",
       "      <td>295.79680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688402 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  latitude  longitude        vo          r      u_200  \\\n",
       "0       2011-01-01       0.0       20.0  0.000003  73.016390  -5.760780   \n",
       "1       2011-01-01       0.0       22.5  0.000003  74.569660  -4.942451   \n",
       "2       2011-01-01       0.0       25.0  0.000004  80.080090  -3.848740   \n",
       "3       2011-01-01       0.0       27.5  0.000012  83.676704   0.330811   \n",
       "4       2011-01-01       0.0       30.0  0.000011  76.225440   3.678749   \n",
       "...            ...       ...        ...       ...        ...        ...   \n",
       "688397  2015-12-31     -30.0       80.0  0.000014  70.662056  23.560066   \n",
       "688398  2015-12-31     -30.0       82.5 -0.000006  51.213654  22.381706   \n",
       "688399  2015-12-31     -30.0       85.0  0.000009  46.678970  22.464828   \n",
       "688400  2015-12-31     -30.0       87.5  0.000002  59.362090  22.364807   \n",
       "688401  2015-12-31     -30.0       90.0  0.000014  65.915980  23.052147   \n",
       "\n",
       "           u_850     v_200     v_850        ttr        sst  lsm  Real_tom_lsm  \n",
       "0      -4.216808  6.860649 -4.352928 -212.59741    0.00000  0.0           0.0  \n",
       "1      -3.857407  6.459419 -3.991157 -198.23593    0.00000  0.0           0.0  \n",
       "2      -3.175144  6.303680 -3.446140 -195.83296    0.00000  0.0           0.0  \n",
       "3      -2.526569  7.235268 -2.307594 -191.47444    0.00000  0.0           0.0  \n",
       "4      -1.027561  7.020271 -0.077572 -191.98111    0.00000  0.0           0.0  \n",
       "...          ...       ...       ...        ...        ...  ...           ...  \n",
       "688397  1.655861  9.690376  3.621418 -271.57556  296.77530  0.0           0.0  \n",
       "688398  0.321705  9.860390 -0.099480 -269.94592  296.44290  0.0           0.0  \n",
       "688399  0.851299  7.661758 -0.725330 -270.18890  295.73486  0.0           0.0  \n",
       "688400  0.543045  5.595253 -1.542034 -264.07333  295.24792  0.0           0.0  \n",
       "688401  0.048565  1.080147 -1.203087 -259.79480  295.79680  0.0           0.0  \n",
       "\n",
       "[688402 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation data set\n",
    "validation_set_wt = validation_set.drop(columns=['Unnamed: 0'])\n",
    "validation_set_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04bc8fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>80.796135</td>\n",
       "      <td>-2.052292</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>4.996910</td>\n",
       "      <td>-1.678764</td>\n",
       "      <td>-272.04962</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>77.748420</td>\n",
       "      <td>-4.445312</td>\n",
       "      <td>0.740505</td>\n",
       "      <td>7.517281</td>\n",
       "      <td>0.792618</td>\n",
       "      <td>-250.63333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>71.178825</td>\n",
       "      <td>-3.778427</td>\n",
       "      <td>1.056324</td>\n",
       "      <td>9.333221</td>\n",
       "      <td>0.688252</td>\n",
       "      <td>-229.52519</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>73.585754</td>\n",
       "      <td>-4.695709</td>\n",
       "      <td>1.236446</td>\n",
       "      <td>9.589882</td>\n",
       "      <td>0.555519</td>\n",
       "      <td>-240.80815</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>72.382780</td>\n",
       "      <td>-4.002563</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>5.410950</td>\n",
       "      <td>-1.086350</td>\n",
       "      <td>-262.45557</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539482</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.637233</td>\n",
       "      <td>33.277840</td>\n",
       "      <td>5.379345</td>\n",
       "      <td>-0.286896</td>\n",
       "      <td>5.558327</td>\n",
       "      <td>-277.60870</td>\n",
       "      <td>294.14987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539483</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>23.660923</td>\n",
       "      <td>34.272537</td>\n",
       "      <td>6.438683</td>\n",
       "      <td>-13.026535</td>\n",
       "      <td>2.857349</td>\n",
       "      <td>-270.80573</td>\n",
       "      <td>294.23798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539484</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>46.051540</td>\n",
       "      <td>35.755882</td>\n",
       "      <td>7.248966</td>\n",
       "      <td>-18.870102</td>\n",
       "      <td>-3.349407</td>\n",
       "      <td>-249.43092</td>\n",
       "      <td>294.26890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539485</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>55.855648</td>\n",
       "      <td>34.069664</td>\n",
       "      <td>6.349327</td>\n",
       "      <td>-18.801796</td>\n",
       "      <td>-8.172478</td>\n",
       "      <td>-239.36870</td>\n",
       "      <td>294.36630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539486</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>61.602300</td>\n",
       "      <td>29.167267</td>\n",
       "      <td>4.805676</td>\n",
       "      <td>-15.093590</td>\n",
       "      <td>-9.708778</td>\n",
       "      <td>-251.60574</td>\n",
       "      <td>293.74924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539487 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  latitude  longitude        vo          r      u_200  \\\n",
       "0       2016-01-01       0.0       20.0  0.000011  80.796135  -2.052292   \n",
       "1       2016-01-01       0.0       22.5  0.000011  77.748420  -4.445312   \n",
       "2       2016-01-01       0.0       25.0 -0.000001  71.178825  -3.778427   \n",
       "3       2016-01-01       0.0       27.5 -0.000005  73.585754  -4.695709   \n",
       "4       2016-01-01       0.0       30.0 -0.000016  72.382780  -4.002563   \n",
       "...            ...       ...        ...       ...        ...        ...   \n",
       "539482  2019-12-01     -30.0       80.0  0.000006   2.637233  33.277840   \n",
       "539483  2019-12-01     -30.0       82.5 -0.000020  23.660923  34.272537   \n",
       "539484  2019-12-01     -30.0       85.0 -0.000019  46.051540  35.755882   \n",
       "539485  2019-12-01     -30.0       87.5 -0.000014  55.855648  34.069664   \n",
       "539486  2019-12-01     -30.0       90.0  0.000006  61.602300  29.167267   \n",
       "\n",
       "           u_850      v_200     v_850        ttr        sst  lsm  Real_tom_lsm  \n",
       "0       0.008678   4.996910 -1.678764 -272.04962    0.00000  0.0           0.0  \n",
       "1       0.740505   7.517281  0.792618 -250.63333    0.00000  0.0           0.0  \n",
       "2       1.056324   9.333221  0.688252 -229.52519    0.00000  0.0           0.0  \n",
       "3       1.236446   9.589882  0.555519 -240.80815    0.00000  0.0           0.0  \n",
       "4       0.734211   5.410950 -1.086350 -262.45557    0.00000  0.0           0.0  \n",
       "...          ...        ...       ...        ...        ...  ...           ...  \n",
       "539482  5.379345  -0.286896  5.558327 -277.60870  294.14987  0.0           0.0  \n",
       "539483  6.438683 -13.026535  2.857349 -270.80573  294.23798  0.0           0.0  \n",
       "539484  7.248966 -18.870102 -3.349407 -249.43092  294.26890  0.0           0.0  \n",
       "539485  6.349327 -18.801796 -8.172478 -239.36870  294.36630  0.0           0.0  \n",
       "539486  4.805676 -15.093590 -9.708778 -251.60574  293.74924  0.0           0.0  \n",
       "\n",
       "[539487 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data set\n",
    "test_set_wt = test_set.drop(columns=['Unnamed: 0'])\n",
    "test_set_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "123b9438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         ...,\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02]],\n",
       "\n",
       "        [[ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         ...,\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02]],\n",
       "\n",
       "        [[ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         ...,\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         ...,\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02]],\n",
       "\n",
       "        [[ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         ...,\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02]],\n",
       "\n",
       "        [[ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         ...,\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02],\n",
       "         [ 1.53911533e-05,  3.20366707e+01,  1.67111511e+01, ...,\n",
       "           4.69425201e+00, -2.82328888e+02,  2.95998840e+02]]],\n",
       "\n",
       "\n",
       "       [[[-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         ...,\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02]],\n",
       "\n",
       "        [[-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         ...,\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02]],\n",
       "\n",
       "        [[-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         ...,\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         ...,\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02]],\n",
       "\n",
       "        [[-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         ...,\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02]],\n",
       "\n",
       "        [[-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         ...,\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02],\n",
       "         [-1.22482015e-05,  2.82475567e+00,  2.23885345e+01, ...,\n",
       "           1.75038528e+00, -2.78030365e+02,  2.96102600e+02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         ...,\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02]],\n",
       "\n",
       "        [[ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         ...,\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02]],\n",
       "\n",
       "        [[ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         ...,\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         ...,\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02]],\n",
       "\n",
       "        [[ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         ...,\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02]],\n",
       "\n",
       "        [[ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         ...,\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02],\n",
       "         [ 1.45858503e-05,  4.00356007e+00,  2.24713516e+01, ...,\n",
       "           6.26106262e-01, -2.74524078e+02,  2.96143036e+02]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         ...,\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02]],\n",
       "\n",
       "        [[ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         ...,\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02]],\n",
       "\n",
       "        [[ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         ...,\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         ...,\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02]],\n",
       "\n",
       "        [[ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         ...,\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02]],\n",
       "\n",
       "        [[ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         ...,\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02],\n",
       "         [ 3.41348641e-06,  1.44798965e+01,  8.79013062e+00, ...,\n",
       "           2.09011078e+00, -2.89581116e+02,  2.94061646e+02]]],\n",
       "\n",
       "\n",
       "       [[[-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         ...,\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02]],\n",
       "\n",
       "        [[-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         ...,\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02]],\n",
       "\n",
       "        [[-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         ...,\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         ...,\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02]],\n",
       "\n",
       "        [[-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         ...,\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02]],\n",
       "\n",
       "        [[-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         ...,\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02],\n",
       "         [-3.74493538e-06,  2.05989456e+01,  1.09164124e+01, ...,\n",
       "           6.18144989e-01, -2.87288513e+02,  2.94186279e+02]]],\n",
       "\n",
       "\n",
       "       [[[ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         ...,\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02]],\n",
       "\n",
       "        [[ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         ...,\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02]],\n",
       "\n",
       "        [[ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         ...,\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         ...,\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02]],\n",
       "\n",
       "        [[ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         ...,\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02]],\n",
       "\n",
       "        [[ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         ...,\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02],\n",
       "         [ 7.33783236e-06,  1.58438835e+01,  2.45103455e+01, ...,\n",
       "          -9.84992981e-02, -2.79404266e+02,  2.94447662e+02]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training set has 11323 days\n",
    "data_images_training_set = np.zeros( (11323,13,29,8), dtype=np.float32 )\n",
    "\n",
    "for days in range(0,11323):\n",
    "    a=training_set_wt.iloc[377*days:377*(days+1),3:11]\n",
    "    for per in range(0,377):\n",
    "        for atr in range(0,8):\n",
    "            data_images_training_set[days,0:13,0:29,atr] = a.iloc[per,atr] \n",
    "            \n",
    "type(data_images_training_set)\n",
    "data_images_training_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2d0832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "os.makedirs('images', exist_ok=True)\n",
    "np.save('images/data_images_training_set', data_images_training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c739ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation set has 1826 days\n",
    "data_images_validation_set = np.zeros( (1826,13,29,8), dtype=np.float32 )\n",
    "\n",
    "for days in range(0,1826):\n",
    "    b=validation_set_wt.iloc[377*days:377*(days+1),3:11]\n",
    "    for per in range(0,377):\n",
    "        for atr in range(0,8):\n",
    "            data_images_validation_set[days,0:13,0:29,atr] = a.iloc[per,atr] \n",
    "                    \n",
    "\n",
    "np.save('images/data_images_validation_set', data_images_validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "050fd9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set has 1431 days\n",
    "data_images_test_set = np.zeros( (1431,13,29,8), dtype=np.float32 )\n",
    "\n",
    "for days in range(0,1431):\n",
    "    b=test_set_wt.iloc[377*days:377*(days+1),3:11]\n",
    "    for per in range(0,377):\n",
    "        for atr in range(0,8):\n",
    "            data_images_test_set[days,0:13,0:29,atr] = a.iloc[per,atr] \n",
    "                    \n",
    "\n",
    "np.save('images/data_images_test_set', data_images_test_set)\n",
    "#loaded_array = np.load('file_name.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d42385b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images_training_set = np.load('images/data_images_training_set.npy')\n",
    "data_images_validation_set = np.load('images/data_images_validation_set.npy')\n",
    "data_images_test_set = np.load('images/data_images_test_set.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150bd816",
   "metadata": {},
   "source": [
    "# SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da502411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting y for training\n",
    "df1=training_set_wt.query(\"latitude == -15.0 and longitude == 55\")\n",
    "y_train = df1['Real_tom_lsm'].values\n",
    "y_train = y_train.reshape(-1,1)\n",
    "\n",
    "#extracting y for validation\n",
    "df2=validation_set_wt.query(\"latitude == -15.0 and longitude == 55\")\n",
    "y_validation = df2['Real_tom_lsm'].values\n",
    "y_validation = y_validation.reshape(-1,1)\n",
    "\n",
    "#extracting y for test\n",
    "df3=test_set_wt.query(\"latitude == -15.0 and longitude == 55\")\n",
    "y_test = df3['Real_tom_lsm'].values\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bbc3fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (11323, 13, 29, 8)\n",
      "Shape of y_train:  (11323, 1)\n",
      "Shape of X_valid:  (1826, 13, 29, 8)\n",
      "Shape of y_valid:  (1826, 1)\n",
      "Shape of X_test:  (1431, 13, 29, 8)\n",
      "Shape of y_test:  (1431, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes\n",
    "# Note, model input must have a four-dimensional shape [samples, rows, columns, channels]\n",
    "\n",
    "X_train = data_images_training_set\n",
    "X_valid = data_images_validation_set\n",
    "X_test = data_images_test_set\n",
    "\n",
    "\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(\"Shape of X_valid: \", X_valid.shape)\n",
    "print(\"Shape of y_valid: \", y_validation.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_test: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b15e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Step 1 - Specify the structure of a Neural Network\n",
    "#--- Define a Model\n",
    "model = Sequential(name=\"DCN-Model\") # Model\n",
    "\n",
    "\n",
    "#--- Input Layer \n",
    "# Specify input shape [rows, columns, channels]\n",
    "model.add(Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3]), name='Input-Layer')) # Input Layer - need to speicfy the shape of inputs\n",
    "\n",
    "\n",
    "#--- First Set of Convolution, Max Pooling and Droput Layers (all parameters shown)\n",
    "model.add(Conv2D(filters=16, # Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "                 kernel_size=(3,3), # An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "                 strides=(1,1), # Default=(1,1), An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n",
    "                 padding='valid', # Default='valid', \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input. When padding=\"same\" and strides=1, the output has the same size as the input.\n",
    "                 data_format=None, # Default=None, A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch_size, height, width, channels) while channels_first corresponds to inputs with shape (batch_size, channels,height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last.\n",
    "                 dilation_rate=(1, 1), # Default=(1, 1), an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n",
    "                 groups=1, # Default=1, A positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with filters / groups filters. The output is the concatenation of all the groups results along the channel axis. Input channels and filters must both be divisible by groups.\n",
    "                 activation='relu', # Default=None, Activation function to use. If you don't specify anything, no activation is applied (see keras.activations).\n",
    "                 use_bias=True, # Default=True. \n",
    "                 kernel_initializer='glorot_uniform', # Default='glorot_uniform', Initializer for the kernel weights matrix (see keras.initializers).\n",
    "                 bias_initializer='zeros', # Default='zeros', Initializer for the bias vector (see keras.initializers).\n",
    "                 kernel_regularizer=None, # Default=None, Regularizer function applied to the kernel weights matrix (see keras.regularizers).\n",
    "                 bias_regularizer=None, # Default=None, Regularizer function applied to the bias vector (see keras.regularizers).\n",
    "                 activity_regularizer=None, # Default=None, Regularizer function applied to the output of the layer (its \"activation\") (see keras.regularizers).\n",
    "                 kernel_constraint=None, # Default=None, Constraint function applied to the kernel matrix (see keras.constraints).\n",
    "                 bias_constraint=None, # Default=None, Constraint function applied to the bias vector (see keras.constraints).\n",
    "                 name='2D-Convolutional-Layer-1')\n",
    "         ) # Convolutional Layer, relu activation used\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2), # Default=(2,2), integer or tuple of 2 integers, window size over which to take the maximum. (2, 2) will take the max value over a 2x2 pooling window. If only one integer is specified, the same window length will be used for both dimensions.\n",
    "                    strides=(2,2), # Default=None, Integer, tuple of 2 integers, or None. Strides values. Specifies how far the pooling window moves for each pooling step. If None, it will default to pool_size.\n",
    "                    padding='valid', # Default='valid', One of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n",
    "                    data_format=None, # Default=None, A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). \n",
    "                    name='2D-MaxPool-Layer-1')\n",
    "         ) # Max Pooling Layer,\n",
    "\n",
    "model.add(Dropout(0.2, name='Dropout-Layer-1')) # Dropout Layer\n",
    "\n",
    "\n",
    "#--- Second Set of Convolution, Max Pooling and Droput Layers \n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', name='2D-Convolutional-Layer-2')) # Convolutional Layer\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='valid', name='2D-MaxPool-Layer-2')) # Second Max Pooling Layer,\n",
    "model.add(Dropout(0.2, name='Dropout-Layer-2')) # Dropout Layer\n",
    "\n",
    "\n",
    "#--- Third Set of Convolution, Max Pooling and Droput Layers\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', name='2D-Convolutional-Layer-3')) # Convolutional Layer\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same', name='2D-MaxPool-Layer-3')) # Second Max Pooling Layer,\n",
    "model.add(Dropout(0.2, name='Dropout-Layer-3')) # Dropout Layer\n",
    "\n",
    "\n",
    "#--- Feed-Forward Densely Connected Layer and Output Layer (note, flattening is required to convert from 2D to 1D shape)\n",
    "model.add(Flatten(name='Flatten-Layer')) # Flatten the shape so we can feed it into a regular densely connected layer\n",
    "model.add(Dense(16, activation='relu', name='Hidden-Layer-1', kernel_initializer='HeNormal')) # Hidden Layer, relu(x) = max(x, 0)\n",
    "model.add(Dense(1, activation='softmax', name='Output-Layer')) # Output Layer, softmax(x) = exp(x) / tf.reduce_sum(exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27bcd6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 0.1482 - Accuracy: 0.0071 - val_loss: 0.1028 - val_Accuracy: 0.0066\n",
      "Epoch 2/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0466 - Accuracy: 0.0071 - val_loss: 0.0815 - val_Accuracy: 0.0066\n",
      "Epoch 3/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0429 - Accuracy: 0.0071 - val_loss: 0.0402 - val_Accuracy: 0.0066\n",
      "Epoch 4/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0459 - Accuracy: 0.0071 - val_loss: 0.1054 - val_Accuracy: 0.0066\n",
      "Epoch 5/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0427 - Accuracy: 0.0071 - val_loss: 0.1030 - val_Accuracy: 0.0066\n",
      "Epoch 6/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0431 - Accuracy: 0.0071 - val_loss: 0.0673 - val_Accuracy: 0.0066\n",
      "Epoch 7/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0429 - Accuracy: 0.0071 - val_loss: 0.0491 - val_Accuracy: 0.0066\n",
      "Epoch 8/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0426 - Accuracy: 0.0071 - val_loss: 0.0786 - val_Accuracy: 0.0066\n",
      "Epoch 9/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0418 - Accuracy: 0.0071 - val_loss: 0.0504 - val_Accuracy: 0.0066\n",
      "Epoch 10/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0436 - Accuracy: 0.0071 - val_loss: 0.0790 - val_Accuracy: 0.0066\n",
      "Epoch 11/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0439 - Accuracy: 0.0071 - val_loss: 0.0607 - val_Accuracy: 0.0066\n",
      "Epoch 12/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0424 - Accuracy: 0.0071 - val_loss: 0.0528 - val_Accuracy: 0.0066\n",
      "Epoch 13/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0427 - Accuracy: 0.0071 - val_loss: 0.0995 - val_Accuracy: 0.0066\n",
      "Epoch 14/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0429 - Accuracy: 0.0071 - val_loss: 0.1238 - val_Accuracy: 0.0066\n",
      "Epoch 15/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0421 - Accuracy: 0.0071 - val_loss: 0.0530 - val_Accuracy: 0.0066\n",
      "Epoch 16/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0423 - Accuracy: 0.0071 - val_loss: 0.0518 - val_Accuracy: 0.0066\n",
      "Epoch 17/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0428 - Accuracy: 0.0071 - val_loss: 0.1638 - val_Accuracy: 0.0066\n",
      "Epoch 18/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0460 - Accuracy: 0.0071 - val_loss: 0.0545 - val_Accuracy: 0.0066\n",
      "Epoch 19/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0426 - Accuracy: 0.0071 - val_loss: 0.0622 - val_Accuracy: 0.0066\n",
      "Epoch 20/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0456 - Accuracy: 0.0071 - val_loss: 0.0522 - val_Accuracy: 0.0066\n"
     ]
    }
   ],
   "source": [
    "##### Step 2 - Compile keras model\n",
    "model.compile(optimizer='adam', # default='rmsprop', an algorithm to be used in backpropagation\n",
    "              loss='binary_crossentropy', # Loss function to be optimized. A string (name of loss function), or a tf.keras.losses.Loss instance.\n",
    "              metrics=['Accuracy'], # List of metrics to be evaluated by the model during training and testing. Each of this can be a string (name of a built-in function), function or a tf.keras.metrics.Metric instance. \n",
    "              loss_weights=None, # default=None, Optional list or dictionary specifying scalar coefficients (Python floats) to weight the loss contributions of different model outputs.\n",
    "              weighted_metrics=None, # default=None, List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing.\n",
    "              run_eagerly=None, # Defaults to False. If True, this Model's logic will not be wrapped in a tf.function. Recommended to leave this as None unless your Model cannot be run inside a tf.function.\n",
    "              steps_per_execution=None # Defaults to 1. The number of batches to run during each tf.function call. Running multiple batches inside a single tf.function call can greatly improve performance on TPUs or small models with a large Python overhead.\n",
    "             )\n",
    "\n",
    "\n",
    "##### Step 3 - Fit keras model on the dataset\n",
    "history = model.fit(X_train, # input data\n",
    "                    y_train, # target data\n",
    "                    #batch_size=1, # Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "                    epochs=20, # default=1, Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided\n",
    "                    #verbose=0, # default='auto', ('auto', 0, 1, or 2). Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 'auto' defaults to 1 for most cases, but 2 when used with ParameterServerStrategy.\n",
    "                    callbacks=None, # default=None, list of callbacks to apply during training. See tf.keras.callbacks\n",
    "                    #validation_split=0.0, # default=0.0, Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. \n",
    "                    validation_data=(X_valid, y_validation), # default=None, Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "                    #shuffle=True, # default=True, Boolean (whether to shuffle the training data before each epoch) or str (for 'batch').\n",
    "                    #class_weight=None, # default=None, Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "                    #sample_weight=None, # default=None, Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only).\n",
    "                    #initial_epoch=0, # Integer, default=0, Epoch at which to start training (useful for resuming a previous training run).\n",
    "                    #steps_per_epoch=None, # Integer or None, default=None, Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. \n",
    "                    #validation_steps=None, # Only relevant if validation_data is provided and is a tf.data dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch.\n",
    "                    #validation_batch_size=None, # Integer or None, default=None, Number of samples per validation batch. If unspecified, will default to batch_size.\n",
    "                    #validation_freq=1, # default=1, Only relevant if validation data is provided. If an integer, specifies how many training epochs to run before a new validation run is performed, e.g. validation_freq=2 runs validation every 2 epochs.\n",
    "                    #max_queue_size=10, # default=10, Used for generator or keras.utils.Sequence input only. Maximum size for the generator queue. If unspecified, max_queue_size will default to 10.\n",
    "                    #workers=1, # default=1, Used for generator or keras.utils.Sequence input only. Maximum number of processes to spin up when using process-based threading. If unspecified, workers will default to 1.\n",
    "                    #use_multiprocessing=False, # default=False, Used for generator or keras.utils.Sequence input only. If True, use process-based threading. If unspecified, use_multiprocessing will default to False. \n",
    "                   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e34c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 1s 2ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "\n",
      "------------------------- Model Summary -------------------------\n",
      "Model: \"DCN-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " 2D-Convolutional-Layer-1 (C  (None, 11, 27, 16)       1168      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-1 (MaxPool  (None, 5, 13, 16)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-1 (Dropout)   (None, 5, 13, 16)         0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-2 (C  (None, 3, 11, 64)        9280      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-2 (MaxPool  (None, 1, 5, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-2 (Dropout)   (None, 1, 5, 64)          0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-3 (C  (None, 1, 5, 64)         36928     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-3 (MaxPool  (None, 1, 3, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-3 (Dropout)   (None, 1, 3, 64)          0         \n",
      "                                                                 \n",
      " Flatten-Layer (Flatten)     (None, 192)               0         \n",
      "                                                                 \n",
      " Hidden-Layer-1 (Dense)      (None, 16)                3088      \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,481\n",
      "Trainable params: 50,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "------------------ Evaluation on Training Data ------------------\n",
      "Final loss : 0.045594874769449234\n",
      "Final Accuracy : 0.007065265439450741\n",
      "Final val_loss : 0.052213914692401886\n",
      "Final val_Accuracy : 0.006571741309016943\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00     11243\n",
      "         1.0       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.99     11323\n",
      "   macro avg       0.50      0.50      0.50     11323\n",
      "weighted avg       0.99      0.99      0.99     11323\n",
      "\n",
      "\n",
      "-------------------- Evaluation on Test Data --------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      1416\n",
      "         1.0       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.99      1431\n",
      "   macro avg       0.49      0.50      0.50      1431\n",
      "weighted avg       0.98      0.99      0.98      1431\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "##### Step 4 - Use model to make predictions\n",
    "# Note, we need to pass model output through argmax to convert from probability to label\n",
    "# Also, we convert output from tensor to numpy array\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = np.array(tf.math.argmax(model.predict(X_train),axis=1))\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = np.array(tf.math.argmax(model.predict(X_test),axis=1))\n",
    "\n",
    "\n",
    "##### Step 5 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('------------------------- Model Summary -------------------------')\n",
    "model.summary() # print model summary\n",
    "print(\"\")\n",
    "    \n",
    "\n",
    "\n",
    "print('------------------ Evaluation on Training Data ------------------')\n",
    "# Print the last value in the evaluation metrics contained within history file\n",
    "for item in history.history:\n",
    "    print(\"Final\", item, \":\", history.history[item][-1])\n",
    "print(\"\")\n",
    "# Print classification report\n",
    "print(classification_report(y_train, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('-------------------- Evaluation on Test Data --------------------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "205c4e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 1s 2ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "\n",
      "-------------------- Model Summary --------------------\n",
      "Model: \"DCN-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " 2D-Convolutional-Layer-1 (C  (None, 11, 27, 16)       1168      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-1 (MaxPool  (None, 5, 13, 16)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-1 (Dropout)   (None, 5, 13, 16)         0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-2 (C  (None, 3, 11, 64)        9280      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-2 (MaxPool  (None, 1, 5, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-2 (Dropout)   (None, 1, 5, 64)          0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-3 (C  (None, 1, 5, 64)         36928     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-3 (MaxPool  (None, 1, 3, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-3 (Dropout)   (None, 1, 3, 64)          0         \n",
      "                                                                 \n",
      " Flatten-Layer (Flatten)     (None, 192)               0         \n",
      "                                                                 \n",
      " Hidden-Layer-1 (Dense)      (None, 16)                3088      \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,481\n",
      "Trainable params: 50,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "-------------------- Weights and Biases --------------------\n",
      "Layer:  2D-Convolutional-Layer-1\n",
      "Layer:  2D-MaxPool-Layer-1\n",
      "Layer:  Dropout-Layer-1\n",
      "Layer:  2D-Convolutional-Layer-2\n",
      "Layer:  2D-MaxPool-Layer-2\n",
      "Layer:  Dropout-Layer-2\n",
      "Layer:  2D-Convolutional-Layer-3\n",
      "Layer:  2D-MaxPool-Layer-3\n",
      "Layer:  Dropout-Layer-3\n",
      "Layer:  Flatten-Layer\n",
      "Layer:  Hidden-Layer-1\n",
      "Layer:  Output-Layer\n",
      "\n",
      "---------- Evaluation on Training Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     11243\n",
      "         1.0       0.01      1.00      0.01        80\n",
      "\n",
      "    accuracy                           0.01     11323\n",
      "   macro avg       0.00      0.50      0.01     11323\n",
      "weighted avg       0.00      0.01      0.00     11323\n",
      "\n",
      "\n",
      "---------- Evaluation on Test Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      1416\n",
      "         1.0       0.01      1.00      0.02        15\n",
      "\n",
      "    accuracy                           0.01      1431\n",
      "   macro avg       0.01      0.50      0.01      1431\n",
      "weighted avg       0.00      0.01      0.00      1431\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fecb80fd480>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Step 6 - Use model to make predictions\n",
    "modelz = model\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = (modelz.predict(X_train)> 0.5).astype(int)\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = (modelz.predict(X_test)> 0.5).astype(int)\n",
    "#> 0.01).astype(int)\n",
    "\n",
    "\n",
    "##### Step 7 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('-------------------- Model Summary --------------------')\n",
    "modelz.summary() # print model summary\n",
    "print(\"\")\n",
    "print('-------------------- Weights and Biases --------------------')\n",
    "for layer in modelz.layers:\n",
    "    print(\"Layer: \", layer.name) # print layer name\n",
    "    \n",
    "print(\"\")\n",
    "print('---------- Evaluation on Training Data ----------')\n",
    "print(classification_report(y_train, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('---------- Evaluation on Test Data ----------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te)).plot(colorbar=False,cmap=plt.cm.Blues)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te,normalize='true')).plot(colorbar=False,cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c88cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
