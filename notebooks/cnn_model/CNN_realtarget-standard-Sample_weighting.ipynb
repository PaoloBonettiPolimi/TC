{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051c21fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.4.4\n",
      "xarray: 0.20.1\n",
      "geopandas: 1.22.3\n",
      "Tensorflow/Keras: 2.9.0\n",
      "pandas: 1.4.4\n",
      "numpy: 1.22.3\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__)\n",
    "\n",
    "import xarray as xr\n",
    "print('xarray: %s' % xr.__version__)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_rows', 150)\n",
    "\n",
    "import numpy as np\n",
    "print('geopandas: %s' % np.__version__)\n",
    "\n",
    "# Tensorflow / Keras\n",
    "import tensorflow as tf # used to access argmax function\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Dense # for creating regular densely-connected NN layer.\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout # for adding Concolutional and densely-connected NN layers.\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "\n",
    "import decimal\n",
    "from decimal import Decimal\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout,BatchNormalization,Conv2D,MaxPooling2D,Dense,Flatten\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import callbacks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense # for creating regular densely-connected NN layer.\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout,MaxPooling2D # for adding Concolutional and densely-connected NN layers.\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from pathlib import Path  \n",
    "\n",
    "from sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n",
    "from sklearn.metrics import classification_report # for model evaluation metrics\n",
    "from sklearn.preprocessing import OrdinalEncoder # for encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89dcffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('Real_Tomorrow/test_real_tom_target.csv')\n",
    "validation_set = pd.read_csv('Real_Tomorrow/validation_real_tom_target.csv')\n",
    "training_set = pd.read_csv('Real_Tomorrow/training_real_tom_target.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb9a5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>80.761185</td>\n",
       "      <td>1.909660</td>\n",
       "      <td>-3.323872</td>\n",
       "      <td>1.687164</td>\n",
       "      <td>-1.823624</td>\n",
       "      <td>-247.54074</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>80.703650</td>\n",
       "      <td>1.165733</td>\n",
       "      <td>-2.844494</td>\n",
       "      <td>1.060593</td>\n",
       "      <td>-1.991425</td>\n",
       "      <td>-240.00592</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>78.231514</td>\n",
       "      <td>-1.311676</td>\n",
       "      <td>-2.125244</td>\n",
       "      <td>3.280617</td>\n",
       "      <td>-1.931789</td>\n",
       "      <td>-223.76889</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>79.631010</td>\n",
       "      <td>-3.777573</td>\n",
       "      <td>-1.122395</td>\n",
       "      <td>5.743889</td>\n",
       "      <td>-1.243538</td>\n",
       "      <td>-235.55556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>71.573875</td>\n",
       "      <td>-5.734505</td>\n",
       "      <td>-1.362953</td>\n",
       "      <td>6.514030</td>\n",
       "      <td>-0.954163</td>\n",
       "      <td>-254.03260</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268766</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>26.797535</td>\n",
       "      <td>25.075424</td>\n",
       "      <td>-3.653679</td>\n",
       "      <td>-1.221291</td>\n",
       "      <td>1.515594</td>\n",
       "      <td>-273.34204</td>\n",
       "      <td>296.89227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268767</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>27.766910</td>\n",
       "      <td>24.175919</td>\n",
       "      <td>-2.866638</td>\n",
       "      <td>-6.724304</td>\n",
       "      <td>0.861771</td>\n",
       "      <td>-280.37018</td>\n",
       "      <td>296.03314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268768</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>29.111805</td>\n",
       "      <td>24.655510</td>\n",
       "      <td>-2.809170</td>\n",
       "      <td>-10.138817</td>\n",
       "      <td>0.051220</td>\n",
       "      <td>-281.05167</td>\n",
       "      <td>295.36078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268769</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27.833050</td>\n",
       "      <td>25.088104</td>\n",
       "      <td>-2.730087</td>\n",
       "      <td>-11.036507</td>\n",
       "      <td>0.666927</td>\n",
       "      <td>-280.05610</td>\n",
       "      <td>295.10638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268770</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>15.843884</td>\n",
       "      <td>24.510345</td>\n",
       "      <td>-3.213837</td>\n",
       "      <td>-10.213325</td>\n",
       "      <td>-0.098499</td>\n",
       "      <td>-279.40427</td>\n",
       "      <td>294.44766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4268771 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time  latitude  longitude        vo          r      u_200  \\\n",
       "0        1980-01-01       0.0       20.0  0.000007  80.761185   1.909660   \n",
       "1        1980-01-01       0.0       22.5  0.000004  80.703650   1.165733   \n",
       "2        1980-01-01       0.0       25.0  0.000007  78.231514  -1.311676   \n",
       "3        1980-01-01       0.0       27.5  0.000010  79.631010  -3.777573   \n",
       "4        1980-01-01       0.0       30.0  0.000010  71.573875  -5.734505   \n",
       "...             ...       ...        ...       ...        ...        ...   \n",
       "4268766  2010-12-31     -30.0       80.0  0.000015  26.797535  25.075424   \n",
       "4268767  2010-12-31     -30.0       82.5 -0.000006  27.766910  24.175919   \n",
       "4268768  2010-12-31     -30.0       85.0  0.000010  29.111805  24.655510   \n",
       "4268769  2010-12-31     -30.0       87.5  0.000006  27.833050  25.088104   \n",
       "4268770  2010-12-31     -30.0       90.0  0.000007  15.843884  24.510345   \n",
       "\n",
       "            u_850      v_200     v_850        ttr        sst  lsm  \\\n",
       "0       -3.323872   1.687164 -1.823624 -247.54074    0.00000  0.0   \n",
       "1       -2.844494   1.060593 -1.991425 -240.00592    0.00000  0.0   \n",
       "2       -2.125244   3.280617 -1.931789 -223.76889    0.00000  0.0   \n",
       "3       -1.122395   5.743889 -1.243538 -235.55556    0.00000  0.0   \n",
       "4       -1.362953   6.514030 -0.954163 -254.03260    0.00000  0.0   \n",
       "...           ...        ...       ...        ...        ...  ...   \n",
       "4268766 -3.653679  -1.221291  1.515594 -273.34204  296.89227  0.0   \n",
       "4268767 -2.866638  -6.724304  0.861771 -280.37018  296.03314  0.0   \n",
       "4268768 -2.809170 -10.138817  0.051220 -281.05167  295.36078  0.0   \n",
       "4268769 -2.730087 -11.036507  0.666927 -280.05610  295.10638  0.0   \n",
       "4268770 -3.213837 -10.213325 -0.098499 -279.40427  294.44766  0.0   \n",
       "\n",
       "         Real_tom_lsm  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "4268766           0.0  \n",
       "4268767           0.0  \n",
       "4268768           0.0  \n",
       "4268769           0.0  \n",
       "4268770           0.0  \n",
       "\n",
       "[4268771 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data set\n",
    "training_set_wt = training_set.drop(columns=['Unnamed: 0'])\n",
    "training_set_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e35108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>73.016390</td>\n",
       "      <td>-5.760780</td>\n",
       "      <td>-4.216808</td>\n",
       "      <td>6.860649</td>\n",
       "      <td>-4.352928</td>\n",
       "      <td>-212.59741</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>74.569660</td>\n",
       "      <td>-4.942451</td>\n",
       "      <td>-3.857407</td>\n",
       "      <td>6.459419</td>\n",
       "      <td>-3.991157</td>\n",
       "      <td>-198.23593</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>80.080090</td>\n",
       "      <td>-3.848740</td>\n",
       "      <td>-3.175144</td>\n",
       "      <td>6.303680</td>\n",
       "      <td>-3.446140</td>\n",
       "      <td>-195.83296</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>83.676704</td>\n",
       "      <td>0.330811</td>\n",
       "      <td>-2.526569</td>\n",
       "      <td>7.235268</td>\n",
       "      <td>-2.307594</td>\n",
       "      <td>-191.47444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>76.225440</td>\n",
       "      <td>3.678749</td>\n",
       "      <td>-1.027561</td>\n",
       "      <td>7.020271</td>\n",
       "      <td>-0.077572</td>\n",
       "      <td>-191.98111</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688397</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>70.662056</td>\n",
       "      <td>23.560066</td>\n",
       "      <td>1.655861</td>\n",
       "      <td>9.690376</td>\n",
       "      <td>3.621418</td>\n",
       "      <td>-271.57556</td>\n",
       "      <td>296.77530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688398</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>51.213654</td>\n",
       "      <td>22.381706</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>9.860390</td>\n",
       "      <td>-0.099480</td>\n",
       "      <td>-269.94592</td>\n",
       "      <td>296.44290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688399</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>46.678970</td>\n",
       "      <td>22.464828</td>\n",
       "      <td>0.851299</td>\n",
       "      <td>7.661758</td>\n",
       "      <td>-0.725330</td>\n",
       "      <td>-270.18890</td>\n",
       "      <td>295.73486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688400</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>59.362090</td>\n",
       "      <td>22.364807</td>\n",
       "      <td>0.543045</td>\n",
       "      <td>5.595253</td>\n",
       "      <td>-1.542034</td>\n",
       "      <td>-264.07333</td>\n",
       "      <td>295.24792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688401</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>65.915980</td>\n",
       "      <td>23.052147</td>\n",
       "      <td>0.048565</td>\n",
       "      <td>1.080147</td>\n",
       "      <td>-1.203087</td>\n",
       "      <td>-259.79480</td>\n",
       "      <td>295.79680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688402 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  latitude  longitude        vo          r      u_200  \\\n",
       "0       2011-01-01       0.0       20.0  0.000003  73.016390  -5.760780   \n",
       "1       2011-01-01       0.0       22.5  0.000003  74.569660  -4.942451   \n",
       "2       2011-01-01       0.0       25.0  0.000004  80.080090  -3.848740   \n",
       "3       2011-01-01       0.0       27.5  0.000012  83.676704   0.330811   \n",
       "4       2011-01-01       0.0       30.0  0.000011  76.225440   3.678749   \n",
       "...            ...       ...        ...       ...        ...        ...   \n",
       "688397  2015-12-31     -30.0       80.0  0.000014  70.662056  23.560066   \n",
       "688398  2015-12-31     -30.0       82.5 -0.000006  51.213654  22.381706   \n",
       "688399  2015-12-31     -30.0       85.0  0.000009  46.678970  22.464828   \n",
       "688400  2015-12-31     -30.0       87.5  0.000002  59.362090  22.364807   \n",
       "688401  2015-12-31     -30.0       90.0  0.000014  65.915980  23.052147   \n",
       "\n",
       "           u_850     v_200     v_850        ttr        sst  lsm  Real_tom_lsm  \n",
       "0      -4.216808  6.860649 -4.352928 -212.59741    0.00000  0.0           0.0  \n",
       "1      -3.857407  6.459419 -3.991157 -198.23593    0.00000  0.0           0.0  \n",
       "2      -3.175144  6.303680 -3.446140 -195.83296    0.00000  0.0           0.0  \n",
       "3      -2.526569  7.235268 -2.307594 -191.47444    0.00000  0.0           0.0  \n",
       "4      -1.027561  7.020271 -0.077572 -191.98111    0.00000  0.0           0.0  \n",
       "...          ...       ...       ...        ...        ...  ...           ...  \n",
       "688397  1.655861  9.690376  3.621418 -271.57556  296.77530  0.0           0.0  \n",
       "688398  0.321705  9.860390 -0.099480 -269.94592  296.44290  0.0           0.0  \n",
       "688399  0.851299  7.661758 -0.725330 -270.18890  295.73486  0.0           0.0  \n",
       "688400  0.543045  5.595253 -1.542034 -264.07333  295.24792  0.0           0.0  \n",
       "688401  0.048565  1.080147 -1.203087 -259.79480  295.79680  0.0           0.0  \n",
       "\n",
       "[688402 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation data set\n",
    "validation_set_wt = validation_set.drop(columns=['Unnamed: 0'])\n",
    "validation_set_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bc8fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>80.796135</td>\n",
       "      <td>-2.052292</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>4.996910</td>\n",
       "      <td>-1.678764</td>\n",
       "      <td>-272.04962</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>77.748420</td>\n",
       "      <td>-4.445312</td>\n",
       "      <td>0.740505</td>\n",
       "      <td>7.517281</td>\n",
       "      <td>0.792618</td>\n",
       "      <td>-250.63333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>71.178825</td>\n",
       "      <td>-3.778427</td>\n",
       "      <td>1.056324</td>\n",
       "      <td>9.333221</td>\n",
       "      <td>0.688252</td>\n",
       "      <td>-229.52519</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>73.585754</td>\n",
       "      <td>-4.695709</td>\n",
       "      <td>1.236446</td>\n",
       "      <td>9.589882</td>\n",
       "      <td>0.555519</td>\n",
       "      <td>-240.80815</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>72.382780</td>\n",
       "      <td>-4.002563</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>5.410950</td>\n",
       "      <td>-1.086350</td>\n",
       "      <td>-262.45557</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539482</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.637233</td>\n",
       "      <td>33.277840</td>\n",
       "      <td>5.379345</td>\n",
       "      <td>-0.286896</td>\n",
       "      <td>5.558327</td>\n",
       "      <td>-277.60870</td>\n",
       "      <td>294.14987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539483</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>23.660923</td>\n",
       "      <td>34.272537</td>\n",
       "      <td>6.438683</td>\n",
       "      <td>-13.026535</td>\n",
       "      <td>2.857349</td>\n",
       "      <td>-270.80573</td>\n",
       "      <td>294.23798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539484</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>46.051540</td>\n",
       "      <td>35.755882</td>\n",
       "      <td>7.248966</td>\n",
       "      <td>-18.870102</td>\n",
       "      <td>-3.349407</td>\n",
       "      <td>-249.43092</td>\n",
       "      <td>294.26890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539485</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>55.855648</td>\n",
       "      <td>34.069664</td>\n",
       "      <td>6.349327</td>\n",
       "      <td>-18.801796</td>\n",
       "      <td>-8.172478</td>\n",
       "      <td>-239.36870</td>\n",
       "      <td>294.36630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539486</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>61.602300</td>\n",
       "      <td>29.167267</td>\n",
       "      <td>4.805676</td>\n",
       "      <td>-15.093590</td>\n",
       "      <td>-9.708778</td>\n",
       "      <td>-251.60574</td>\n",
       "      <td>293.74924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539487 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  latitude  longitude        vo          r      u_200  \\\n",
       "0       2016-01-01       0.0       20.0  0.000011  80.796135  -2.052292   \n",
       "1       2016-01-01       0.0       22.5  0.000011  77.748420  -4.445312   \n",
       "2       2016-01-01       0.0       25.0 -0.000001  71.178825  -3.778427   \n",
       "3       2016-01-01       0.0       27.5 -0.000005  73.585754  -4.695709   \n",
       "4       2016-01-01       0.0       30.0 -0.000016  72.382780  -4.002563   \n",
       "...            ...       ...        ...       ...        ...        ...   \n",
       "539482  2019-12-01     -30.0       80.0  0.000006   2.637233  33.277840   \n",
       "539483  2019-12-01     -30.0       82.5 -0.000020  23.660923  34.272537   \n",
       "539484  2019-12-01     -30.0       85.0 -0.000019  46.051540  35.755882   \n",
       "539485  2019-12-01     -30.0       87.5 -0.000014  55.855648  34.069664   \n",
       "539486  2019-12-01     -30.0       90.0  0.000006  61.602300  29.167267   \n",
       "\n",
       "           u_850      v_200     v_850        ttr        sst  lsm  Real_tom_lsm  \n",
       "0       0.008678   4.996910 -1.678764 -272.04962    0.00000  0.0           0.0  \n",
       "1       0.740505   7.517281  0.792618 -250.63333    0.00000  0.0           0.0  \n",
       "2       1.056324   9.333221  0.688252 -229.52519    0.00000  0.0           0.0  \n",
       "3       1.236446   9.589882  0.555519 -240.80815    0.00000  0.0           0.0  \n",
       "4       0.734211   5.410950 -1.086350 -262.45557    0.00000  0.0           0.0  \n",
       "...          ...        ...       ...        ...        ...  ...           ...  \n",
       "539482  5.379345  -0.286896  5.558327 -277.60870  294.14987  0.0           0.0  \n",
       "539483  6.438683 -13.026535  2.857349 -270.80573  294.23798  0.0           0.0  \n",
       "539484  7.248966 -18.870102 -3.349407 -249.43092  294.26890  0.0           0.0  \n",
       "539485  6.349327 -18.801796 -8.172478 -239.36870  294.36630  0.0           0.0  \n",
       "539486  4.805676 -15.093590 -9.708778 -251.60574  293.74924  0.0           0.0  \n",
       "\n",
       "[539487 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data set\n",
    "test_set_wt = test_set.drop(columns=['Unnamed: 0'])\n",
    "test_set_wt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da2f63",
   "metadata": {},
   "source": [
    "# Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dfe51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#scaled_x_training = scaler.fit_transform(x_training)\n",
    "#df = pd.DataFrame(StandardScaler().fit_transform(x_training))\n",
    "\n",
    "X_train_stand = training_set_wt.copy()\n",
    "X_valid_stand = validation_set_wt.copy()\n",
    "X_test_stand = test_set_wt.copy()\n",
    "\n",
    "\n",
    "num_cols = [ 'vo', 'r', 'u_200', 'u_850', 'v_200','v_850', 'ttr','sst']\n",
    "\n",
    "# apply standardization on numerical features\n",
    "for i in num_cols:\n",
    "    \n",
    "    # fit on training data column\n",
    "    scale = StandardScaler().fit(X_train_stand[[i]])\n",
    "    \n",
    "    # transform the training data column\n",
    "    X_train_stand[i] = scale.transform(X_train_stand[[i]])\n",
    "    \n",
    "    # transform the training data column\n",
    "    X_valid_stand[i] = scale.transform(X_valid_stand[[i]])   \n",
    "\n",
    "    # transform the testing data column\n",
    "    X_test_stand[i] = scale.transform(X_test_stand[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c96795ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.427113</td>\n",
       "      <td>1.375089</td>\n",
       "      <td>-0.367070</td>\n",
       "      <td>-0.185388</td>\n",
       "      <td>0.412678</td>\n",
       "      <td>-0.721641</td>\n",
       "      <td>0.460973</td>\n",
       "      <td>-1.588255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.219114</td>\n",
       "      <td>1.372826</td>\n",
       "      <td>-0.408894</td>\n",
       "      <td>-0.087275</td>\n",
       "      <td>0.339019</td>\n",
       "      <td>-0.767529</td>\n",
       "      <td>0.678441</td>\n",
       "      <td>-1.588255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.421190</td>\n",
       "      <td>1.275581</td>\n",
       "      <td>-0.548176</td>\n",
       "      <td>0.059933</td>\n",
       "      <td>0.600002</td>\n",
       "      <td>-0.751221</td>\n",
       "      <td>1.147069</td>\n",
       "      <td>-1.588255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.618823</td>\n",
       "      <td>1.330632</td>\n",
       "      <td>-0.686810</td>\n",
       "      <td>0.265184</td>\n",
       "      <td>0.889582</td>\n",
       "      <td>-0.563007</td>\n",
       "      <td>0.806886</td>\n",
       "      <td>-1.588255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.639442</td>\n",
       "      <td>1.013693</td>\n",
       "      <td>-0.796831</td>\n",
       "      <td>0.215949</td>\n",
       "      <td>0.980119</td>\n",
       "      <td>-0.483872</td>\n",
       "      <td>0.273606</td>\n",
       "      <td>-1.588255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268766</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.944351</td>\n",
       "      <td>-0.747649</td>\n",
       "      <td>0.935328</td>\n",
       "      <td>-0.252889</td>\n",
       "      <td>0.070764</td>\n",
       "      <td>0.191525</td>\n",
       "      <td>-0.283698</td>\n",
       "      <td>0.612925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268767</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.453259</td>\n",
       "      <td>-0.709517</td>\n",
       "      <td>0.884757</td>\n",
       "      <td>-0.091807</td>\n",
       "      <td>-0.576164</td>\n",
       "      <td>0.012726</td>\n",
       "      <td>-0.486542</td>\n",
       "      <td>0.606555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268768</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.636774</td>\n",
       "      <td>-0.656614</td>\n",
       "      <td>0.911720</td>\n",
       "      <td>-0.080045</td>\n",
       "      <td>-0.977570</td>\n",
       "      <td>-0.208933</td>\n",
       "      <td>-0.506211</td>\n",
       "      <td>0.601571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268769</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.368231</td>\n",
       "      <td>-0.706915</td>\n",
       "      <td>0.936041</td>\n",
       "      <td>-0.063859</td>\n",
       "      <td>-1.083102</td>\n",
       "      <td>-0.040557</td>\n",
       "      <td>-0.477477</td>\n",
       "      <td>0.599684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268770</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.462658</td>\n",
       "      <td>-1.178526</td>\n",
       "      <td>0.903559</td>\n",
       "      <td>-0.162867</td>\n",
       "      <td>-0.986329</td>\n",
       "      <td>-0.249876</td>\n",
       "      <td>-0.458664</td>\n",
       "      <td>0.594801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4268771 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time  latitude  longitude        vo         r     u_200  \\\n",
       "0        1980-01-01       0.0       20.0  0.427113  1.375089 -0.367070   \n",
       "1        1980-01-01       0.0       22.5  0.219114  1.372826 -0.408894   \n",
       "2        1980-01-01       0.0       25.0  0.421190  1.275581 -0.548176   \n",
       "3        1980-01-01       0.0       27.5  0.618823  1.330632 -0.686810   \n",
       "4        1980-01-01       0.0       30.0  0.639442  1.013693 -0.796831   \n",
       "...             ...       ...        ...       ...       ...       ...   \n",
       "4268766  2010-12-31     -30.0       80.0  0.944351 -0.747649  0.935328   \n",
       "4268767  2010-12-31     -30.0       82.5 -0.453259 -0.709517  0.884757   \n",
       "4268768  2010-12-31     -30.0       85.0  0.636774 -0.656614  0.911720   \n",
       "4268769  2010-12-31     -30.0       87.5  0.368231 -0.706915  0.936041   \n",
       "4268770  2010-12-31     -30.0       90.0  0.462658 -1.178526  0.903559   \n",
       "\n",
       "            u_850     v_200     v_850       ttr       sst  lsm  Real_tom_lsm  \n",
       "0       -0.185388  0.412678 -0.721641  0.460973 -1.588255  0.0           0.0  \n",
       "1       -0.087275  0.339019 -0.767529  0.678441 -1.588255  0.0           0.0  \n",
       "2        0.059933  0.600002 -0.751221  1.147069 -1.588255  0.0           0.0  \n",
       "3        0.265184  0.889582 -0.563007  0.806886 -1.588255  0.0           0.0  \n",
       "4        0.215949  0.980119 -0.483872  0.273606 -1.588255  0.0           0.0  \n",
       "...           ...       ...       ...       ...       ...  ...           ...  \n",
       "4268766 -0.252889  0.070764  0.191525 -0.283698  0.612925  0.0           0.0  \n",
       "4268767 -0.091807 -0.576164  0.012726 -0.486542  0.606555  0.0           0.0  \n",
       "4268768 -0.080045 -0.977570 -0.208933 -0.506211  0.601571  0.0           0.0  \n",
       "4268769 -0.063859 -1.083102 -0.040557 -0.477477  0.599684  0.0           0.0  \n",
       "4268770 -0.162867 -0.986329 -0.249876 -0.458664  0.594801  0.0           0.0  \n",
       "\n",
       "[4268771 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "075b7f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============> data_images_training_set is extracted and saved\n"
     ]
    }
   ],
   "source": [
    "#training set has 11323 days\n",
    "data_images_training_set = np.zeros( (11323,13,29,8), dtype=np.float32 )\n",
    "\n",
    "for days in range(0,11323):\n",
    "    a=X_train_stand.iloc[377*days:377*(days+1),3:11]\n",
    "    for per in range(0,13):\n",
    "        for atr in range(0,29):\n",
    "            data_images_training_set[days,per,atr,:] = a.iloc[(per*29)+atr,:]\n",
    "            \n",
    "type(data_images_training_set)\n",
    "import os  \n",
    "os.makedirs('images/real_images/standard_images', exist_ok=True)\n",
    "np.save('images/real_images/standard_images/data_images_training_set', data_images_training_set)\n",
    "print(\"==============> data_images_training_set is extracted and saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c739ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============> data_images_validation_set is extracted and saved\n"
     ]
    }
   ],
   "source": [
    "#validation set has 1826 days\n",
    "data_images_validation_set = np.zeros( (1826,13,29,8), dtype=np.float32 )\n",
    "\n",
    "for days in range(0,1826):\n",
    "    b=X_valid_stand.iloc[377*days:377*(days+1),3:11]\n",
    "    for per in range(0,13):\n",
    "        for atr in range(0,29):\n",
    "            data_images_validation_set[days,per,atr,:] = a.iloc[(per*29)+atr,:]\n",
    "                    \n",
    "\n",
    "np.save('images/real_images/standard_images/data_images_validation_set', data_images_validation_set)\n",
    "\n",
    "print(\"==============> data_images_validation_set is extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "050fd9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============> data_images_test_set is extracted and saved\n"
     ]
    }
   ],
   "source": [
    "#test set has 1431 days\n",
    "data_images_test_set = np.zeros( (1431,13,29,8), dtype=np.float32 )\n",
    "\n",
    "for days in range(0,1431):\n",
    "    b=X_test_stand.iloc[377*days:377*(days+1),3:11]\n",
    "    for per in range(0,13):\n",
    "        for atr in range(0,29):\n",
    "            data_images_test_set[days,per,atr,:] = a.iloc[(per*29)+atr,:]\n",
    "                    \n",
    "\n",
    "np.save('images/real_images/standard_images/data_images_test_set', data_images_test_set)\n",
    "#loaded_array = np.load('file_name.npy')\n",
    "print(\"==============> data_images_test_set is extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d42385b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images_training_set = np.load('images/real_images/standard_images/data_images_training_set.npy')\n",
    "data_images_validation_set = np.load('images/real_images/standard_images/data_images_validation_set.npy')\n",
    "data_images_test_set = np.load('images/real_images/standard_images/data_images_test_set.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5349b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.3699198 ,  1.4375393 , -0.5122167 , ..., -1.479522  ,\n",
       "           1.014268  , -1.5882549 ],\n",
       "         [ 0.5395018 ,  1.3120407 , -0.53472614, ..., -1.4367177 ,\n",
       "           1.0395807 , -1.5882549 ],\n",
       "         [ 0.69605756,  1.2094198 , -0.5475988 , ..., -1.5780278 ,\n",
       "           0.6318392 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.056734  ,  1.0967445 , -1.7741865 , ..., -0.258732  ,\n",
       "           0.6202094 ,  0.64691883],\n",
       "         [ 0.77006793,  0.88277596, -1.7575761 , ..., -0.59422547,\n",
       "           0.37340927,  0.6470593 ],\n",
       "         [ 0.6897662 ,  0.6141815 , -1.7871565 , ..., -0.9833871 ,\n",
       "           0.01475467,  0.6485754 ]],\n",
       "\n",
       "        [[-0.00547387,  1.2520872 , -0.75133353, ..., -1.2649589 ,\n",
       "           1.4598074 , -1.5882549 ],\n",
       "         [ 0.1731918 ,  1.1778677 , -0.6965681 , ..., -1.3496872 ,\n",
       "           1.0308584 , -1.5882549 ],\n",
       "         [ 0.2974    ,  1.2267771 , -0.6779615 , ..., -1.3143802 ,\n",
       "           1.3000633 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-0.2796858 ,  1.1767899 , -1.4940785 , ..., -0.1472969 ,\n",
       "           1.6638489 ,  0.64618814],\n",
       "         [-0.35191372,  1.1909208 , -1.616141  , ..., -0.73146605,\n",
       "           1.253029  ,  0.64675516],\n",
       "         [ 0.08551692,  1.120073  , -1.6485579 , ..., -1.353379  ,\n",
       "           0.556414  ,  0.64832795]],\n",
       "\n",
       "        [[-0.03236887,  1.1032389 , -0.84543836, ..., -0.8039201 ,\n",
       "           1.5978309 , -1.5882549 ],\n",
       "         [-0.10388847,  1.0822607 , -0.8415235 , ..., -1.0835985 ,\n",
       "           1.7835716 , -1.5882549 ],\n",
       "         [-0.0706263 ,  1.0551329 , -0.78412914, ..., -0.8383038 ,\n",
       "           1.6768476 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-1.5780797 ,  0.8127803 , -1.4838691 , ...,  0.10041277,\n",
       "           0.8516161 ,  0.6452373 ],\n",
       "         [-1.3558266 ,  1.0484176 , -1.4596366 , ..., -0.70004815,\n",
       "           1.3301649 ,  0.64397085],\n",
       "         [-1.0309364 ,  1.2628572 , -1.3829755 , ..., -1.6003219 ,\n",
       "           1.4892248 ,  0.64502007]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9014507 ,  1.265258  , -0.02086635, ..., -1.6976206 ,\n",
       "           1.3469263 , -1.5882549 ],\n",
       "         [ 0.5319456 ,  1.1570402 , -0.2477222 , ..., -1.9658478 ,\n",
       "           0.6109733 , -1.5882549 ],\n",
       "         [ 0.7679294 ,  1.2885116 , -0.362972  , ..., -1.9669015 ,\n",
       "           0.5413632 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.0423845 , -0.11361935,  0.51154596, ..., -0.61837435,\n",
       "          -0.72307956,  0.60708004],\n",
       "         [ 1.9068193 , -0.01136441,  0.47339132, ..., -0.10370702,\n",
       "          -0.7680617 ,  0.60846305],\n",
       "         [ 1.3718673 , -0.37730694,  0.41628996, ...,  0.4352751 ,\n",
       "          -0.82911956,  0.6085289 ]],\n",
       "\n",
       "        [[-1.1314641 ,  1.3619165 ,  0.28881046, ..., -1.4127597 ,\n",
       "           1.9133856 , -1.5882549 ],\n",
       "         [ 0.71841073,  1.3142242 ,  0.20471646, ..., -2.255275  ,\n",
       "           2.074327  , -1.5882549 ],\n",
       "         [ 0.34093875,  1.3806069 ,  0.06552371, ..., -1.6197774 ,\n",
       "           2.395184  , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.18806082, -0.07490955,  0.8205622 , ..., -0.31062362,\n",
       "          -0.6450894 ,  0.6040813 ],\n",
       "         [-0.0733876 , -0.28615922,  0.7928203 , ..., -0.04285748,\n",
       "          -0.68049264,  0.6000079 ],\n",
       "         [ 0.07011276, -0.67910314,  0.7436807 , ...,  0.0178189 ,\n",
       "          -0.76498246,  0.59647983]],\n",
       "\n",
       "        [[-2.2932813 ,  0.77748924,  0.8988365 , ..., -1.4134598 ,\n",
       "           1.1827351 , -1.5882549 ],\n",
       "         [-0.22785147,  0.8926288 ,  0.8168112 , ..., -1.9391317 ,\n",
       "           2.6602843 , -1.5882549 ],\n",
       "         [ 1.1291623 ,  1.1381904 ,  0.7885331 , ..., -1.7031996 ,\n",
       "           2.4892519 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.6367741 , -0.6566135 ,  0.9117203 , ..., -0.20893301,\n",
       "          -0.5062108 ,  0.6015705 ],\n",
       "         [ 0.36823073, -0.7069152 ,  0.93604106, ..., -0.04055723,\n",
       "          -0.4774769 ,  0.59968436],\n",
       "         [ 0.46265805, -1.1785263 ,  0.90355897, ..., -0.2498763 ,\n",
       "          -0.45866397,  0.5948006 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.3699198 ,  1.4375393 , -0.5122167 , ..., -1.479522  ,\n",
       "           1.014268  , -1.5882549 ],\n",
       "         [ 0.5395018 ,  1.3120407 , -0.53472614, ..., -1.4367177 ,\n",
       "           1.0395807 , -1.5882549 ],\n",
       "         [ 0.69605756,  1.2094198 , -0.5475988 , ..., -1.5780278 ,\n",
       "           0.6318392 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.056734  ,  1.0967445 , -1.7741865 , ..., -0.258732  ,\n",
       "           0.6202094 ,  0.64691883],\n",
       "         [ 0.77006793,  0.88277596, -1.7575761 , ..., -0.59422547,\n",
       "           0.37340927,  0.6470593 ],\n",
       "         [ 0.6897662 ,  0.6141815 , -1.7871565 , ..., -0.9833871 ,\n",
       "           0.01475467,  0.6485754 ]],\n",
       "\n",
       "        [[-0.00547387,  1.2520872 , -0.75133353, ..., -1.2649589 ,\n",
       "           1.4598074 , -1.5882549 ],\n",
       "         [ 0.1731918 ,  1.1778677 , -0.6965681 , ..., -1.3496872 ,\n",
       "           1.0308584 , -1.5882549 ],\n",
       "         [ 0.2974    ,  1.2267771 , -0.6779615 , ..., -1.3143802 ,\n",
       "           1.3000633 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-0.2796858 ,  1.1767899 , -1.4940785 , ..., -0.1472969 ,\n",
       "           1.6638489 ,  0.64618814],\n",
       "         [-0.35191372,  1.1909208 , -1.616141  , ..., -0.73146605,\n",
       "           1.253029  ,  0.64675516],\n",
       "         [ 0.08551692,  1.120073  , -1.6485579 , ..., -1.353379  ,\n",
       "           0.556414  ,  0.64832795]],\n",
       "\n",
       "        [[-0.03236887,  1.1032389 , -0.84543836, ..., -0.8039201 ,\n",
       "           1.5978309 , -1.5882549 ],\n",
       "         [-0.10388847,  1.0822607 , -0.8415235 , ..., -1.0835985 ,\n",
       "           1.7835716 , -1.5882549 ],\n",
       "         [-0.0706263 ,  1.0551329 , -0.78412914, ..., -0.8383038 ,\n",
       "           1.6768476 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-1.5780797 ,  0.8127803 , -1.4838691 , ...,  0.10041277,\n",
       "           0.8516161 ,  0.6452373 ],\n",
       "         [-1.3558266 ,  1.0484176 , -1.4596366 , ..., -0.70004815,\n",
       "           1.3301649 ,  0.64397085],\n",
       "         [-1.0309364 ,  1.2628572 , -1.3829755 , ..., -1.6003219 ,\n",
       "           1.4892248 ,  0.64502007]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9014507 ,  1.265258  , -0.02086635, ..., -1.6976206 ,\n",
       "           1.3469263 , -1.5882549 ],\n",
       "         [ 0.5319456 ,  1.1570402 , -0.2477222 , ..., -1.9658478 ,\n",
       "           0.6109733 , -1.5882549 ],\n",
       "         [ 0.7679294 ,  1.2885116 , -0.362972  , ..., -1.9669015 ,\n",
       "           0.5413632 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.0423845 , -0.11361935,  0.51154596, ..., -0.61837435,\n",
       "          -0.72307956,  0.60708004],\n",
       "         [ 1.9068193 , -0.01136441,  0.47339132, ..., -0.10370702,\n",
       "          -0.7680617 ,  0.60846305],\n",
       "         [ 1.3718673 , -0.37730694,  0.41628996, ...,  0.4352751 ,\n",
       "          -0.82911956,  0.6085289 ]],\n",
       "\n",
       "        [[-1.1314641 ,  1.3619165 ,  0.28881046, ..., -1.4127597 ,\n",
       "           1.9133856 , -1.5882549 ],\n",
       "         [ 0.71841073,  1.3142242 ,  0.20471646, ..., -2.255275  ,\n",
       "           2.074327  , -1.5882549 ],\n",
       "         [ 0.34093875,  1.3806069 ,  0.06552371, ..., -1.6197774 ,\n",
       "           2.395184  , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.18806082, -0.07490955,  0.8205622 , ..., -0.31062362,\n",
       "          -0.6450894 ,  0.6040813 ],\n",
       "         [-0.0733876 , -0.28615922,  0.7928203 , ..., -0.04285748,\n",
       "          -0.68049264,  0.6000079 ],\n",
       "         [ 0.07011276, -0.67910314,  0.7436807 , ...,  0.0178189 ,\n",
       "          -0.76498246,  0.59647983]],\n",
       "\n",
       "        [[-2.2932813 ,  0.77748924,  0.8988365 , ..., -1.4134598 ,\n",
       "           1.1827351 , -1.5882549 ],\n",
       "         [-0.22785147,  0.8926288 ,  0.8168112 , ..., -1.9391317 ,\n",
       "           2.6602843 , -1.5882549 ],\n",
       "         [ 1.1291623 ,  1.1381904 ,  0.7885331 , ..., -1.7031996 ,\n",
       "           2.4892519 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.6367741 , -0.6566135 ,  0.9117203 , ..., -0.20893301,\n",
       "          -0.5062108 ,  0.6015705 ],\n",
       "         [ 0.36823073, -0.7069152 ,  0.93604106, ..., -0.04055723,\n",
       "          -0.4774769 ,  0.59968436],\n",
       "         [ 0.46265805, -1.1785263 ,  0.90355897, ..., -0.2498763 ,\n",
       "          -0.45866397,  0.5948006 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.3699198 ,  1.4375393 , -0.5122167 , ..., -1.479522  ,\n",
       "           1.014268  , -1.5882549 ],\n",
       "         [ 0.5395018 ,  1.3120407 , -0.53472614, ..., -1.4367177 ,\n",
       "           1.0395807 , -1.5882549 ],\n",
       "         [ 0.69605756,  1.2094198 , -0.5475988 , ..., -1.5780278 ,\n",
       "           0.6318392 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.056734  ,  1.0967445 , -1.7741865 , ..., -0.258732  ,\n",
       "           0.6202094 ,  0.64691883],\n",
       "         [ 0.77006793,  0.88277596, -1.7575761 , ..., -0.59422547,\n",
       "           0.37340927,  0.6470593 ],\n",
       "         [ 0.6897662 ,  0.6141815 , -1.7871565 , ..., -0.9833871 ,\n",
       "           0.01475467,  0.6485754 ]],\n",
       "\n",
       "        [[-0.00547387,  1.2520872 , -0.75133353, ..., -1.2649589 ,\n",
       "           1.4598074 , -1.5882549 ],\n",
       "         [ 0.1731918 ,  1.1778677 , -0.6965681 , ..., -1.3496872 ,\n",
       "           1.0308584 , -1.5882549 ],\n",
       "         [ 0.2974    ,  1.2267771 , -0.6779615 , ..., -1.3143802 ,\n",
       "           1.3000633 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-0.2796858 ,  1.1767899 , -1.4940785 , ..., -0.1472969 ,\n",
       "           1.6638489 ,  0.64618814],\n",
       "         [-0.35191372,  1.1909208 , -1.616141  , ..., -0.73146605,\n",
       "           1.253029  ,  0.64675516],\n",
       "         [ 0.08551692,  1.120073  , -1.6485579 , ..., -1.353379  ,\n",
       "           0.556414  ,  0.64832795]],\n",
       "\n",
       "        [[-0.03236887,  1.1032389 , -0.84543836, ..., -0.8039201 ,\n",
       "           1.5978309 , -1.5882549 ],\n",
       "         [-0.10388847,  1.0822607 , -0.8415235 , ..., -1.0835985 ,\n",
       "           1.7835716 , -1.5882549 ],\n",
       "         [-0.0706263 ,  1.0551329 , -0.78412914, ..., -0.8383038 ,\n",
       "           1.6768476 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-1.5780797 ,  0.8127803 , -1.4838691 , ...,  0.10041277,\n",
       "           0.8516161 ,  0.6452373 ],\n",
       "         [-1.3558266 ,  1.0484176 , -1.4596366 , ..., -0.70004815,\n",
       "           1.3301649 ,  0.64397085],\n",
       "         [-1.0309364 ,  1.2628572 , -1.3829755 , ..., -1.6003219 ,\n",
       "           1.4892248 ,  0.64502007]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9014507 ,  1.265258  , -0.02086635, ..., -1.6976206 ,\n",
       "           1.3469263 , -1.5882549 ],\n",
       "         [ 0.5319456 ,  1.1570402 , -0.2477222 , ..., -1.9658478 ,\n",
       "           0.6109733 , -1.5882549 ],\n",
       "         [ 0.7679294 ,  1.2885116 , -0.362972  , ..., -1.9669015 ,\n",
       "           0.5413632 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.0423845 , -0.11361935,  0.51154596, ..., -0.61837435,\n",
       "          -0.72307956,  0.60708004],\n",
       "         [ 1.9068193 , -0.01136441,  0.47339132, ..., -0.10370702,\n",
       "          -0.7680617 ,  0.60846305],\n",
       "         [ 1.3718673 , -0.37730694,  0.41628996, ...,  0.4352751 ,\n",
       "          -0.82911956,  0.6085289 ]],\n",
       "\n",
       "        [[-1.1314641 ,  1.3619165 ,  0.28881046, ..., -1.4127597 ,\n",
       "           1.9133856 , -1.5882549 ],\n",
       "         [ 0.71841073,  1.3142242 ,  0.20471646, ..., -2.255275  ,\n",
       "           2.074327  , -1.5882549 ],\n",
       "         [ 0.34093875,  1.3806069 ,  0.06552371, ..., -1.6197774 ,\n",
       "           2.395184  , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.18806082, -0.07490955,  0.8205622 , ..., -0.31062362,\n",
       "          -0.6450894 ,  0.6040813 ],\n",
       "         [-0.0733876 , -0.28615922,  0.7928203 , ..., -0.04285748,\n",
       "          -0.68049264,  0.6000079 ],\n",
       "         [ 0.07011276, -0.67910314,  0.7436807 , ...,  0.0178189 ,\n",
       "          -0.76498246,  0.59647983]],\n",
       "\n",
       "        [[-2.2932813 ,  0.77748924,  0.8988365 , ..., -1.4134598 ,\n",
       "           1.1827351 , -1.5882549 ],\n",
       "         [-0.22785147,  0.8926288 ,  0.8168112 , ..., -1.9391317 ,\n",
       "           2.6602843 , -1.5882549 ],\n",
       "         [ 1.1291623 ,  1.1381904 ,  0.7885331 , ..., -1.7031996 ,\n",
       "           2.4892519 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.6367741 , -0.6566135 ,  0.9117203 , ..., -0.20893301,\n",
       "          -0.5062108 ,  0.6015705 ],\n",
       "         [ 0.36823073, -0.7069152 ,  0.93604106, ..., -0.04055723,\n",
       "          -0.4774769 ,  0.59968436],\n",
       "         [ 0.46265805, -1.1785263 ,  0.90355897, ..., -0.2498763 ,\n",
       "          -0.45866397,  0.5948006 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0.3699198 ,  1.4375393 , -0.5122167 , ..., -1.479522  ,\n",
       "           1.014268  , -1.5882549 ],\n",
       "         [ 0.5395018 ,  1.3120407 , -0.53472614, ..., -1.4367177 ,\n",
       "           1.0395807 , -1.5882549 ],\n",
       "         [ 0.69605756,  1.2094198 , -0.5475988 , ..., -1.5780278 ,\n",
       "           0.6318392 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.056734  ,  1.0967445 , -1.7741865 , ..., -0.258732  ,\n",
       "           0.6202094 ,  0.64691883],\n",
       "         [ 0.77006793,  0.88277596, -1.7575761 , ..., -0.59422547,\n",
       "           0.37340927,  0.6470593 ],\n",
       "         [ 0.6897662 ,  0.6141815 , -1.7871565 , ..., -0.9833871 ,\n",
       "           0.01475467,  0.6485754 ]],\n",
       "\n",
       "        [[-0.00547387,  1.2520872 , -0.75133353, ..., -1.2649589 ,\n",
       "           1.4598074 , -1.5882549 ],\n",
       "         [ 0.1731918 ,  1.1778677 , -0.6965681 , ..., -1.3496872 ,\n",
       "           1.0308584 , -1.5882549 ],\n",
       "         [ 0.2974    ,  1.2267771 , -0.6779615 , ..., -1.3143802 ,\n",
       "           1.3000633 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-0.2796858 ,  1.1767899 , -1.4940785 , ..., -0.1472969 ,\n",
       "           1.6638489 ,  0.64618814],\n",
       "         [-0.35191372,  1.1909208 , -1.616141  , ..., -0.73146605,\n",
       "           1.253029  ,  0.64675516],\n",
       "         [ 0.08551692,  1.120073  , -1.6485579 , ..., -1.353379  ,\n",
       "           0.556414  ,  0.64832795]],\n",
       "\n",
       "        [[-0.03236887,  1.1032389 , -0.84543836, ..., -0.8039201 ,\n",
       "           1.5978309 , -1.5882549 ],\n",
       "         [-0.10388847,  1.0822607 , -0.8415235 , ..., -1.0835985 ,\n",
       "           1.7835716 , -1.5882549 ],\n",
       "         [-0.0706263 ,  1.0551329 , -0.78412914, ..., -0.8383038 ,\n",
       "           1.6768476 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-1.5780797 ,  0.8127803 , -1.4838691 , ...,  0.10041277,\n",
       "           0.8516161 ,  0.6452373 ],\n",
       "         [-1.3558266 ,  1.0484176 , -1.4596366 , ..., -0.70004815,\n",
       "           1.3301649 ,  0.64397085],\n",
       "         [-1.0309364 ,  1.2628572 , -1.3829755 , ..., -1.6003219 ,\n",
       "           1.4892248 ,  0.64502007]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9014507 ,  1.265258  , -0.02086635, ..., -1.6976206 ,\n",
       "           1.3469263 , -1.5882549 ],\n",
       "         [ 0.5319456 ,  1.1570402 , -0.2477222 , ..., -1.9658478 ,\n",
       "           0.6109733 , -1.5882549 ],\n",
       "         [ 0.7679294 ,  1.2885116 , -0.362972  , ..., -1.9669015 ,\n",
       "           0.5413632 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.0423845 , -0.11361935,  0.51154596, ..., -0.61837435,\n",
       "          -0.72307956,  0.60708004],\n",
       "         [ 1.9068193 , -0.01136441,  0.47339132, ..., -0.10370702,\n",
       "          -0.7680617 ,  0.60846305],\n",
       "         [ 1.3718673 , -0.37730694,  0.41628996, ...,  0.4352751 ,\n",
       "          -0.82911956,  0.6085289 ]],\n",
       "\n",
       "        [[-1.1314641 ,  1.3619165 ,  0.28881046, ..., -1.4127597 ,\n",
       "           1.9133856 , -1.5882549 ],\n",
       "         [ 0.71841073,  1.3142242 ,  0.20471646, ..., -2.255275  ,\n",
       "           2.074327  , -1.5882549 ],\n",
       "         [ 0.34093875,  1.3806069 ,  0.06552371, ..., -1.6197774 ,\n",
       "           2.395184  , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.18806082, -0.07490955,  0.8205622 , ..., -0.31062362,\n",
       "          -0.6450894 ,  0.6040813 ],\n",
       "         [-0.0733876 , -0.28615922,  0.7928203 , ..., -0.04285748,\n",
       "          -0.68049264,  0.6000079 ],\n",
       "         [ 0.07011276, -0.67910314,  0.7436807 , ...,  0.0178189 ,\n",
       "          -0.76498246,  0.59647983]],\n",
       "\n",
       "        [[-2.2932813 ,  0.77748924,  0.8988365 , ..., -1.4134598 ,\n",
       "           1.1827351 , -1.5882549 ],\n",
       "         [-0.22785147,  0.8926288 ,  0.8168112 , ..., -1.9391317 ,\n",
       "           2.6602843 , -1.5882549 ],\n",
       "         [ 1.1291623 ,  1.1381904 ,  0.7885331 , ..., -1.7031996 ,\n",
       "           2.4892519 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.6367741 , -0.6566135 ,  0.9117203 , ..., -0.20893301,\n",
       "          -0.5062108 ,  0.6015705 ],\n",
       "         [ 0.36823073, -0.7069152 ,  0.93604106, ..., -0.04055723,\n",
       "          -0.4774769 ,  0.59968436],\n",
       "         [ 0.46265805, -1.1785263 ,  0.90355897, ..., -0.2498763 ,\n",
       "          -0.45866397,  0.5948006 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.3699198 ,  1.4375393 , -0.5122167 , ..., -1.479522  ,\n",
       "           1.014268  , -1.5882549 ],\n",
       "         [ 0.5395018 ,  1.3120407 , -0.53472614, ..., -1.4367177 ,\n",
       "           1.0395807 , -1.5882549 ],\n",
       "         [ 0.69605756,  1.2094198 , -0.5475988 , ..., -1.5780278 ,\n",
       "           0.6318392 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.056734  ,  1.0967445 , -1.7741865 , ..., -0.258732  ,\n",
       "           0.6202094 ,  0.64691883],\n",
       "         [ 0.77006793,  0.88277596, -1.7575761 , ..., -0.59422547,\n",
       "           0.37340927,  0.6470593 ],\n",
       "         [ 0.6897662 ,  0.6141815 , -1.7871565 , ..., -0.9833871 ,\n",
       "           0.01475467,  0.6485754 ]],\n",
       "\n",
       "        [[-0.00547387,  1.2520872 , -0.75133353, ..., -1.2649589 ,\n",
       "           1.4598074 , -1.5882549 ],\n",
       "         [ 0.1731918 ,  1.1778677 , -0.6965681 , ..., -1.3496872 ,\n",
       "           1.0308584 , -1.5882549 ],\n",
       "         [ 0.2974    ,  1.2267771 , -0.6779615 , ..., -1.3143802 ,\n",
       "           1.3000633 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-0.2796858 ,  1.1767899 , -1.4940785 , ..., -0.1472969 ,\n",
       "           1.6638489 ,  0.64618814],\n",
       "         [-0.35191372,  1.1909208 , -1.616141  , ..., -0.73146605,\n",
       "           1.253029  ,  0.64675516],\n",
       "         [ 0.08551692,  1.120073  , -1.6485579 , ..., -1.353379  ,\n",
       "           0.556414  ,  0.64832795]],\n",
       "\n",
       "        [[-0.03236887,  1.1032389 , -0.84543836, ..., -0.8039201 ,\n",
       "           1.5978309 , -1.5882549 ],\n",
       "         [-0.10388847,  1.0822607 , -0.8415235 , ..., -1.0835985 ,\n",
       "           1.7835716 , -1.5882549 ],\n",
       "         [-0.0706263 ,  1.0551329 , -0.78412914, ..., -0.8383038 ,\n",
       "           1.6768476 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-1.5780797 ,  0.8127803 , -1.4838691 , ...,  0.10041277,\n",
       "           0.8516161 ,  0.6452373 ],\n",
       "         [-1.3558266 ,  1.0484176 , -1.4596366 , ..., -0.70004815,\n",
       "           1.3301649 ,  0.64397085],\n",
       "         [-1.0309364 ,  1.2628572 , -1.3829755 , ..., -1.6003219 ,\n",
       "           1.4892248 ,  0.64502007]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9014507 ,  1.265258  , -0.02086635, ..., -1.6976206 ,\n",
       "           1.3469263 , -1.5882549 ],\n",
       "         [ 0.5319456 ,  1.1570402 , -0.2477222 , ..., -1.9658478 ,\n",
       "           0.6109733 , -1.5882549 ],\n",
       "         [ 0.7679294 ,  1.2885116 , -0.362972  , ..., -1.9669015 ,\n",
       "           0.5413632 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.0423845 , -0.11361935,  0.51154596, ..., -0.61837435,\n",
       "          -0.72307956,  0.60708004],\n",
       "         [ 1.9068193 , -0.01136441,  0.47339132, ..., -0.10370702,\n",
       "          -0.7680617 ,  0.60846305],\n",
       "         [ 1.3718673 , -0.37730694,  0.41628996, ...,  0.4352751 ,\n",
       "          -0.82911956,  0.6085289 ]],\n",
       "\n",
       "        [[-1.1314641 ,  1.3619165 ,  0.28881046, ..., -1.4127597 ,\n",
       "           1.9133856 , -1.5882549 ],\n",
       "         [ 0.71841073,  1.3142242 ,  0.20471646, ..., -2.255275  ,\n",
       "           2.074327  , -1.5882549 ],\n",
       "         [ 0.34093875,  1.3806069 ,  0.06552371, ..., -1.6197774 ,\n",
       "           2.395184  , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.18806082, -0.07490955,  0.8205622 , ..., -0.31062362,\n",
       "          -0.6450894 ,  0.6040813 ],\n",
       "         [-0.0733876 , -0.28615922,  0.7928203 , ..., -0.04285748,\n",
       "          -0.68049264,  0.6000079 ],\n",
       "         [ 0.07011276, -0.67910314,  0.7436807 , ...,  0.0178189 ,\n",
       "          -0.76498246,  0.59647983]],\n",
       "\n",
       "        [[-2.2932813 ,  0.77748924,  0.8988365 , ..., -1.4134598 ,\n",
       "           1.1827351 , -1.5882549 ],\n",
       "         [-0.22785147,  0.8926288 ,  0.8168112 , ..., -1.9391317 ,\n",
       "           2.6602843 , -1.5882549 ],\n",
       "         [ 1.1291623 ,  1.1381904 ,  0.7885331 , ..., -1.7031996 ,\n",
       "           2.4892519 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.6367741 , -0.6566135 ,  0.9117203 , ..., -0.20893301,\n",
       "          -0.5062108 ,  0.6015705 ],\n",
       "         [ 0.36823073, -0.7069152 ,  0.93604106, ..., -0.04055723,\n",
       "          -0.4774769 ,  0.59968436],\n",
       "         [ 0.46265805, -1.1785263 ,  0.90355897, ..., -0.2498763 ,\n",
       "          -0.45866397,  0.5948006 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.3699198 ,  1.4375393 , -0.5122167 , ..., -1.479522  ,\n",
       "           1.014268  , -1.5882549 ],\n",
       "         [ 0.5395018 ,  1.3120407 , -0.53472614, ..., -1.4367177 ,\n",
       "           1.0395807 , -1.5882549 ],\n",
       "         [ 0.69605756,  1.2094198 , -0.5475988 , ..., -1.5780278 ,\n",
       "           0.6318392 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.056734  ,  1.0967445 , -1.7741865 , ..., -0.258732  ,\n",
       "           0.6202094 ,  0.64691883],\n",
       "         [ 0.77006793,  0.88277596, -1.7575761 , ..., -0.59422547,\n",
       "           0.37340927,  0.6470593 ],\n",
       "         [ 0.6897662 ,  0.6141815 , -1.7871565 , ..., -0.9833871 ,\n",
       "           0.01475467,  0.6485754 ]],\n",
       "\n",
       "        [[-0.00547387,  1.2520872 , -0.75133353, ..., -1.2649589 ,\n",
       "           1.4598074 , -1.5882549 ],\n",
       "         [ 0.1731918 ,  1.1778677 , -0.6965681 , ..., -1.3496872 ,\n",
       "           1.0308584 , -1.5882549 ],\n",
       "         [ 0.2974    ,  1.2267771 , -0.6779615 , ..., -1.3143802 ,\n",
       "           1.3000633 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-0.2796858 ,  1.1767899 , -1.4940785 , ..., -0.1472969 ,\n",
       "           1.6638489 ,  0.64618814],\n",
       "         [-0.35191372,  1.1909208 , -1.616141  , ..., -0.73146605,\n",
       "           1.253029  ,  0.64675516],\n",
       "         [ 0.08551692,  1.120073  , -1.6485579 , ..., -1.353379  ,\n",
       "           0.556414  ,  0.64832795]],\n",
       "\n",
       "        [[-0.03236887,  1.1032389 , -0.84543836, ..., -0.8039201 ,\n",
       "           1.5978309 , -1.5882549 ],\n",
       "         [-0.10388847,  1.0822607 , -0.8415235 , ..., -1.0835985 ,\n",
       "           1.7835716 , -1.5882549 ],\n",
       "         [-0.0706263 ,  1.0551329 , -0.78412914, ..., -0.8383038 ,\n",
       "           1.6768476 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-1.5780797 ,  0.8127803 , -1.4838691 , ...,  0.10041277,\n",
       "           0.8516161 ,  0.6452373 ],\n",
       "         [-1.3558266 ,  1.0484176 , -1.4596366 , ..., -0.70004815,\n",
       "           1.3301649 ,  0.64397085],\n",
       "         [-1.0309364 ,  1.2628572 , -1.3829755 , ..., -1.6003219 ,\n",
       "           1.4892248 ,  0.64502007]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9014507 ,  1.265258  , -0.02086635, ..., -1.6976206 ,\n",
       "           1.3469263 , -1.5882549 ],\n",
       "         [ 0.5319456 ,  1.1570402 , -0.2477222 , ..., -1.9658478 ,\n",
       "           0.6109733 , -1.5882549 ],\n",
       "         [ 0.7679294 ,  1.2885116 , -0.362972  , ..., -1.9669015 ,\n",
       "           0.5413632 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.0423845 , -0.11361935,  0.51154596, ..., -0.61837435,\n",
       "          -0.72307956,  0.60708004],\n",
       "         [ 1.9068193 , -0.01136441,  0.47339132, ..., -0.10370702,\n",
       "          -0.7680617 ,  0.60846305],\n",
       "         [ 1.3718673 , -0.37730694,  0.41628996, ...,  0.4352751 ,\n",
       "          -0.82911956,  0.6085289 ]],\n",
       "\n",
       "        [[-1.1314641 ,  1.3619165 ,  0.28881046, ..., -1.4127597 ,\n",
       "           1.9133856 , -1.5882549 ],\n",
       "         [ 0.71841073,  1.3142242 ,  0.20471646, ..., -2.255275  ,\n",
       "           2.074327  , -1.5882549 ],\n",
       "         [ 0.34093875,  1.3806069 ,  0.06552371, ..., -1.6197774 ,\n",
       "           2.395184  , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.18806082, -0.07490955,  0.8205622 , ..., -0.31062362,\n",
       "          -0.6450894 ,  0.6040813 ],\n",
       "         [-0.0733876 , -0.28615922,  0.7928203 , ..., -0.04285748,\n",
       "          -0.68049264,  0.6000079 ],\n",
       "         [ 0.07011276, -0.67910314,  0.7436807 , ...,  0.0178189 ,\n",
       "          -0.76498246,  0.59647983]],\n",
       "\n",
       "        [[-2.2932813 ,  0.77748924,  0.8988365 , ..., -1.4134598 ,\n",
       "           1.1827351 , -1.5882549 ],\n",
       "         [-0.22785147,  0.8926288 ,  0.8168112 , ..., -1.9391317 ,\n",
       "           2.6602843 , -1.5882549 ],\n",
       "         [ 1.1291623 ,  1.1381904 ,  0.7885331 , ..., -1.7031996 ,\n",
       "           2.4892519 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.6367741 , -0.6566135 ,  0.9117203 , ..., -0.20893301,\n",
       "          -0.5062108 ,  0.6015705 ],\n",
       "         [ 0.36823073, -0.7069152 ,  0.93604106, ..., -0.04055723,\n",
       "          -0.4774769 ,  0.59968436],\n",
       "         [ 0.46265805, -1.1785263 ,  0.90355897, ..., -0.2498763 ,\n",
       "          -0.45866397,  0.5948006 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_images_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150bd816",
   "metadata": {},
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da502411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting y for training\n",
    "df1=training_set_wt.query(\"latitude == -15.0 and longitude == 55\")\n",
    "y_train = df1['Real_tom_lsm']\n",
    "\n",
    "#extracting y for validation\n",
    "df2=validation_set_wt.query(\"latitude == -15.0 and longitude == 55\")\n",
    "y_validation = df2['Real_tom_lsm'].values\n",
    "y_validation = y_validation.reshape(-1,1)\n",
    "\n",
    "#extracting y for test\n",
    "df3=test_set_wt.query(\"latitude == -15.0 and longitude == 55\")\n",
    "y_test = df3['Real_tom_lsm'].values\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bbc3fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (11323, 13, 29, 8)\n",
      "Shape of y_train:  (11323,)\n",
      "Shape of X_valid:  (1826, 13, 29, 8)\n",
      "Shape of y_valid:  (1826, 1)\n",
      "Shape of X_test:  (1431, 13, 29, 8)\n",
      "Shape of y_test:  (1431, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes\n",
    "# Note, model input must have a four-dimensional shape [samples, rows, columns, channels]\n",
    "\n",
    "X_train = data_images_training_set\n",
    "X_valid = data_images_validation_set\n",
    "X_test = data_images_test_set\n",
    "\n",
    "\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(\"Shape of X_valid: \", X_valid.shape)\n",
    "print(\"Shape of y_valid: \", y_validation.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_test: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701d0873",
   "metadata": {},
   "source": [
    "# Sample weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0fbc8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "##n_samples / (n_classes * np.bincount(y))\n",
    "sample_weights = compute_sample_weight(class_weight = 'balanced', \n",
    "                                                  y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9550c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50355777, 0.50355777, 0.50355777, ..., 0.50355777, 0.50355777,\n",
       "       0.50355777])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b15e113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 10:17:49.735322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "##### Step 1 - Specify the structure of a Neural Network\n",
    "#--- Define a Model\n",
    "model = Sequential(name=\"DCN-Model\") # Model\n",
    "\n",
    "\n",
    "#--- Input Layer \n",
    "# Specify input shape [rows, columns, channels]\n",
    "model.add(Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3]), name='Input-Layer')) # Input Layer - need to speicfy the shape of inputs\n",
    "\n",
    "\n",
    "#--- First Set of Convolution, Max Pooling and Droput Layers (all parameters shown)\n",
    "model.add(Conv2D(filters=16, # Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "                 kernel_size=(3,3), # An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "                 strides=(1,1), # Default=(1,1), An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n",
    "                 padding='valid', # Default='valid', \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input. When padding=\"same\" and strides=1, the output has the same size as the input.\n",
    "                 data_format=None, # Default=None, A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch_size, height, width, channels) while channels_first corresponds to inputs with shape (batch_size, channels,height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last.\n",
    "                 dilation_rate=(1, 1), # Default=(1, 1), an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n",
    "                 groups=1, # Default=1, A positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with filters / groups filters. The output is the concatenation of all the groups results along the channel axis. Input channels and filters must both be divisible by groups.\n",
    "                 activation='relu', # Default=None, Activation function to use. If you don't specify anything, no activation is applied (see keras.activations).\n",
    "                 use_bias=True, # Default=True. \n",
    "                 kernel_initializer='glorot_uniform', # Default='glorot_uniform', Initializer for the kernel weights matrix (see keras.initializers).\n",
    "                 bias_initializer='zeros', # Default='zeros', Initializer for the bias vector (see keras.initializers).\n",
    "                 kernel_regularizer=None, # Default=None, Regularizer function applied to the kernel weights matrix (see keras.regularizers).\n",
    "                 bias_regularizer=None, # Default=None, Regularizer function applied to the bias vector (see keras.regularizers).\n",
    "                 activity_regularizer=None, # Default=None, Regularizer function applied to the output of the layer (its \"activation\") (see keras.regularizers).\n",
    "                 kernel_constraint=None, # Default=None, Constraint function applied to the kernel matrix (see keras.constraints).\n",
    "                 bias_constraint=None, # Default=None, Constraint function applied to the bias vector (see keras.constraints).\n",
    "                 name='2D-Convolutional-Layer-1')\n",
    "         ) # Convolutional Layer, relu activation used\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2), # Default=(2,2), integer or tuple of 2 integers, window size over which to take the maximum. (2, 2) will take the max value over a 2x2 pooling window. If only one integer is specified, the same window length will be used for both dimensions.\n",
    "                    strides=(2,2), # Default=None, Integer, tuple of 2 integers, or None. Strides values. Specifies how far the pooling window moves for each pooling step. If None, it will default to pool_size.\n",
    "                    padding='valid', # Default='valid', One of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n",
    "                    data_format=None, # Default=None, A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). \n",
    "                    name='2D-MaxPool-Layer-1')\n",
    "         ) # Max Pooling Layer,\n",
    "\n",
    "model.add(Dropout(0.2, name='Dropout-Layer-1')) # Dropout Layer\n",
    "\n",
    "\n",
    "#--- Second Set of Convolution, Max Pooling and Droput Layers \n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', name='2D-Convolutional-Layer-2')) # Convolutional Layer\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='valid', name='2D-MaxPool-Layer-2')) # Second Max Pooling Layer,\n",
    "model.add(Dropout(0.2, name='Dropout-Layer-2')) # Dropout Layer\n",
    "\n",
    "\n",
    "#--- Third Set of Convolution, Max Pooling and Droput Layers\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', name='2D-Convolutional-Layer-3')) # Convolutional Layer\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same', name='2D-MaxPool-Layer-3')) # Second Max Pooling Layer,\n",
    "model.add(Dropout(0.2, name='Dropout-Layer-3')) # Dropout Layer\n",
    "\n",
    "\n",
    "#--- Feed-Forward Densely Connected Layer and Output Layer (note, flattening is required to convert from 2D to 1D shape)\n",
    "model.add(Flatten(name='Flatten-Layer')) # Flatten the shape so we can feed it into a regular densely connected layer\n",
    "model.add(Dense(16, activation='relu', name='Hidden-Layer-1', kernel_initializer='HeNormal')) # Hidden Layer, relu(x) = max(x, 0)\n",
    "model.add(Dense(1, activation='softmax', name='Output-Layer')) # Output Layer, softmax(x) = exp(x) / tf.reduce_sum(exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27bcd6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 0.8994 - Accuracy: 0.0071 - val_loss: 1.2321 - val_Accuracy: 0.0066\n",
      "Epoch 2/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.3296 - Accuracy: 0.0071 - val_loss: 1.0505 - val_Accuracy: 0.0066\n",
      "Epoch 3/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.2747 - Accuracy: 0.0071 - val_loss: 0.8092 - val_Accuracy: 0.0066\n",
      "Epoch 4/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.1987 - Accuracy: 0.0071 - val_loss: 0.3456 - val_Accuracy: 0.0066\n",
      "Epoch 5/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1978 - Accuracy: 0.0071 - val_loss: 0.4763 - val_Accuracy: 0.0066\n",
      "Epoch 6/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.2086 - Accuracy: 0.0071 - val_loss: 0.3379 - val_Accuracy: 0.0066\n",
      "Epoch 7/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1606 - Accuracy: 0.0071 - val_loss: 0.1010 - val_Accuracy: 0.0066\n",
      "Epoch 8/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1680 - Accuracy: 0.0071 - val_loss: 0.4846 - val_Accuracy: 0.0066\n",
      "Epoch 9/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1913 - Accuracy: 0.0071 - val_loss: 0.2171 - val_Accuracy: 0.0066\n",
      "Epoch 10/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1577 - Accuracy: 0.0071 - val_loss: 0.1105 - val_Accuracy: 0.0066\n",
      "Epoch 11/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.1632 - Accuracy: 0.0071 - val_loss: 0.3187 - val_Accuracy: 0.0066\n",
      "Epoch 12/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.2015 - Accuracy: 0.0071 - val_loss: 0.1279 - val_Accuracy: 0.0066\n",
      "Epoch 13/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1515 - Accuracy: 0.0071 - val_loss: 0.0454 - val_Accuracy: 0.0066\n",
      "Epoch 14/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.1231 - Accuracy: 0.0071 - val_loss: 0.0413 - val_Accuracy: 0.0066\n",
      "Epoch 15/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1596 - Accuracy: 0.0071 - val_loss: 0.0678 - val_Accuracy: 0.0066\n",
      "Epoch 16/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.2537 - Accuracy: 0.0071 - val_loss: 0.2072 - val_Accuracy: 0.0066\n",
      "Epoch 17/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1332 - Accuracy: 0.0071 - val_loss: 0.0608 - val_Accuracy: 0.0066\n",
      "Epoch 18/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1361 - Accuracy: 0.0071 - val_loss: 0.0426 - val_Accuracy: 0.0066\n",
      "Epoch 19/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1085 - Accuracy: 0.0071 - val_loss: 0.0682 - val_Accuracy: 0.0066\n",
      "Epoch 20/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.1296 - Accuracy: 0.0071 - val_loss: 0.0474 - val_Accuracy: 0.0066\n"
     ]
    }
   ],
   "source": [
    "##### Step 2 - Compile keras model\n",
    "model.compile(optimizer='adam', # default='rmsprop', an algorithm to be used in backpropagation\n",
    "              loss='binary_crossentropy', # Loss function to be optimized. A string (name of loss function), or a tf.keras.losses.Loss instance.\n",
    "              metrics=['Accuracy'], # List of metrics to be evaluated by the model during training and testing. Each of this can be a string (name of a built-in function), function or a tf.keras.metrics.Metric instance. \n",
    "              loss_weights=None, # default=None, Optional list or dictionary specifying scalar coefficients (Python floats) to weight the loss contributions of different model outputs.\n",
    "              weighted_metrics=None, # default=None, List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing.\n",
    "              run_eagerly=None, # Defaults to False. If True, this Model's logic will not be wrapped in a tf.function. Recommended to leave this as None unless your Model cannot be run inside a tf.function.\n",
    "              steps_per_execution=None # Defaults to 1. The number of batches to run during each tf.function call. Running multiple batches inside a single tf.function call can greatly improve performance on TPUs or small models with a large Python overhead.\n",
    "             )\n",
    "\n",
    "\n",
    "##### Step 3 - Fit keras model on the dataset\n",
    "history = model.fit(X_train, # input data\n",
    "                    y_train, # target data\n",
    "                    sample_weight=sample_weights,\n",
    "                    #batch_size=1, # Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "                    epochs=20, # default=1, Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided\n",
    "                    #verbose=0, # default='auto', ('auto', 0, 1, or 2). Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 'auto' defaults to 1 for most cases, but 2 when used with ParameterServerStrategy.\n",
    "                    callbacks=None, # default=None, list of callbacks to apply during training. See tf.keras.callbacks\n",
    "                    #validation_split=0.0, # default=0.0, Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. \n",
    "                    validation_data=(X_valid, y_validation), # default=None, Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "                    #shuffle=True, # default=True, Boolean (whether to shuffle the training data before each epoch) or str (for 'batch').\n",
    "                    #class_weight=None, # default=None, Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "                    #sample_weight=None, # default=None, Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only).\n",
    "                    #initial_epoch=0, # Integer, default=0, Epoch at which to start training (useful for resuming a previous training run).\n",
    "                    #steps_per_epoch=None, # Integer or None, default=None, Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. \n",
    "                    #validation_steps=None, # Only relevant if validation_data is provided and is a tf.data dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch.\n",
    "                    #validation_batch_size=None, # Integer or None, default=None, Number of samples per validation batch. If unspecified, will default to batch_size.\n",
    "                    #validation_freq=1, # default=1, Only relevant if validation data is provided. If an integer, specifies how many training epochs to run before a new validation run is performed, e.g. validation_freq=2 runs validation every 2 epochs.\n",
    "                    #max_queue_size=10, # default=10, Used for generator or keras.utils.Sequence input only. Maximum size for the generator queue. If unspecified, max_queue_size will default to 10.\n",
    "                    #workers=1, # default=1, Used for generator or keras.utils.Sequence input only. Maximum number of processes to spin up when using process-based threading. If unspecified, workers will default to 1.\n",
    "                    #use_multiprocessing=False, # default=False, Used for generator or keras.utils.Sequence input only. If True, use process-based threading. If unspecified, use_multiprocessing will default to False. \n",
    "                   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e34c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 1s 2ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "\n",
      "------------------------- Model Summary -------------------------\n",
      "Model: \"DCN-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " 2D-Convolutional-Layer-1 (C  (None, 11, 27, 16)       1168      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-1 (MaxPool  (None, 5, 13, 16)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-1 (Dropout)   (None, 5, 13, 16)         0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-2 (C  (None, 3, 11, 64)        9280      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-2 (MaxPool  (None, 1, 5, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-2 (Dropout)   (None, 1, 5, 64)          0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-3 (C  (None, 1, 5, 64)         36928     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-3 (MaxPool  (None, 1, 3, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-3 (Dropout)   (None, 1, 3, 64)          0         \n",
      "                                                                 \n",
      " Flatten-Layer (Flatten)     (None, 192)               0         \n",
      "                                                                 \n",
      " Hidden-Layer-1 (Dense)      (None, 16)                3088      \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,481\n",
      "Trainable params: 50,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "------------------ Evaluation on Training Data ------------------\n",
      "Final loss : 0.12958651781082153\n",
      "Final Accuracy : 0.007065265439450741\n",
      "Final val_loss : 0.047377314418554306\n",
      "Final val_Accuracy : 0.006571741309016943\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00     11243\n",
      "         1.0       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.99     11323\n",
      "   macro avg       0.50      0.50      0.50     11323\n",
      "weighted avg       0.99      0.99      0.99     11323\n",
      "\n",
      "\n",
      "-------------------- Evaluation on Test Data --------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      1416\n",
      "         1.0       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.99      1431\n",
      "   macro avg       0.49      0.50      0.50      1431\n",
      "weighted avg       0.98      0.99      0.98      1431\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "##### Step 4 - Use model to make predictions\n",
    "# Note, we need to pass model output through argmax to convert from probability to label\n",
    "# Also, we convert output from tensor to numpy array\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = np.array(tf.math.argmax(model.predict(X_train),axis=1))\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = np.array(tf.math.argmax(model.predict(X_test),axis=1))\n",
    "\n",
    "\n",
    "##### Step 5 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('------------------------- Model Summary -------------------------')\n",
    "model.summary() # print model summary\n",
    "print(\"\")\n",
    "    \n",
    "\n",
    "\n",
    "print('------------------ Evaluation on Training Data ------------------')\n",
    "# Print the last value in the evaluation metrics contained within history file\n",
    "for item in history.history:\n",
    "    print(\"Final\", item, \":\", history.history[item][-1])\n",
    "print(\"\")\n",
    "# Print classification report\n",
    "print(classification_report(y_train, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('-------------------- Evaluation on Test Data --------------------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8461123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = np.array(tf.math.argmax(model.predict(X_train),axis=1))\n",
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bd38be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 in ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7fcf084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels_tr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "205c4e9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 1s 2ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "\n",
      "-------------------- Model Summary --------------------\n",
      "Model: \"DCN-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " 2D-Convolutional-Layer-1 (C  (None, 11, 27, 16)       1168      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-1 (MaxPool  (None, 5, 13, 16)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-1 (Dropout)   (None, 5, 13, 16)         0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-2 (C  (None, 3, 11, 64)        9280      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-2 (MaxPool  (None, 1, 5, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-2 (Dropout)   (None, 1, 5, 64)          0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-3 (C  (None, 1, 5, 64)         36928     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-3 (MaxPool  (None, 1, 3, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-3 (Dropout)   (None, 1, 3, 64)          0         \n",
      "                                                                 \n",
      " Flatten-Layer (Flatten)     (None, 192)               0         \n",
      "                                                                 \n",
      " Hidden-Layer-1 (Dense)      (None, 16)                3088      \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,481\n",
      "Trainable params: 50,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "-------------------- Weights and Biases --------------------\n",
      "Layer:  2D-Convolutional-Layer-1\n",
      "Layer:  2D-MaxPool-Layer-1\n",
      "Layer:  Dropout-Layer-1\n",
      "Layer:  2D-Convolutional-Layer-2\n",
      "Layer:  2D-MaxPool-Layer-2\n",
      "Layer:  Dropout-Layer-2\n",
      "Layer:  2D-Convolutional-Layer-3\n",
      "Layer:  2D-MaxPool-Layer-3\n",
      "Layer:  Dropout-Layer-3\n",
      "Layer:  Flatten-Layer\n",
      "Layer:  Hidden-Layer-1\n",
      "Layer:  Output-Layer\n",
      "\n",
      "---------- Evaluation on Training Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     11243\n",
      "         1.0       0.01      1.00      0.01        80\n",
      "\n",
      "    accuracy                           0.01     11323\n",
      "   macro avg       0.00      0.50      0.01     11323\n",
      "weighted avg       0.00      0.01      0.00     11323\n",
      "\n",
      "\n",
      "---------- Evaluation on Test Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      1416\n",
      "         1.0       0.01      1.00      0.02        15\n",
      "\n",
      "    accuracy                           0.01      1431\n",
      "   macro avg       0.01      0.50      0.01      1431\n",
      "weighted avg       0.00      0.01      0.00      1431\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f82f80b1990>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAGwCAYAAAAXAEo1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfOklEQVR4nO3de1hVdb7H8c/mjpcN4gXBAFFL0RQRL2FjqZWl5YPTzDQerczR6Tg2KcfKGY/TmBWSncZr4yWa1Cw7Ot66jFpWWmaaoeiUovNYKpjiXTaCosA6fzju4xZQNmzcP+X9eh6fp/Xbay++3ni31l7ubbMsyxIAAAbz8fYAAABcC7ECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4ft4eoDpKS0t16NAh1a9fXzabzdvjAADcZFmW8vPzFRkZKR+fis+fbuhYHTp0SFFRUd4eAwBQTTk5ObrlllsqfPyGjlX9+vUlSXv35ai+3e7laYCaEd3zWW+PANQYq+S8zu9a4Px+XpEbOlaXLv3Vt9tlJ1a4Sdl8A7w9AlDjrvVSDjdYAACMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUq7c2/f6n45AlqemeKej42WV9n7vX2SEAZ3RNa6r0p/6ldq1J16tvX1e/uDhXuO3XcQJ369nWN+I+eLutDfn6nPpwzWgfW/Y9Offu67PWCy31+nzvbae28Z3VowxTtXfuK3n51uCd/KrgMsUKlLP9kq/57yjI9M/R+ffHOH5XUsaUeGT1LObknvT0a4KJOcKC+/9dPGvs/S666X7+7Oyjx9uY6dPR0mceCg/z12aZdmjr/kwqf379XR82Z+LgWfbhZPQa/ogeGT9HSNRnVHR8V8HqsZs2apdjYWAUFBSkxMVEbNmzw9kgox6xFn+vR5CQ9PqC7Wsc2Vdozv1Sz8AZ6aym/XzDLp1/vUuqcj/TRuh0V7hPROESvPvcrPfn8fBUXl5R5fM576zVtwVp9+93+cp/v6+ujtGd+oT/PWKl5y7/SD9lHtffAUX3w+XYP/SxwJa/GavHixUpJSdH48eOVmZmpHj16qG/fvsrOzvbmWLjC+QvF2r47R727xbms9+oWpy3/3OelqYCqsdlsmjPxcc185zPt/jG3SseIbx2lZuENVGpZ+uKdPyhrdar+Pv13atOiqYenxSVejdWUKVM0bNgwDR8+XHFxcZo2bZqioqI0e/Zsb46FK5w4fUYlJaVqHFbfZb1xw/o6esLhpamAqkkZcp+KS0o193/XV/kYzZs1kiT98bf99NrfPtbA/5qj046z+mhuikLtdTw0KS7ntVidP39eW7duVZ8+fVzW+/Tpo6+//rrc5xQVFcnhcLj8wPVjs7luW5Yl25WLgMHi20TpPwf21FMT36nWcXx8Lv65/8u8j/Xhuu3asTtHT734jizL0oB7EjwxKq7g560vfPz4cZWUlCg8PNxlPTw8XLm55Z+ap6WlaeLEiddjPFymYWg9+fr66OiJfJf14yfPlDnbAkyWlNBSjRvU03cfvuhc8/Pz1cujH9bvBvZSfPKESh0n93ieJGnPj4eda+cvFGv/Tyd0S9Mwzw4NSV6M1SVX/p/51f5vfdy4cRozZoxz2+FwKCoqqkbngxTg76eObaK07pvdeqhXvHN9/Zbd6ntXey9OBrhn8apv9cWWPS5rS2c8pSWrt+jdDzdX+jg7dufoXNEFtYoJ1+YdP0qS/Hx9FB0Rxh2yNcRrsWrUqJF8fX3LnEUdPXq0zNnWJYGBgQoMDLwe4+EKIwf11ogJbyuhbbS6tI/VghUbdTD3pIb+ooe3RwNc1A0OUGxUY+d2TGRD3X5bM53OK9TBI6d0Kq/AZf/i4hIdOeHQ3gNHnWtNGtZXk4Z2tYi6+NpUu1aRyi88p4O5p3TaUaj8gnOat/wr/fHJfvrpyCnl5J7U04/eK0la+em26/CzrH28FquAgAAlJiZq7dq1+vnPf+5cX7t2rZKTk701FirwcJ9Encwr0KtvrtaR4w7FtYzQ4mkjFR3BJQ+YpWNcjD6aO9q5PWnMLyRJiz7aXOnXqoY+3EN/fLKfc3tV+n9JkkZOXKj3PvpGkvTn6StUXFKqORMfV1Cgv7buPKDkkTOUl3/WUz8VXMZmWZblrS++ePFiPfbYY5ozZ46SkpL0xhtvKD09XTt37lRMTMw1n+9wOBQSEqIjJ/Jkt9uvw8TA9degy++9PQJQY6yS8yr6Ll15eVf/Pu7V16x+/etf68SJE3rxxRd1+PBh3X777Vq1alWlQgUAqD28emZVXZxZoTbgzAo3s8qeWXn97ZYAALgWYgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADj+VVmpxkzZlT6gKNGjaryMAAAlKdSsZo6dWqlDmaz2YgVAMDjKhWrffv21fQcAABUqMqvWZ0/f1579uxRcXGxJ+cBAKAMt2NVWFioYcOGqU6dOmrXrp2ys7MlXXyt6pVXXvH4gAAAuB2rcePGaceOHVq/fr2CgoKc6/fee68WL17s0eEAAJAq+ZrV5VauXKnFixfrjjvukM1mc663bdtWP/zwg0eHAwBAqsKZ1bFjx9SkSZMy6wUFBS7xAgDAU9yOVZcuXfSPf/zDuX0pUOnp6UpKSvLcZAAA/JvblwHT0tL0wAMPaNeuXSouLtb06dO1c+dObdq0SV988UVNzAgAqOXcPrPq3r27Nm7cqMLCQrVs2VKffPKJwsPDtWnTJiUmJtbEjACAWs7tMytJat++vRYsWODpWQAAKFeVYlVSUqIVK1YoKytLNptNcXFxSk5Olp9flQ4HAMBVuV2X77//XsnJycrNzVXr1q0lSf/617/UuHFjffDBB2rfvr3HhwQA1G5uv2Y1fPhwtWvXTgcPHtS2bdu0bds25eTkqEOHDnryySdrYkYAQC3n9pnVjh07lJGRoQYNGjjXGjRooNTUVHXp0sWjwwEAIFXhzKp169Y6cuRImfWjR4+qVatWHhkKAIDLVSpWDofD+WPSpEkaNWqUli5dqoMHD+rgwYNaunSpUlJSNHny5JqeFwBQC1XqMmBoaKjLWylZlqVHHnnEuWZZliSpf//+KikpqYExAQC1WaVitW7dupqeAwCAClUqVnfffXdNzwEAQIWq/K94CwsLlZ2drfPnz7usd+jQodpDAQBwObdjdezYMQ0dOlSrV68u93FeswIAeJrbt66npKTo1KlT2rx5s4KDg7VmzRotWLBAt956qz744IOamBEAUMu5fWb1+eef6/3331eXLl3k4+OjmJgY3XfffbLb7UpLS9ODDz5YE3MCAGoxt8+sCgoKnJ8UHBYWpmPHjkm6+E7s27Zt8+x0AACoiu9gsWfPHklSx44dNXfuXP3000+aM2eOIiIiPD4gAABuXwZMSUnR4cOHJUkTJkzQ/fffr3fffVcBAQGaP3++p+cDAMD9WA0ePNj53wkJCdq/f792796t6OhoNWrUyKPDAQAgVePfWV1Sp04dderUyROzAABQrkrFasyYMZU+4JQpU6o8DAAA5alUrDIzMyt1sMvf7BaAZ5z4Zqa3RwBqjMPhUETj9GvuxxvZAgCM5/at6wAAXG/ECgBgPGIFADAesQIAGI9YAQCMV6VYLVy4UHfeeaciIyN14MABSdK0adP0/vvve3Q4AACkKsRq9uzZGjNmjPr166fTp087P2wxNDRU06ZN8/R8AAC4H6uZM2cqPT1d48ePl6+vr3O9c+fO+u677zw6HAAAUhVitW/fPiUkJJRZDwwMVEFBgUeGAgDgcm7HKjY2Vtu3by+zvnr1arVt29YTMwEA4MLtd11/7rnn9NRTT+ncuXOyLEtbtmzRe++9p7S0NL355ps1MSMAoJZzO1ZDhw5VcXGxxo4dq8LCQg0aNEjNmjXT9OnTNXDgwJqYEQBQy9ksy7Kq+uTjx4+rtLRUTZo08eRMleZwOBQSEqIjJ/Jkt9u9MgNQ00pLq/xXFDDexXddD1Ve3tW/j1frwxf5ZGAAwPXgdqxiY2Ov+rlVP/74Y7UGAgDgSm7HKiUlxWX7woULyszM1Jo1a/Tcc895ai4AAJzcjtXo0aPLXf/rX/+qjIyMag8EAMCVPPZGtn379tWyZcs8dTgAAJw8FqulS5cqLCzMU4cDAMDJ7cuACQkJLjdYWJal3NxcHTt2TLNmzfLocAAASFWI1YABA1y2fXx81LhxY/Xs2VNt2rTx1FwAADi5Favi4mI1b95c999/v5o2bVpTMwEA4MKt16z8/Pz0u9/9TkVFRTU1DwAAZbh9g0W3bt2UmZlZE7MAAFAut1+zGjlypJ555hkdPHhQiYmJqlu3rsvjHTp08NhwAABIbryR7W9+8xtNmzZNoaGhZQ9is8myLNlsNufH3F8PvJEtagPeyBY3s8q+kW2lY+Xr66vDhw/r7NmzV90vJibGvUmrgVihNiBWuJl5/F3XLzXtesYIAADJzRssrvZu6wAA1BS3brC47bbbrhmskydPVmsgAACu5FasJk6cqJCQkJqaBQCAcrkVq4EDB3rtI+wBALVXpV+z4vUqAIC3VDpWlbzDHQAAj6v0ZcDS0tKanAMAgAp57MMXAQCoKcQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8P28PgBvHm3//UjPf+UxHjuepTYsITRrzC3VPaOXtsQC3fZ25V6+/85m2787WkeMOvf3qcD14d7zz8adeXKj//ccWl+cktmuuT9565nqPin8jVqiU5Z9s1X9PWabX/vBrdYtvofnLv9Ijo2dp05I/KappmLfHA9xSeLZI7W5tpv94qJue+OPfyt3nnqQ4zXz+Ued2gJ/v9RoP5fDqZcAvv/xS/fv3V2RkpGw2m1auXOnNcXAVsxZ9rkeTk/T4gO5qHdtUac/8Us3CG+itpRu8PRrgtnu7t9P4EQ+pf6+OFe4T4O+n8IZ2548GIXWv34Aow6uxKigoUHx8vF5//XVvjoFrOH+hWNt356h3tziX9V7d4rTln/u8NBVQszZu26vWD4xT11++qJRJi3TsZL63R6rVvHoZsG/fvurbt2+l9y8qKlJRUZFz2+Fw1MRYuMKJ02dUUlKqxmH1XdYbN6yvoyf4PcDN596ktkrunaCoiDAdOHRCaXP/oQFPzdTnC55TYIC/t8erlW6o16zS0tI0ceJEb49Ra9lsrtuWZcl25SJwE/j5fYnO/45rGamOcdHqmDxBn2zcedVLh6g5N9St6+PGjVNeXp7zR05OjrdHqhUahtaTr6+Pjp5wvQxy/OSZMmdbwM2oaaMQRTUN0485x7w9Sq11Q8UqMDBQdrvd5QdqXoC/nzq2idK6b3a7rK/fsltdO8R6aSrg+jmZV6Cfjp5SeCO+53jLDXUZEN4zclBvjZjwthLaRqtL+1gtWLFRB3NPaugvenh7NMBtZwqLtO/g/58lZR86oe/+dVAN7HUUaq+rV9NXqX/vjgpvaFf24ZN6efaHCgup5/JvsXB9EStUysN9EnUyr0CvvrlaR447FNcyQounjVR0BP/GCjee7VnZSh45w7n9p2krJEkDH+yq18b+Wrt+OKTFq7coL/+swhvZ9bPEW/W31KGqXzfIWyPXejbLsixvffEzZ85o7969kqSEhARNmTJFvXr1UlhYmKKjo6/5fIfDoZCQEB05kcclQdy0Sku99lcUqHEOh0MRjUOVl3f17+NePbPKyMhQr169nNtjxoyRJA0ZMkTz58/30lQAANN4NVY9e/aUF0/sAAA3iBvqbkAAQO1ErAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPH8vD1AdViWJUnKdzi8PAlQc0pLLW+PANSY/PyL378vfT+vyA0dq/z8fElSq9goL08CAKiO/Px8hYSEVPi4zbpWzgxWWlqqQ4cOqX79+rLZbN4ep1ZwOByKiopSTk6O7Ha7t8cBPIo/39efZVnKz89XZGSkfHwqfmXqhj6z8vHx0S233OLtMWolu93OX2bctPjzfX1d7YzqEm6wAAAYj1gBAIxHrOCWwMBATZgwQYGBgd4eBfA4/nyb64a+wQIAUDtwZgUAMB6xAgAYj1gBAIxHrAAAxiNWqLRZs2YpNjZWQUFBSkxM1IYNG7w9EuARX375pfr376/IyEjZbDatXLnS2yPhCsQKlbJ48WKlpKRo/PjxyszMVI8ePdS3b19lZ2d7ezSg2goKChQfH6/XX3/d26OgAty6jkrp1q2bOnXqpNmzZzvX4uLiNGDAAKWlpXlxMsCzbDabVqxYoQEDBnh7FFyGMytc0/nz57V161b16dPHZb1Pnz76+uuvvTQVgNqEWOGajh8/rpKSEoWHh7ush4eHKzc310tTAahNiBUq7cqPYbEsi49mAXBdECtcU6NGjeTr61vmLOro0aNlzrYAoCYQK1xTQECAEhMTtXbtWpf1tWvXqnv37l6aCkBtckN/+CKunzFjxuixxx5T586dlZSUpDfeeEPZ2dkaMWKEt0cDqu3MmTPau3evc3vfvn3avn27wsLCFB0d7cXJcAm3rqPSZs2apVdffVWHDx/W7bffrqlTp+quu+7y9lhAta1fv169evUqsz5kyBDNnz//+g+EMogVAMB4vGYFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFVNMLL7ygjh07OrefeOIJr3xw3/79+2Wz2bR9+/YK92nevLmmTZtW6WPOnz9foaGh1Z6Nj4pHdREr3JSeeOIJ2Ww22Ww2+fv7q0WLFnr22WdVUFBQ4197+vTplX6LnsoEBgBvZIub2AMPPKB58+bpwoUL2rBhg4YPH66CggLNnj27zL4XLlyQv7+/R75uSEiIR44D4P9xZoWbVmBgoJo2baqoqCgNGjRIgwcPdl6KunTp7q233lKLFi0UGBgoy7KUl5enJ598Uk2aNJHdblfv3r21Y8cOl+O+8sorCg8PV/369TVs2DCdO3fO5fErLwOWlpZq8uTJatWqlQIDAxUdHa3U1FRJUmxsrCQpISFBNptNPXv2dD5v3rx5iouLU1BQkNq0aaNZs2a5fJ0tW7YoISFBQUFB6ty5szIzM93+NZoyZYrat2+vunXrKioqSiNHjtSZM2fK7Ldy5UrddtttCgoK0n333aecnByXxz/88EMlJiYqKChILVq00MSJE1VcXOz2PEBFiBVqjeDgYF24cMG5vXfvXi1ZskTLli1zXoZ78MEHlZubq1WrVmnr1q3q1KmT7rnnHp08eVKStGTJEk2YMEGpqanKyMhQREREmYhcady4cZo8ebKef/557dq1S4sWLXJ+aOWWLVskSZ9++qkOHz6s5cuXS5LS09M1fvx4paamKisrS5MmTdLzzz+vBQsWSJIKCgr00EMPqXXr1tq6dateeOEFPfvss27/mvj4+GjGjBn6/vvvtWDBAn3++ecaO3asyz6FhYVKTU3VggULtHHjRjkcDg0cOND5+Mcff6xHH31Uo0aN0q5duzR37lzNnz/fGWTAIyzgJjRkyBArOTnZuf3NN99YDRs2tB555BHLsixrwoQJlr+/v3X06FHnPp999pllt9utc+fOuRyrZcuW1ty5cy3LsqykpCRrxIgRLo9369bNio+PL/drOxwOKzAw0EpPTy93zn379lmSrMzMTJf1qKgoa9GiRS5rL730kpWUlGRZlmXNnTvXCgsLswoKCpyPz549u9xjXS4mJsaaOnVqhY8vWbLEatiwoXN73rx5liRr8+bNzrWsrCxLkvXNN99YlmVZPXr0sCZNmuRynIULF1oRERHObUnWihUrKvy6wLXwmhVuWh999JHq1aun4uJiXbhwQcnJyZo5c6bz8ZiYGDVu3Ni5vXXrVp05c0YNGzZ0Oc7Zs2f1ww8/SJKysrLKfOBkUlKS1q1bV+4MWVlZKioq0j333FPpuY8dO6acnBwNGzZMv/3tb53rxcXFztfDsrKyFB8frzp16rjM4a5169Zp0qRJ2rVrlxwOh4qLi3Xu3DkVFBSobt26kiQ/Pz917tzZ+Zw2bdooNDRUWVlZ6tq1q7Zu3apvv/3W5UyqpKRE586dU2FhocuMQFURK9y0evXqpdmzZ8vf31+RkZFlbqC49M34ktLSUkVERGj9+vVljlXV27eDg4Pdfk5paamki5cCu3Xr5vKYr6+vJMnywMfQHThwQP369dOIESP00ksvKSwsTF999ZWGDRvmcrlUunjr+ZUurZWWlmrixIl6+OGHy+wTFBRU7TkBiVjhJla3bl21atWq0vt36tRJubm58vPzU/PmzcvdJy4uTps3b9bjjz/uXNu8eXOFx7z11lsVHByszz77TMOHDy/zeEBAgKSLZyKXhIeHq1mzZvrxxx81ePDgco/btm1bLVy4UGfPnnUG8WpzlCcjI0PFxcX6y1/+Ih+fiy9fL1mypMx+xcXFysjIUNeuXSVJe/bs0enTp9WmTRtJF3/d9uzZ49avNeAuYgX827333qukpCQNGDBAkydPVuvWrXXo0CGtWrVKAwYMUOfOnTV69GgNGTJEnTt31s9+9jO9++672rlzp1q0aFHuMYOCgvSHP/xBY8eOVUBAgO68804dO3ZMO3fu1LBhw9SkSRMFBwdrzZo1uuWWWxQUFKSQkBC98MILGjVqlOx2u/r27auioiJlZGTo1KlTGjNmjAYNGqTx48dr2LBh+tOf/qT9+/frtddec+vn27JlSxUXF2vmzJnq37+/Nm7cqDlz5pTZz9/fX08//bRmzJghf39//f73v9cdd9zhjNef//xnPfTQQ4qKitKvfvUr+fj46J///Ke+++47vfzyy+7/RgDl8faLZkBNuPIGiytNmDDB5aaISxwOh/X0009bkZGRlr+/vxUVFWUNHjzYys7Odu6TmppqNWrUyKpXr541ZMgQa+zYsRXeYGFZllVSUmK9/PLLVkxMjOXv729FR0e73JCQnp5uRUVFWT4+Ptbdd9/tXH/33Xetjh07WgEBAVaDBg2su+66y1q+fLnz8U2bNlnx8fFWQECA1bFjR2vZsmVu32AxZcoUKyIiwgoODrbuv/9+6+2337YkWadOnbIs6+INFiEhIdayZcusFi1aWAEBAVbv3r2t/fv3uxx3zZo1Vvfu3a3g4GDLbrdbXbt2td544w3n4+IGC1STzbI8cPEbAIAaxL+zAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxvs/UUDZlkRw538AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Step 6 - Use model to make predictions\n",
    "modelz = model\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = (modelz.predict(X_train)> 0.5).astype(int)\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = (modelz.predict(X_test)> 0.5).astype(int)\n",
    "#> 0.01).astype(int)\n",
    "\n",
    "\n",
    "##### Step 7 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('-------------------- Model Summary --------------------')\n",
    "modelz.summary() # print model summary\n",
    "print(\"\")\n",
    "print('-------------------- Weights and Biases --------------------')\n",
    "for layer in modelz.layers:\n",
    "    print(\"Layer: \", layer.name) # print layer name\n",
    "    \n",
    "print(\"\")\n",
    "print('---------- Evaluation on Training Data ----------')\n",
    "print(classification_report(y_train, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('---------- Evaluation on Test Data ----------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te)).plot(colorbar=False,cmap=plt.cm.Blues)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te,normalize='true')).plot(colorbar=False,cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "702c88cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61f82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37f0eaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0031 - Accuracy: 0.0071 - val_loss: 0.0798 - val_Accuracy: 0.0066\n",
      "Epoch 2/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0035 - Accuracy: 0.0071 - val_loss: 0.0801 - val_Accuracy: 0.0066\n",
      "Epoch 3/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0026 - Accuracy: 0.0071 - val_loss: 0.0803 - val_Accuracy: 0.0066\n",
      "Epoch 4/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0041 - Accuracy: 0.0071 - val_loss: 0.0804 - val_Accuracy: 0.0066\n",
      "Epoch 5/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0035 - Accuracy: 0.0071 - val_loss: 0.0805 - val_Accuracy: 0.0066\n",
      "Epoch 6/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0035 - Accuracy: 0.0071 - val_loss: 0.0806 - val_Accuracy: 0.0066\n",
      "Epoch 7/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0041 - Accuracy: 0.0071 - val_loss: 0.0806 - val_Accuracy: 0.0066\n",
      "Epoch 8/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0031 - Accuracy: 0.0071 - val_loss: 0.0807 - val_Accuracy: 0.0066\n",
      "Epoch 9/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0034 - Accuracy: 0.0071 - val_loss: 0.0807 - val_Accuracy: 0.0066\n",
      "Epoch 10/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0043 - Accuracy: 0.0071 - val_loss: 0.0806 - val_Accuracy: 0.0066\n",
      "Epoch 11/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0031 - Accuracy: 0.0071 - val_loss: 0.0807 - val_Accuracy: 0.0066\n",
      "Epoch 12/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0028 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 13/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0035 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 14/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0042 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 15/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0030 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 16/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0040 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 17/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0038 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 18/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0025 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 19/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0031 - Accuracy: 0.0071 - val_loss: 0.0809 - val_Accuracy: 0.0066\n",
      "Epoch 20/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0044 - Accuracy: 0.0071 - val_loss: 0.0809 - val_Accuracy: 0.0066\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# lrate = initial_lrate * (1 / (1 + decay * iteration))\n",
    "opt = SGD(lr=0.001, momentum=0.9, decay=0.01)\n",
    "\n",
    "##### Step 2 - Compile keras model\n",
    "model.compile(optimizer=opt, # default='rmsprop', an algorithm to be used in backpropagation\n",
    "              loss='binary_crossentropy', # Loss function to be optimized. A string (name of loss function), or a tf.keras.losses.Loss instance.\n",
    "              metrics=['Accuracy'], # List of metrics to be evaluated by the model during training and testing. Each of this can be a string (name of a built-in function), function or a tf.keras.metrics.Metric instance. \n",
    "              loss_weights=None, # default=None, Optional list or dictionary specifying scalar coefficients (Python floats) to weight the loss contributions of different model outputs.\n",
    "              weighted_metrics=None, # default=None, List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing.\n",
    "              run_eagerly=None, # Defaults to False. If True, this Model's logic will not be wrapped in a tf.function. Recommended to leave this as None unless your Model cannot be run inside a tf.function.\n",
    "              steps_per_execution=None # Defaults to 1. The number of batches to run during each tf.function call. Running multiple batches inside a single tf.function call can greatly improve performance on TPUs or small models with a large Python overhead.\n",
    "             )\n",
    "\n",
    "\n",
    "##### Step 3 - Fit keras model on the dataset\n",
    "history = model.fit(X_train, # input data\n",
    "                    y_train, # target data\n",
    "                    #batch_size=1, # Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "                    epochs=20, # default=1, Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided\n",
    "                    #verbose=0, # default='auto', ('auto', 0, 1, or 2). Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 'auto' defaults to 1 for most cases, but 2 when used with ParameterServerStrategy.\n",
    "                    callbacks=None, # default=None, list of callbacks to apply during training. See tf.keras.callbacks\n",
    "                    #validation_split=0.0, # default=0.0, Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. \n",
    "                    validation_data=(X_valid, y_validation), # default=None, Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "                    #shuffle=True, # default=True, Boolean (whether to shuffle the training data before each epoch) or str (for 'batch').\n",
    "                    #class_weight=None, # default=None, Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "                    #sample_weight=None, # default=None, Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only).\n",
    "                    #initial_epoch=0, # Integer, default=0, Epoch at which to start training (useful for resuming a previous training run).\n",
    "                    #steps_per_epoch=None, # Integer or None, default=None, Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. \n",
    "                    #validation_steps=None, # Only relevant if validation_data is provided and is a tf.data dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch.\n",
    "                    #validation_batch_size=None, # Integer or None, default=None, Number of samples per validation batch. If unspecified, will default to batch_size.\n",
    "                    #validation_freq=1, # default=1, Only relevant if validation data is provided. If an integer, specifies how many training epochs to run before a new validation run is performed, e.g. validation_freq=2 runs validation every 2 epochs.\n",
    "                    #max_queue_size=10, # default=10, Used for generator or keras.utils.Sequence input only. Maximum size for the generator queue. If unspecified, max_queue_size will default to 10.\n",
    "                    #workers=1, # default=1, Used for generator or keras.utils.Sequence input only. Maximum number of processes to spin up when using process-based threading. If unspecified, workers will default to 1.\n",
    "                    #use_multiprocessing=False, # default=False, Used for generator or keras.utils.Sequence input only. If True, use process-based threading. If unspecified, use_multiprocessing will default to False. \n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "858b92b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 1s 2ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "\n",
      "-------------------- Model Summary --------------------\n",
      "Model: \"DCN-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " 2D-Convolutional-Layer-1 (C  (None, 11, 27, 16)       1168      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-1 (MaxPool  (None, 5, 13, 16)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-1 (Dropout)   (None, 5, 13, 16)         0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-2 (C  (None, 3, 11, 64)        9280      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-2 (MaxPool  (None, 1, 5, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-2 (Dropout)   (None, 1, 5, 64)          0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-3 (C  (None, 1, 5, 64)         36928     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-3 (MaxPool  (None, 1, 3, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-3 (Dropout)   (None, 1, 3, 64)          0         \n",
      "                                                                 \n",
      " Flatten-Layer (Flatten)     (None, 192)               0         \n",
      "                                                                 \n",
      " Hidden-Layer-1 (Dense)      (None, 16)                3088      \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,481\n",
      "Trainable params: 50,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "-------------------- Weights and Biases --------------------\n",
      "Layer:  2D-Convolutional-Layer-1\n",
      "Layer:  2D-MaxPool-Layer-1\n",
      "Layer:  Dropout-Layer-1\n",
      "Layer:  2D-Convolutional-Layer-2\n",
      "Layer:  2D-MaxPool-Layer-2\n",
      "Layer:  Dropout-Layer-2\n",
      "Layer:  2D-Convolutional-Layer-3\n",
      "Layer:  2D-MaxPool-Layer-3\n",
      "Layer:  Dropout-Layer-3\n",
      "Layer:  Flatten-Layer\n",
      "Layer:  Hidden-Layer-1\n",
      "Layer:  Output-Layer\n",
      "\n",
      "---------- Evaluation on Training Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     11243\n",
      "         1.0       0.01      1.00      0.01        80\n",
      "\n",
      "    accuracy                           0.01     11323\n",
      "   macro avg       0.00      0.50      0.01     11323\n",
      "weighted avg       0.00      0.01      0.00     11323\n",
      "\n",
      "\n",
      "---------- Evaluation on Test Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      1416\n",
      "         1.0       0.01      1.00      0.02        15\n",
      "\n",
      "    accuracy                           0.01      1431\n",
      "   macro avg       0.01      0.50      0.01      1431\n",
      "weighted avg       0.00      0.01      0.00      1431\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f835a1d7dc0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Step 6 - Use model to make predictions\n",
    "modelz = model\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = (modelz.predict(X_train)> 0.1).astype(int)\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = (modelz.predict(X_test)> 0.1).astype(int)\n",
    "#> 0.01).astype(int)\n",
    "\n",
    "\n",
    "##### Step 7 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('-------------------- Model Summary --------------------')\n",
    "modelz.summary() # print model summary\n",
    "print(\"\")\n",
    "print('-------------------- Weights and Biases --------------------')\n",
    "for layer in modelz.layers:\n",
    "    print(\"Layer: \", layer.name) # print layer name\n",
    "    \n",
    "print(\"\")\n",
    "print('---------- Evaluation on Training Data ----------')\n",
    "print(classification_report(y_train, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('---------- Evaluation on Test Data ----------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te)).plot(colorbar=False,cmap=plt.cm.Blues)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te,normalize='true')).plot(colorbar=False,cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1984527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelz.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91b3494a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.4271133 ,  1.3750889 , -0.36706957, ..., -0.72164124,\n",
       "          0.46097258, -1.5882549 ],\n",
       "        [ 0.21911433,  1.3728257 , -0.40889373, ..., -0.7675293 ,\n",
       "          0.6784405 , -1.5882549 ],\n",
       "        [ 0.4211898 ,  1.2755808 , -0.5481757 , ..., -0.751221  ,\n",
       "          1.1470692 , -1.5882549 ],\n",
       "        ...,\n",
       "        [ 1.8873287 ,  1.3200705 , -0.32587594, ..., -0.5681132 ,\n",
       "          2.5245645 ,  0.6460893 ],\n",
       "        [ 1.9649917 ,  1.205714  , -0.37440342, ..., -0.0285605 ,\n",
       "          1.8790027 ,  0.64933926],\n",
       "        [ 1.035885  ,  1.0905316 , -0.18530034, ...,  0.24728519,\n",
       "          1.2652528 ,  0.6503019 ]],\n",
       "\n",
       "       [[ 0.6468425 ,  1.3257917 , -0.4029256 , ..., -0.5522619 ,\n",
       "          0.8381844 , -1.5882549 ],\n",
       "        [ 0.67109096,  1.2544683 , -0.6589153 , ..., -0.4843103 ,\n",
       "          1.7563723 , -1.5882549 ],\n",
       "        [ 0.5968568 ,  1.1915245 , -0.7871699 , ..., -0.09679794,\n",
       "          1.77835   , -1.5882549 ],\n",
       "        ...,\n",
       "        [ 0.9459548 ,  1.2310246 , -0.25974983, ..., -0.45370817,\n",
       "          3.5056925 ,  0.64907855],\n",
       "        [ 0.66603345,  1.1657215 , -0.29181755, ...,  0.12942715,\n",
       "          3.1896245 ,  0.64998865],\n",
       "        [-0.415342  ,  1.1909032 , -0.02850859, ...,  0.31313476,\n",
       "          2.1086996 ,  0.6504472 ]],\n",
       "\n",
       "       [[ 0.46381202,  1.203677  , -0.8237718 , ..., -0.71136576,\n",
       "          1.219587  , -1.5882549 ],\n",
       "        [ 0.53084815,  1.2029467 , -0.893117  , ..., -0.5437536 ,\n",
       "          1.6776118 , -1.5882549 ],\n",
       "        [ 0.7593866 ,  1.050658  , -0.910638  , ..., -0.29477957,\n",
       "          1.3849756 , -1.5882549 ],\n",
       "        ...,\n",
       "        [-1.5059763 ,  0.8916963 , -0.16684903, ..., -0.43345875,\n",
       "          2.1348674 ,  0.6507494 ],\n",
       "        [-0.96365887,  0.9232201 , -0.10562646, ..., -0.1756092 ,\n",
       "          1.4212346 ,  0.6513788 ],\n",
       "        [-0.5549505 ,  0.89637697,  0.02181227, ...,  0.05965724,\n",
       "          0.36203024,  0.65100884]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.13380767, -0.62399745,  0.15919921, ...,  2.0028815 ,\n",
       "         -1.4220096 , -1.5882549 ],\n",
       "        [-3.7811956 , -0.61070424,  0.08230821, ...,  0.7299504 ,\n",
       "         -1.2947617 , -1.5882549 ],\n",
       "        [-0.81028086, -0.23457216,  0.02535266, ..., -2.0662794 ,\n",
       "         -0.5061308 , -1.5882549 ],\n",
       "        ...,\n",
       "        [ 0.18498233, -0.97399634,  0.18287484, ...,  0.1859756 ,\n",
       "         -0.71658653,  0.61504644],\n",
       "        [ 0.01905681, -0.5684075 , -0.17589733, ...,  0.50491667,\n",
       "         -0.7159873 ,  0.6179657 ],\n",
       "        [ 0.47339582, -0.30412638, -0.3461815 , ...,  0.9096021 ,\n",
       "         -0.7208621 ,  0.6149864 ]],\n",
       "\n",
       "       [[ 1.3221638 , -0.95858586,  0.81400687, ...,  2.343449  ,\n",
       "         -1.3351249 , -1.5882549 ],\n",
       "        [-1.7697463 , -0.7890165 ,  0.7778574 , ...,  1.9982779 ,\n",
       "         -1.2227571 , -1.5882549 ],\n",
       "        [-1.0588918 , -0.6532864 ,  0.6708573 , ..., -0.30773082,\n",
       "         -0.751818  , -1.5882549 ],\n",
       "        ...,\n",
       "        [ 1.0008578 , -0.12980169,  0.4383374 , ..., -0.0089766 ,\n",
       "         -0.52930593,  0.6129308 ],\n",
       "        [ 1.222959  , -0.12159996,  0.16181223, ...,  0.5153789 ,\n",
       "         -0.50835377,  0.6141164 ],\n",
       "        [ 1.1444147 , -0.2412005 ,  0.05792738, ...,  1.0705441 ,\n",
       "         -0.6476595 ,  0.61108696]],\n",
       "\n",
       "       [[ 0.99423003, -1.3800368 ,  1.3856428 , ...,  2.33719   ,\n",
       "         -1.1869247 , -1.5882549 ],\n",
       "        [-0.8030964 , -0.9053325 ,  1.4207811 , ...,  1.6400063 ,\n",
       "         -1.3875458 , -1.5882549 ],\n",
       "        [-2.5357256 , -0.7962381 ,  1.4130167 , ...,  0.7940631 ,\n",
       "         -1.1669997 , -1.5882549 ],\n",
       "        ...,\n",
       "        [ 1.1057992 ,  0.15718514,  0.70052594, ...,  0.4772637 ,\n",
       "         -0.48269886,  0.6092296 ],\n",
       "        [ 0.73255193, -0.23911293,  0.53792226, ...,  0.7263566 ,\n",
       "         -0.4875739 ,  0.6085662 ],\n",
       "        [ 1.0011225 , -0.54155976,  0.46508208, ...,  1.060784  ,\n",
       "         -0.54307383,  0.6063011 ]]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7262f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57001dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 29, 8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e58a8f85",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (13, 29, 8) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m imgplot \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/matplotlib/_api/deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[1;32m    454\u001b[0m     warn_deprecated(\n\u001b[1;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/matplotlib/pyplot.py:2652\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   2647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   2648\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2649\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   2650\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filternorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filterrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.0\u001b[39m,\n\u001b[1;32m   2651\u001b[0m         resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2652\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2659\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2660\u001b[0m     sci(__ret)\n\u001b[1;32m   2661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/matplotlib/_api/deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[1;32m    454\u001b[0m     warn_deprecated(\n\u001b[1;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/matplotlib/__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1414\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1415\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1416\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5481\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5474\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5475\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap, norm, interpolation,\n\u001b[1;32m   5476\u001b[0m                       origin, extent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[1;32m   5477\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[1;32m   5478\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[1;32m   5479\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5481\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5482\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5484\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/matplotlib/image.py:715\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    716\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (13, 29, 8) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "imgplot = plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c317cb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
