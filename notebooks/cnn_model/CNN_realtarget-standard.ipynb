{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051c21fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.4.4\n",
      "xarray: 0.20.1\n",
      "geopandas: 1.22.3\n",
      "Tensorflow/Keras: 2.9.0\n",
      "pandas: 1.4.4\n",
      "numpy: 1.22.3\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__)\n",
    "\n",
    "import xarray as xr\n",
    "print('xarray: %s' % xr.__version__)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_rows', 150)\n",
    "\n",
    "import numpy as np\n",
    "print('geopandas: %s' % np.__version__)\n",
    "\n",
    "# Tensorflow / Keras\n",
    "import tensorflow as tf # used to access argmax function\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Dense # for creating regular densely-connected NN layer.\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout # for adding Concolutional and densely-connected NN layers.\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "\n",
    "import decimal\n",
    "from decimal import Decimal\n",
    "\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout,BatchNormalization,Conv2D,MaxPooling2D,Dense,Flatten\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import callbacks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense # for creating regular densely-connected NN layer.\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout,MaxPooling2D # for adding Concolutional and densely-connected NN layers.\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from pathlib import Path  \n",
    "\n",
    "from sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n",
    "from sklearn.metrics import classification_report # for model evaluation metrics\n",
    "from sklearn.preprocessing import OrdinalEncoder # for encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89dcffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('Real_Tomorrow/test_real_tom_target.csv')\n",
    "validation_set = pd.read_csv('Real_Tomorrow/validation_real_tom_target.csv')\n",
    "training_set = pd.read_csv('Real_Tomorrow/training_real_tom_target.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb9a5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>80.761185</td>\n",
       "      <td>1.909660</td>\n",
       "      <td>-3.323872</td>\n",
       "      <td>1.687164</td>\n",
       "      <td>-1.823624</td>\n",
       "      <td>-247.54074</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>80.703650</td>\n",
       "      <td>1.165733</td>\n",
       "      <td>-2.844494</td>\n",
       "      <td>1.060593</td>\n",
       "      <td>-1.991425</td>\n",
       "      <td>-240.00592</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>78.231514</td>\n",
       "      <td>-1.311676</td>\n",
       "      <td>-2.125244</td>\n",
       "      <td>3.280617</td>\n",
       "      <td>-1.931789</td>\n",
       "      <td>-223.76889</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>79.631010</td>\n",
       "      <td>-3.777573</td>\n",
       "      <td>-1.122395</td>\n",
       "      <td>5.743889</td>\n",
       "      <td>-1.243538</td>\n",
       "      <td>-235.55556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>71.573875</td>\n",
       "      <td>-5.734505</td>\n",
       "      <td>-1.362953</td>\n",
       "      <td>6.514030</td>\n",
       "      <td>-0.954163</td>\n",
       "      <td>-254.03260</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268766</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>26.797535</td>\n",
       "      <td>25.075424</td>\n",
       "      <td>-3.653679</td>\n",
       "      <td>-1.221291</td>\n",
       "      <td>1.515594</td>\n",
       "      <td>-273.34204</td>\n",
       "      <td>296.89227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268767</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>27.766910</td>\n",
       "      <td>24.175919</td>\n",
       "      <td>-2.866638</td>\n",
       "      <td>-6.724304</td>\n",
       "      <td>0.861771</td>\n",
       "      <td>-280.37018</td>\n",
       "      <td>296.03314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268768</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>29.111805</td>\n",
       "      <td>24.655510</td>\n",
       "      <td>-2.809170</td>\n",
       "      <td>-10.138817</td>\n",
       "      <td>0.051220</td>\n",
       "      <td>-281.05167</td>\n",
       "      <td>295.36078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268769</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27.833050</td>\n",
       "      <td>25.088104</td>\n",
       "      <td>-2.730087</td>\n",
       "      <td>-11.036507</td>\n",
       "      <td>0.666927</td>\n",
       "      <td>-280.05610</td>\n",
       "      <td>295.10638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268770</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>15.843884</td>\n",
       "      <td>24.510345</td>\n",
       "      <td>-3.213837</td>\n",
       "      <td>-10.213325</td>\n",
       "      <td>-0.098499</td>\n",
       "      <td>-279.40427</td>\n",
       "      <td>294.44766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4268771 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time  latitude  longitude        vo          r      u_200  \\\n",
       "0        1980-01-01       0.0       20.0  0.000007  80.761185   1.909660   \n",
       "1        1980-01-01       0.0       22.5  0.000004  80.703650   1.165733   \n",
       "2        1980-01-01       0.0       25.0  0.000007  78.231514  -1.311676   \n",
       "3        1980-01-01       0.0       27.5  0.000010  79.631010  -3.777573   \n",
       "4        1980-01-01       0.0       30.0  0.000010  71.573875  -5.734505   \n",
       "...             ...       ...        ...       ...        ...        ...   \n",
       "4268766  2010-12-31     -30.0       80.0  0.000015  26.797535  25.075424   \n",
       "4268767  2010-12-31     -30.0       82.5 -0.000006  27.766910  24.175919   \n",
       "4268768  2010-12-31     -30.0       85.0  0.000010  29.111805  24.655510   \n",
       "4268769  2010-12-31     -30.0       87.5  0.000006  27.833050  25.088104   \n",
       "4268770  2010-12-31     -30.0       90.0  0.000007  15.843884  24.510345   \n",
       "\n",
       "            u_850      v_200     v_850        ttr        sst  lsm  \\\n",
       "0       -3.323872   1.687164 -1.823624 -247.54074    0.00000  0.0   \n",
       "1       -2.844494   1.060593 -1.991425 -240.00592    0.00000  0.0   \n",
       "2       -2.125244   3.280617 -1.931789 -223.76889    0.00000  0.0   \n",
       "3       -1.122395   5.743889 -1.243538 -235.55556    0.00000  0.0   \n",
       "4       -1.362953   6.514030 -0.954163 -254.03260    0.00000  0.0   \n",
       "...           ...        ...       ...        ...        ...  ...   \n",
       "4268766 -3.653679  -1.221291  1.515594 -273.34204  296.89227  0.0   \n",
       "4268767 -2.866638  -6.724304  0.861771 -280.37018  296.03314  0.0   \n",
       "4268768 -2.809170 -10.138817  0.051220 -281.05167  295.36078  0.0   \n",
       "4268769 -2.730087 -11.036507  0.666927 -280.05610  295.10638  0.0   \n",
       "4268770 -3.213837 -10.213325 -0.098499 -279.40427  294.44766  0.0   \n",
       "\n",
       "         Real_tom_lsm  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "4268766           0.0  \n",
       "4268767           0.0  \n",
       "4268768           0.0  \n",
       "4268769           0.0  \n",
       "4268770           0.0  \n",
       "\n",
       "[4268771 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data set\n",
    "training_set_wt = training_set.drop(columns=['Unnamed: 0'])\n",
    "training_set_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e35108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>73.016390</td>\n",
       "      <td>-5.760780</td>\n",
       "      <td>-4.216808</td>\n",
       "      <td>6.860649</td>\n",
       "      <td>-4.352928</td>\n",
       "      <td>-212.59741</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>74.569660</td>\n",
       "      <td>-4.942451</td>\n",
       "      <td>-3.857407</td>\n",
       "      <td>6.459419</td>\n",
       "      <td>-3.991157</td>\n",
       "      <td>-198.23593</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>80.080090</td>\n",
       "      <td>-3.848740</td>\n",
       "      <td>-3.175144</td>\n",
       "      <td>6.303680</td>\n",
       "      <td>-3.446140</td>\n",
       "      <td>-195.83296</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>83.676704</td>\n",
       "      <td>0.330811</td>\n",
       "      <td>-2.526569</td>\n",
       "      <td>7.235268</td>\n",
       "      <td>-2.307594</td>\n",
       "      <td>-191.47444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>76.225440</td>\n",
       "      <td>3.678749</td>\n",
       "      <td>-1.027561</td>\n",
       "      <td>7.020271</td>\n",
       "      <td>-0.077572</td>\n",
       "      <td>-191.98111</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688397</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>70.662056</td>\n",
       "      <td>23.560066</td>\n",
       "      <td>1.655861</td>\n",
       "      <td>9.690376</td>\n",
       "      <td>3.621418</td>\n",
       "      <td>-271.57556</td>\n",
       "      <td>296.77530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688398</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>51.213654</td>\n",
       "      <td>22.381706</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>9.860390</td>\n",
       "      <td>-0.099480</td>\n",
       "      <td>-269.94592</td>\n",
       "      <td>296.44290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688399</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>46.678970</td>\n",
       "      <td>22.464828</td>\n",
       "      <td>0.851299</td>\n",
       "      <td>7.661758</td>\n",
       "      <td>-0.725330</td>\n",
       "      <td>-270.18890</td>\n",
       "      <td>295.73486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688400</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>59.362090</td>\n",
       "      <td>22.364807</td>\n",
       "      <td>0.543045</td>\n",
       "      <td>5.595253</td>\n",
       "      <td>-1.542034</td>\n",
       "      <td>-264.07333</td>\n",
       "      <td>295.24792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688401</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>65.915980</td>\n",
       "      <td>23.052147</td>\n",
       "      <td>0.048565</td>\n",
       "      <td>1.080147</td>\n",
       "      <td>-1.203087</td>\n",
       "      <td>-259.79480</td>\n",
       "      <td>295.79680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688402 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  latitude  longitude        vo          r      u_200  \\\n",
       "0       2011-01-01       0.0       20.0  0.000003  73.016390  -5.760780   \n",
       "1       2011-01-01       0.0       22.5  0.000003  74.569660  -4.942451   \n",
       "2       2011-01-01       0.0       25.0  0.000004  80.080090  -3.848740   \n",
       "3       2011-01-01       0.0       27.5  0.000012  83.676704   0.330811   \n",
       "4       2011-01-01       0.0       30.0  0.000011  76.225440   3.678749   \n",
       "...            ...       ...        ...       ...        ...        ...   \n",
       "688397  2015-12-31     -30.0       80.0  0.000014  70.662056  23.560066   \n",
       "688398  2015-12-31     -30.0       82.5 -0.000006  51.213654  22.381706   \n",
       "688399  2015-12-31     -30.0       85.0  0.000009  46.678970  22.464828   \n",
       "688400  2015-12-31     -30.0       87.5  0.000002  59.362090  22.364807   \n",
       "688401  2015-12-31     -30.0       90.0  0.000014  65.915980  23.052147   \n",
       "\n",
       "           u_850     v_200     v_850        ttr        sst  lsm  Real_tom_lsm  \n",
       "0      -4.216808  6.860649 -4.352928 -212.59741    0.00000  0.0           0.0  \n",
       "1      -3.857407  6.459419 -3.991157 -198.23593    0.00000  0.0           0.0  \n",
       "2      -3.175144  6.303680 -3.446140 -195.83296    0.00000  0.0           0.0  \n",
       "3      -2.526569  7.235268 -2.307594 -191.47444    0.00000  0.0           0.0  \n",
       "4      -1.027561  7.020271 -0.077572 -191.98111    0.00000  0.0           0.0  \n",
       "...          ...       ...       ...        ...        ...  ...           ...  \n",
       "688397  1.655861  9.690376  3.621418 -271.57556  296.77530  0.0           0.0  \n",
       "688398  0.321705  9.860390 -0.099480 -269.94592  296.44290  0.0           0.0  \n",
       "688399  0.851299  7.661758 -0.725330 -270.18890  295.73486  0.0           0.0  \n",
       "688400  0.543045  5.595253 -1.542034 -264.07333  295.24792  0.0           0.0  \n",
       "688401  0.048565  1.080147 -1.203087 -259.79480  295.79680  0.0           0.0  \n",
       "\n",
       "[688402 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation data set\n",
    "validation_set_wt = validation_set.drop(columns=['Unnamed: 0'])\n",
    "validation_set_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bc8fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>80.796135</td>\n",
       "      <td>-2.052292</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>4.996910</td>\n",
       "      <td>-1.678764</td>\n",
       "      <td>-272.04962</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>77.748420</td>\n",
       "      <td>-4.445312</td>\n",
       "      <td>0.740505</td>\n",
       "      <td>7.517281</td>\n",
       "      <td>0.792618</td>\n",
       "      <td>-250.63333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>71.178825</td>\n",
       "      <td>-3.778427</td>\n",
       "      <td>1.056324</td>\n",
       "      <td>9.333221</td>\n",
       "      <td>0.688252</td>\n",
       "      <td>-229.52519</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>73.585754</td>\n",
       "      <td>-4.695709</td>\n",
       "      <td>1.236446</td>\n",
       "      <td>9.589882</td>\n",
       "      <td>0.555519</td>\n",
       "      <td>-240.80815</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>72.382780</td>\n",
       "      <td>-4.002563</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>5.410950</td>\n",
       "      <td>-1.086350</td>\n",
       "      <td>-262.45557</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539482</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.637233</td>\n",
       "      <td>33.277840</td>\n",
       "      <td>5.379345</td>\n",
       "      <td>-0.286896</td>\n",
       "      <td>5.558327</td>\n",
       "      <td>-277.60870</td>\n",
       "      <td>294.14987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539483</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>23.660923</td>\n",
       "      <td>34.272537</td>\n",
       "      <td>6.438683</td>\n",
       "      <td>-13.026535</td>\n",
       "      <td>2.857349</td>\n",
       "      <td>-270.80573</td>\n",
       "      <td>294.23798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539484</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>46.051540</td>\n",
       "      <td>35.755882</td>\n",
       "      <td>7.248966</td>\n",
       "      <td>-18.870102</td>\n",
       "      <td>-3.349407</td>\n",
       "      <td>-249.43092</td>\n",
       "      <td>294.26890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539485</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>55.855648</td>\n",
       "      <td>34.069664</td>\n",
       "      <td>6.349327</td>\n",
       "      <td>-18.801796</td>\n",
       "      <td>-8.172478</td>\n",
       "      <td>-239.36870</td>\n",
       "      <td>294.36630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539486</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>61.602300</td>\n",
       "      <td>29.167267</td>\n",
       "      <td>4.805676</td>\n",
       "      <td>-15.093590</td>\n",
       "      <td>-9.708778</td>\n",
       "      <td>-251.60574</td>\n",
       "      <td>293.74924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539487 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  latitude  longitude        vo          r      u_200  \\\n",
       "0       2016-01-01       0.0       20.0  0.000011  80.796135  -2.052292   \n",
       "1       2016-01-01       0.0       22.5  0.000011  77.748420  -4.445312   \n",
       "2       2016-01-01       0.0       25.0 -0.000001  71.178825  -3.778427   \n",
       "3       2016-01-01       0.0       27.5 -0.000005  73.585754  -4.695709   \n",
       "4       2016-01-01       0.0       30.0 -0.000016  72.382780  -4.002563   \n",
       "...            ...       ...        ...       ...        ...        ...   \n",
       "539482  2019-12-01     -30.0       80.0  0.000006   2.637233  33.277840   \n",
       "539483  2019-12-01     -30.0       82.5 -0.000020  23.660923  34.272537   \n",
       "539484  2019-12-01     -30.0       85.0 -0.000019  46.051540  35.755882   \n",
       "539485  2019-12-01     -30.0       87.5 -0.000014  55.855648  34.069664   \n",
       "539486  2019-12-01     -30.0       90.0  0.000006  61.602300  29.167267   \n",
       "\n",
       "           u_850      v_200     v_850        ttr        sst  lsm  Real_tom_lsm  \n",
       "0       0.008678   4.996910 -1.678764 -272.04962    0.00000  0.0           0.0  \n",
       "1       0.740505   7.517281  0.792618 -250.63333    0.00000  0.0           0.0  \n",
       "2       1.056324   9.333221  0.688252 -229.52519    0.00000  0.0           0.0  \n",
       "3       1.236446   9.589882  0.555519 -240.80815    0.00000  0.0           0.0  \n",
       "4       0.734211   5.410950 -1.086350 -262.45557    0.00000  0.0           0.0  \n",
       "...          ...        ...       ...        ...        ...  ...           ...  \n",
       "539482  5.379345  -0.286896  5.558327 -277.60870  294.14987  0.0           0.0  \n",
       "539483  6.438683 -13.026535  2.857349 -270.80573  294.23798  0.0           0.0  \n",
       "539484  7.248966 -18.870102 -3.349407 -249.43092  294.26890  0.0           0.0  \n",
       "539485  6.349327 -18.801796 -8.172478 -239.36870  294.36630  0.0           0.0  \n",
       "539486  4.805676 -15.093590 -9.708778 -251.60574  293.74924  0.0           0.0  \n",
       "\n",
       "[539487 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data set\n",
    "test_set_wt = test_set.drop(columns=['Unnamed: 0'])\n",
    "test_set_wt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da2f63",
   "metadata": {},
   "source": [
    "# Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dfe51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#scaled_x_training = scaler.fit_transform(x_training)\n",
    "#df = pd.DataFrame(StandardScaler().fit_transform(x_training))\n",
    "\n",
    "X_train_stand = training_set_wt.copy()\n",
    "X_valid_stand = validation_set_wt.copy()\n",
    "X_test_stand = test_set_wt.copy()\n",
    "\n",
    "\n",
    "num_cols = [ 'vo', 'r', 'u_200', 'u_850', 'v_200','v_850', 'ttr','sst']\n",
    "\n",
    "# apply standardization on numerical features\n",
    "for i in num_cols:\n",
    "    \n",
    "    # fit on training data column\n",
    "    scale = StandardScaler().fit(X_train_stand[[i]])\n",
    "    \n",
    "    # transform the training data column\n",
    "    X_train_stand[i] = scale.transform(X_train_stand[[i]])\n",
    "    \n",
    "    # transform the training data column\n",
    "    X_valid_stand[i] = scale.transform(X_valid_stand[[i]])   \n",
    "\n",
    "    # transform the testing data column\n",
    "    X_test_stand[i] = scale.transform(X_test_stand[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c96795ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vo</th>\n",
       "      <th>r</th>\n",
       "      <th>u_200</th>\n",
       "      <th>u_850</th>\n",
       "      <th>v_200</th>\n",
       "      <th>v_850</th>\n",
       "      <th>ttr</th>\n",
       "      <th>sst</th>\n",
       "      <th>lsm</th>\n",
       "      <th>Real_tom_lsm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.427113</td>\n",
       "      <td>1.375089</td>\n",
       "      <td>-0.367070</td>\n",
       "      <td>-0.185388</td>\n",
       "      <td>0.412678</td>\n",
       "      <td>-0.721641</td>\n",
       "      <td>0.460973</td>\n",
       "      <td>-1.588255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.219114</td>\n",
       "      <td>1.372826</td>\n",
       "      <td>-0.408894</td>\n",
       "      <td>-0.087275</td>\n",
       "      <td>0.339019</td>\n",
       "      <td>-0.767529</td>\n",
       "      <td>0.678441</td>\n",
       "      <td>-1.588255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.421190</td>\n",
       "      <td>1.275581</td>\n",
       "      <td>-0.548176</td>\n",
       "      <td>0.059933</td>\n",
       "      <td>0.600002</td>\n",
       "      <td>-0.751221</td>\n",
       "      <td>1.147069</td>\n",
       "      <td>-1.588255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.618823</td>\n",
       "      <td>1.330632</td>\n",
       "      <td>-0.686810</td>\n",
       "      <td>0.265184</td>\n",
       "      <td>0.889582</td>\n",
       "      <td>-0.563007</td>\n",
       "      <td>0.806886</td>\n",
       "      <td>-1.588255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.639442</td>\n",
       "      <td>1.013693</td>\n",
       "      <td>-0.796831</td>\n",
       "      <td>0.215949</td>\n",
       "      <td>0.980119</td>\n",
       "      <td>-0.483872</td>\n",
       "      <td>0.273606</td>\n",
       "      <td>-1.588255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268766</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.944351</td>\n",
       "      <td>-0.747649</td>\n",
       "      <td>0.935328</td>\n",
       "      <td>-0.252889</td>\n",
       "      <td>0.070764</td>\n",
       "      <td>0.191525</td>\n",
       "      <td>-0.283698</td>\n",
       "      <td>0.612925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268767</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>-0.453259</td>\n",
       "      <td>-0.709517</td>\n",
       "      <td>0.884757</td>\n",
       "      <td>-0.091807</td>\n",
       "      <td>-0.576164</td>\n",
       "      <td>0.012726</td>\n",
       "      <td>-0.486542</td>\n",
       "      <td>0.606555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268768</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.636774</td>\n",
       "      <td>-0.656614</td>\n",
       "      <td>0.911720</td>\n",
       "      <td>-0.080045</td>\n",
       "      <td>-0.977570</td>\n",
       "      <td>-0.208933</td>\n",
       "      <td>-0.506211</td>\n",
       "      <td>0.601571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268769</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.368231</td>\n",
       "      <td>-0.706915</td>\n",
       "      <td>0.936041</td>\n",
       "      <td>-0.063859</td>\n",
       "      <td>-1.083102</td>\n",
       "      <td>-0.040557</td>\n",
       "      <td>-0.477477</td>\n",
       "      <td>0.599684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268770</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.462658</td>\n",
       "      <td>-1.178526</td>\n",
       "      <td>0.903559</td>\n",
       "      <td>-0.162867</td>\n",
       "      <td>-0.986329</td>\n",
       "      <td>-0.249876</td>\n",
       "      <td>-0.458664</td>\n",
       "      <td>0.594801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4268771 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time  latitude  longitude        vo         r     u_200  \\\n",
       "0        1980-01-01       0.0       20.0  0.427113  1.375089 -0.367070   \n",
       "1        1980-01-01       0.0       22.5  0.219114  1.372826 -0.408894   \n",
       "2        1980-01-01       0.0       25.0  0.421190  1.275581 -0.548176   \n",
       "3        1980-01-01       0.0       27.5  0.618823  1.330632 -0.686810   \n",
       "4        1980-01-01       0.0       30.0  0.639442  1.013693 -0.796831   \n",
       "...             ...       ...        ...       ...       ...       ...   \n",
       "4268766  2010-12-31     -30.0       80.0  0.944351 -0.747649  0.935328   \n",
       "4268767  2010-12-31     -30.0       82.5 -0.453259 -0.709517  0.884757   \n",
       "4268768  2010-12-31     -30.0       85.0  0.636774 -0.656614  0.911720   \n",
       "4268769  2010-12-31     -30.0       87.5  0.368231 -0.706915  0.936041   \n",
       "4268770  2010-12-31     -30.0       90.0  0.462658 -1.178526  0.903559   \n",
       "\n",
       "            u_850     v_200     v_850       ttr       sst  lsm  Real_tom_lsm  \n",
       "0       -0.185388  0.412678 -0.721641  0.460973 -1.588255  0.0           0.0  \n",
       "1       -0.087275  0.339019 -0.767529  0.678441 -1.588255  0.0           0.0  \n",
       "2        0.059933  0.600002 -0.751221  1.147069 -1.588255  0.0           0.0  \n",
       "3        0.265184  0.889582 -0.563007  0.806886 -1.588255  0.0           0.0  \n",
       "4        0.215949  0.980119 -0.483872  0.273606 -1.588255  0.0           0.0  \n",
       "...           ...       ...       ...       ...       ...  ...           ...  \n",
       "4268766 -0.252889  0.070764  0.191525 -0.283698  0.612925  0.0           0.0  \n",
       "4268767 -0.091807 -0.576164  0.012726 -0.486542  0.606555  0.0           0.0  \n",
       "4268768 -0.080045 -0.977570 -0.208933 -0.506211  0.601571  0.0           0.0  \n",
       "4268769 -0.063859 -1.083102 -0.040557 -0.477477  0.599684  0.0           0.0  \n",
       "4268770 -0.162867 -0.986329 -0.249876 -0.458664  0.594801  0.0           0.0  \n",
       "\n",
       "[4268771 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "075b7f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============> data_images_training_set is extracted and saved\n"
     ]
    }
   ],
   "source": [
    "#training set has 11323 days\n",
    "data_images_training_set = np.zeros( (11323,13,29,8), dtype=np.float32 )\n",
    "\n",
    "for days in range(0,11323):\n",
    "    a=X_train_stand.iloc[377*days:377*(days+1),3:11]\n",
    "    for per in range(0,13):\n",
    "        for atr in range(0,29):\n",
    "            data_images_training_set[days,per,atr,:] = a.iloc[(per*29)+atr,:]\n",
    "            \n",
    "type(data_images_training_set)\n",
    "import os  \n",
    "os.makedirs('images/real_images/standard_images', exist_ok=True)\n",
    "np.save('images/real_images/standard_images/data_images_training_set', data_images_training_set)\n",
    "print(\"==============> data_images_training_set is extracted and saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c739ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============> data_images_validation_set is extracted and saved\n"
     ]
    }
   ],
   "source": [
    "#validation set has 1826 days\n",
    "data_images_validation_set = np.zeros( (1826,13,29,8), dtype=np.float32 )\n",
    "\n",
    "for days in range(0,1826):\n",
    "    b=X_valid_stand.iloc[377*days:377*(days+1),3:11]\n",
    "    for per in range(0,13):\n",
    "        for atr in range(0,29):\n",
    "            data_images_validation_set[days,per,atr,:] = a.iloc[(per*29)+atr,:]\n",
    "                    \n",
    "\n",
    "np.save('images/real_images/standard_images/data_images_validation_set', data_images_validation_set)\n",
    "\n",
    "print(\"==============> data_images_validation_set is extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "050fd9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============> data_images_test_set is extracted and saved\n"
     ]
    }
   ],
   "source": [
    "#test set has 1431 days\n",
    "data_images_test_set = np.zeros( (1431,13,29,8), dtype=np.float32 )\n",
    "\n",
    "for days in range(0,1431):\n",
    "    b=X_test_stand.iloc[377*days:377*(days+1),3:11]\n",
    "    for per in range(0,13):\n",
    "        for atr in range(0,29):\n",
    "            data_images_test_set[days,per,atr,:] = a.iloc[(per*29)+atr,:]\n",
    "                    \n",
    "\n",
    "np.save('images/real_images/standard_images/data_images_test_set', data_images_test_set)\n",
    "#loaded_array = np.load('file_name.npy')\n",
    "print(\"==============> data_images_test_set is extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d42385b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images_training_set = np.load('images/real_images/standard_images/data_images_training_set.npy')\n",
    "data_images_validation_set = np.load('images/real_images/standard_images/data_images_validation_set.npy')\n",
    "data_images_test_set = np.load('images/real_images/standard_images/data_images_test_set.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5349b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.3699198 ,  1.4375393 , -0.5122167 , ..., -1.479522  ,\n",
       "           1.014268  , -1.5882549 ],\n",
       "         [ 0.5395018 ,  1.3120407 , -0.53472614, ..., -1.4367177 ,\n",
       "           1.0395807 , -1.5882549 ],\n",
       "         [ 0.69605756,  1.2094198 , -0.5475988 , ..., -1.5780278 ,\n",
       "           0.6318392 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.056734  ,  1.0967445 , -1.7741865 , ..., -0.258732  ,\n",
       "           0.6202094 ,  0.64691883],\n",
       "         [ 0.77006793,  0.88277596, -1.7575761 , ..., -0.59422547,\n",
       "           0.37340927,  0.6470593 ],\n",
       "         [ 0.6897662 ,  0.6141815 , -1.7871565 , ..., -0.9833871 ,\n",
       "           0.01475467,  0.6485754 ]],\n",
       "\n",
       "        [[-0.00547387,  1.2520872 , -0.75133353, ..., -1.2649589 ,\n",
       "           1.4598074 , -1.5882549 ],\n",
       "         [ 0.1731918 ,  1.1778677 , -0.6965681 , ..., -1.3496872 ,\n",
       "           1.0308584 , -1.5882549 ],\n",
       "         [ 0.2974    ,  1.2267771 , -0.6779615 , ..., -1.3143802 ,\n",
       "           1.3000633 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-0.2796858 ,  1.1767899 , -1.4940785 , ..., -0.1472969 ,\n",
       "           1.6638489 ,  0.64618814],\n",
       "         [-0.35191372,  1.1909208 , -1.616141  , ..., -0.73146605,\n",
       "           1.253029  ,  0.64675516],\n",
       "         [ 0.08551692,  1.120073  , -1.6485579 , ..., -1.353379  ,\n",
       "           0.556414  ,  0.64832795]],\n",
       "\n",
       "        [[-0.03236887,  1.1032389 , -0.84543836, ..., -0.8039201 ,\n",
       "           1.5978309 , -1.5882549 ],\n",
       "         [-0.10388847,  1.0822607 , -0.8415235 , ..., -1.0835985 ,\n",
       "           1.7835716 , -1.5882549 ],\n",
       "         [-0.0706263 ,  1.0551329 , -0.78412914, ..., -0.8383038 ,\n",
       "           1.6768476 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-1.5780797 ,  0.8127803 , -1.4838691 , ...,  0.10041277,\n",
       "           0.8516161 ,  0.6452373 ],\n",
       "         [-1.3558266 ,  1.0484176 , -1.4596366 , ..., -0.70004815,\n",
       "           1.3301649 ,  0.64397085],\n",
       "         [-1.0309364 ,  1.2628572 , -1.3829755 , ..., -1.6003219 ,\n",
       "           1.4892248 ,  0.64502007]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9014507 ,  1.265258  , -0.02086635, ..., -1.6976206 ,\n",
       "           1.3469263 , -1.5882549 ],\n",
       "         [ 0.5319456 ,  1.1570402 , -0.2477222 , ..., -1.9658478 ,\n",
       "           0.6109733 , -1.5882549 ],\n",
       "         [ 0.7679294 ,  1.2885116 , -0.362972  , ..., -1.9669015 ,\n",
       "           0.5413632 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.0423845 , -0.11361935,  0.51154596, ..., -0.61837435,\n",
       "          -0.72307956,  0.60708004],\n",
       "         [ 1.9068193 , -0.01136441,  0.47339132, ..., -0.10370702,\n",
       "          -0.7680617 ,  0.60846305],\n",
       "         [ 1.3718673 , -0.37730694,  0.41628996, ...,  0.4352751 ,\n",
       "          -0.82911956,  0.6085289 ]],\n",
       "\n",
       "        [[-1.1314641 ,  1.3619165 ,  0.28881046, ..., -1.4127597 ,\n",
       "           1.9133856 , -1.5882549 ],\n",
       "         [ 0.71841073,  1.3142242 ,  0.20471646, ..., -2.255275  ,\n",
       "           2.074327  , -1.5882549 ],\n",
       "         [ 0.34093875,  1.3806069 ,  0.06552371, ..., -1.6197774 ,\n",
       "           2.395184  , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.18806082, -0.07490955,  0.8205622 , ..., -0.31062362,\n",
       "          -0.6450894 ,  0.6040813 ],\n",
       "         [-0.0733876 , -0.28615922,  0.7928203 , ..., -0.04285748,\n",
       "          -0.68049264,  0.6000079 ],\n",
       "         [ 0.07011276, -0.67910314,  0.7436807 , ...,  0.0178189 ,\n",
       "          -0.76498246,  0.59647983]],\n",
       "\n",
       "        [[-2.2932813 ,  0.77748924,  0.8988365 , ..., -1.4134598 ,\n",
       "           1.1827351 , -1.5882549 ],\n",
       "         [-0.22785147,  0.8926288 ,  0.8168112 , ..., -1.9391317 ,\n",
       "           2.6602843 , -1.5882549 ],\n",
       "         [ 1.1291623 ,  1.1381904 ,  0.7885331 , ..., -1.7031996 ,\n",
       "           2.4892519 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.6367741 , -0.6566135 ,  0.9117203 , ..., -0.20893301,\n",
       "          -0.5062108 ,  0.6015705 ],\n",
       "         [ 0.36823073, -0.7069152 ,  0.93604106, ..., -0.04055723,\n",
       "          -0.4774769 ,  0.59968436],\n",
       "         [ 0.46265805, -1.1785263 ,  0.90355897, ..., -0.2498763 ,\n",
       "          -0.45866397,  0.5948006 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.3699198 ,  1.4375393 , -0.5122167 , ..., -1.479522  ,\n",
       "           1.014268  , -1.5882549 ],\n",
       "         [ 0.5395018 ,  1.3120407 , -0.53472614, ..., -1.4367177 ,\n",
       "           1.0395807 , -1.5882549 ],\n",
       "         [ 0.69605756,  1.2094198 , -0.5475988 , ..., -1.5780278 ,\n",
       "           0.6318392 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.056734  ,  1.0967445 , -1.7741865 , ..., -0.258732  ,\n",
       "           0.6202094 ,  0.64691883],\n",
       "         [ 0.77006793,  0.88277596, -1.7575761 , ..., -0.59422547,\n",
       "           0.37340927,  0.6470593 ],\n",
       "         [ 0.6897662 ,  0.6141815 , -1.7871565 , ..., -0.9833871 ,\n",
       "           0.01475467,  0.6485754 ]],\n",
       "\n",
       "        [[-0.00547387,  1.2520872 , -0.75133353, ..., -1.2649589 ,\n",
       "           1.4598074 , -1.5882549 ],\n",
       "         [ 0.1731918 ,  1.1778677 , -0.6965681 , ..., -1.3496872 ,\n",
       "           1.0308584 , -1.5882549 ],\n",
       "         [ 0.2974    ,  1.2267771 , -0.6779615 , ..., -1.3143802 ,\n",
       "           1.3000633 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-0.2796858 ,  1.1767899 , -1.4940785 , ..., -0.1472969 ,\n",
       "           1.6638489 ,  0.64618814],\n",
       "         [-0.35191372,  1.1909208 , -1.616141  , ..., -0.73146605,\n",
       "           1.253029  ,  0.64675516],\n",
       "         [ 0.08551692,  1.120073  , -1.6485579 , ..., -1.353379  ,\n",
       "           0.556414  ,  0.64832795]],\n",
       "\n",
       "        [[-0.03236887,  1.1032389 , -0.84543836, ..., -0.8039201 ,\n",
       "           1.5978309 , -1.5882549 ],\n",
       "         [-0.10388847,  1.0822607 , -0.8415235 , ..., -1.0835985 ,\n",
       "           1.7835716 , -1.5882549 ],\n",
       "         [-0.0706263 ,  1.0551329 , -0.78412914, ..., -0.8383038 ,\n",
       "           1.6768476 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-1.5780797 ,  0.8127803 , -1.4838691 , ...,  0.10041277,\n",
       "           0.8516161 ,  0.6452373 ],\n",
       "         [-1.3558266 ,  1.0484176 , -1.4596366 , ..., -0.70004815,\n",
       "           1.3301649 ,  0.64397085],\n",
       "         [-1.0309364 ,  1.2628572 , -1.3829755 , ..., -1.6003219 ,\n",
       "           1.4892248 ,  0.64502007]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9014507 ,  1.265258  , -0.02086635, ..., -1.6976206 ,\n",
       "           1.3469263 , -1.5882549 ],\n",
       "         [ 0.5319456 ,  1.1570402 , -0.2477222 , ..., -1.9658478 ,\n",
       "           0.6109733 , -1.5882549 ],\n",
       "         [ 0.7679294 ,  1.2885116 , -0.362972  , ..., -1.9669015 ,\n",
       "           0.5413632 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.0423845 , -0.11361935,  0.51154596, ..., -0.61837435,\n",
       "          -0.72307956,  0.60708004],\n",
       "         [ 1.9068193 , -0.01136441,  0.47339132, ..., -0.10370702,\n",
       "          -0.7680617 ,  0.60846305],\n",
       "         [ 1.3718673 , -0.37730694,  0.41628996, ...,  0.4352751 ,\n",
       "          -0.82911956,  0.6085289 ]],\n",
       "\n",
       "        [[-1.1314641 ,  1.3619165 ,  0.28881046, ..., -1.4127597 ,\n",
       "           1.9133856 , -1.5882549 ],\n",
       "         [ 0.71841073,  1.3142242 ,  0.20471646, ..., -2.255275  ,\n",
       "           2.074327  , -1.5882549 ],\n",
       "         [ 0.34093875,  1.3806069 ,  0.06552371, ..., -1.6197774 ,\n",
       "           2.395184  , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.18806082, -0.07490955,  0.8205622 , ..., -0.31062362,\n",
       "          -0.6450894 ,  0.6040813 ],\n",
       "         [-0.0733876 , -0.28615922,  0.7928203 , ..., -0.04285748,\n",
       "          -0.68049264,  0.6000079 ],\n",
       "         [ 0.07011276, -0.67910314,  0.7436807 , ...,  0.0178189 ,\n",
       "          -0.76498246,  0.59647983]],\n",
       "\n",
       "        [[-2.2932813 ,  0.77748924,  0.8988365 , ..., -1.4134598 ,\n",
       "           1.1827351 , -1.5882549 ],\n",
       "         [-0.22785147,  0.8926288 ,  0.8168112 , ..., -1.9391317 ,\n",
       "           2.6602843 , -1.5882549 ],\n",
       "         [ 1.1291623 ,  1.1381904 ,  0.7885331 , ..., -1.7031996 ,\n",
       "           2.4892519 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.6367741 , -0.6566135 ,  0.9117203 , ..., -0.20893301,\n",
       "          -0.5062108 ,  0.6015705 ],\n",
       "         [ 0.36823073, -0.7069152 ,  0.93604106, ..., -0.04055723,\n",
       "          -0.4774769 ,  0.59968436],\n",
       "         [ 0.46265805, -1.1785263 ,  0.90355897, ..., -0.2498763 ,\n",
       "          -0.45866397,  0.5948006 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.3699198 ,  1.4375393 , -0.5122167 , ..., -1.479522  ,\n",
       "           1.014268  , -1.5882549 ],\n",
       "         [ 0.5395018 ,  1.3120407 , -0.53472614, ..., -1.4367177 ,\n",
       "           1.0395807 , -1.5882549 ],\n",
       "         [ 0.69605756,  1.2094198 , -0.5475988 , ..., -1.5780278 ,\n",
       "           0.6318392 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.056734  ,  1.0967445 , -1.7741865 , ..., -0.258732  ,\n",
       "           0.6202094 ,  0.64691883],\n",
       "         [ 0.77006793,  0.88277596, -1.7575761 , ..., -0.59422547,\n",
       "           0.37340927,  0.6470593 ],\n",
       "         [ 0.6897662 ,  0.6141815 , -1.7871565 , ..., -0.9833871 ,\n",
       "           0.01475467,  0.6485754 ]],\n",
       "\n",
       "        [[-0.00547387,  1.2520872 , -0.75133353, ..., -1.2649589 ,\n",
       "           1.4598074 , -1.5882549 ],\n",
       "         [ 0.1731918 ,  1.1778677 , -0.6965681 , ..., -1.3496872 ,\n",
       "           1.0308584 , -1.5882549 ],\n",
       "         [ 0.2974    ,  1.2267771 , -0.6779615 , ..., -1.3143802 ,\n",
       "           1.3000633 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-0.2796858 ,  1.1767899 , -1.4940785 , ..., -0.1472969 ,\n",
       "           1.6638489 ,  0.64618814],\n",
       "         [-0.35191372,  1.1909208 , -1.616141  , ..., -0.73146605,\n",
       "           1.253029  ,  0.64675516],\n",
       "         [ 0.08551692,  1.120073  , -1.6485579 , ..., -1.353379  ,\n",
       "           0.556414  ,  0.64832795]],\n",
       "\n",
       "        [[-0.03236887,  1.1032389 , -0.84543836, ..., -0.8039201 ,\n",
       "           1.5978309 , -1.5882549 ],\n",
       "         [-0.10388847,  1.0822607 , -0.8415235 , ..., -1.0835985 ,\n",
       "           1.7835716 , -1.5882549 ],\n",
       "         [-0.0706263 ,  1.0551329 , -0.78412914, ..., -0.8383038 ,\n",
       "           1.6768476 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-1.5780797 ,  0.8127803 , -1.4838691 , ...,  0.10041277,\n",
       "           0.8516161 ,  0.6452373 ],\n",
       "         [-1.3558266 ,  1.0484176 , -1.4596366 , ..., -0.70004815,\n",
       "           1.3301649 ,  0.64397085],\n",
       "         [-1.0309364 ,  1.2628572 , -1.3829755 , ..., -1.6003219 ,\n",
       "           1.4892248 ,  0.64502007]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9014507 ,  1.265258  , -0.02086635, ..., -1.6976206 ,\n",
       "           1.3469263 , -1.5882549 ],\n",
       "         [ 0.5319456 ,  1.1570402 , -0.2477222 , ..., -1.9658478 ,\n",
       "           0.6109733 , -1.5882549 ],\n",
       "         [ 0.7679294 ,  1.2885116 , -0.362972  , ..., -1.9669015 ,\n",
       "           0.5413632 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.0423845 , -0.11361935,  0.51154596, ..., -0.61837435,\n",
       "          -0.72307956,  0.60708004],\n",
       "         [ 1.9068193 , -0.01136441,  0.47339132, ..., -0.10370702,\n",
       "          -0.7680617 ,  0.60846305],\n",
       "         [ 1.3718673 , -0.37730694,  0.41628996, ...,  0.4352751 ,\n",
       "          -0.82911956,  0.6085289 ]],\n",
       "\n",
       "        [[-1.1314641 ,  1.3619165 ,  0.28881046, ..., -1.4127597 ,\n",
       "           1.9133856 , -1.5882549 ],\n",
       "         [ 0.71841073,  1.3142242 ,  0.20471646, ..., -2.255275  ,\n",
       "           2.074327  , -1.5882549 ],\n",
       "         [ 0.34093875,  1.3806069 ,  0.06552371, ..., -1.6197774 ,\n",
       "           2.395184  , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.18806082, -0.07490955,  0.8205622 , ..., -0.31062362,\n",
       "          -0.6450894 ,  0.6040813 ],\n",
       "         [-0.0733876 , -0.28615922,  0.7928203 , ..., -0.04285748,\n",
       "          -0.68049264,  0.6000079 ],\n",
       "         [ 0.07011276, -0.67910314,  0.7436807 , ...,  0.0178189 ,\n",
       "          -0.76498246,  0.59647983]],\n",
       "\n",
       "        [[-2.2932813 ,  0.77748924,  0.8988365 , ..., -1.4134598 ,\n",
       "           1.1827351 , -1.5882549 ],\n",
       "         [-0.22785147,  0.8926288 ,  0.8168112 , ..., -1.9391317 ,\n",
       "           2.6602843 , -1.5882549 ],\n",
       "         [ 1.1291623 ,  1.1381904 ,  0.7885331 , ..., -1.7031996 ,\n",
       "           2.4892519 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.6367741 , -0.6566135 ,  0.9117203 , ..., -0.20893301,\n",
       "          -0.5062108 ,  0.6015705 ],\n",
       "         [ 0.36823073, -0.7069152 ,  0.93604106, ..., -0.04055723,\n",
       "          -0.4774769 ,  0.59968436],\n",
       "         [ 0.46265805, -1.1785263 ,  0.90355897, ..., -0.2498763 ,\n",
       "          -0.45866397,  0.5948006 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0.3699198 ,  1.4375393 , -0.5122167 , ..., -1.479522  ,\n",
       "           1.014268  , -1.5882549 ],\n",
       "         [ 0.5395018 ,  1.3120407 , -0.53472614, ..., -1.4367177 ,\n",
       "           1.0395807 , -1.5882549 ],\n",
       "         [ 0.69605756,  1.2094198 , -0.5475988 , ..., -1.5780278 ,\n",
       "           0.6318392 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.056734  ,  1.0967445 , -1.7741865 , ..., -0.258732  ,\n",
       "           0.6202094 ,  0.64691883],\n",
       "         [ 0.77006793,  0.88277596, -1.7575761 , ..., -0.59422547,\n",
       "           0.37340927,  0.6470593 ],\n",
       "         [ 0.6897662 ,  0.6141815 , -1.7871565 , ..., -0.9833871 ,\n",
       "           0.01475467,  0.6485754 ]],\n",
       "\n",
       "        [[-0.00547387,  1.2520872 , -0.75133353, ..., -1.2649589 ,\n",
       "           1.4598074 , -1.5882549 ],\n",
       "         [ 0.1731918 ,  1.1778677 , -0.6965681 , ..., -1.3496872 ,\n",
       "           1.0308584 , -1.5882549 ],\n",
       "         [ 0.2974    ,  1.2267771 , -0.6779615 , ..., -1.3143802 ,\n",
       "           1.3000633 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-0.2796858 ,  1.1767899 , -1.4940785 , ..., -0.1472969 ,\n",
       "           1.6638489 ,  0.64618814],\n",
       "         [-0.35191372,  1.1909208 , -1.616141  , ..., -0.73146605,\n",
       "           1.253029  ,  0.64675516],\n",
       "         [ 0.08551692,  1.120073  , -1.6485579 , ..., -1.353379  ,\n",
       "           0.556414  ,  0.64832795]],\n",
       "\n",
       "        [[-0.03236887,  1.1032389 , -0.84543836, ..., -0.8039201 ,\n",
       "           1.5978309 , -1.5882549 ],\n",
       "         [-0.10388847,  1.0822607 , -0.8415235 , ..., -1.0835985 ,\n",
       "           1.7835716 , -1.5882549 ],\n",
       "         [-0.0706263 ,  1.0551329 , -0.78412914, ..., -0.8383038 ,\n",
       "           1.6768476 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-1.5780797 ,  0.8127803 , -1.4838691 , ...,  0.10041277,\n",
       "           0.8516161 ,  0.6452373 ],\n",
       "         [-1.3558266 ,  1.0484176 , -1.4596366 , ..., -0.70004815,\n",
       "           1.3301649 ,  0.64397085],\n",
       "         [-1.0309364 ,  1.2628572 , -1.3829755 , ..., -1.6003219 ,\n",
       "           1.4892248 ,  0.64502007]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9014507 ,  1.265258  , -0.02086635, ..., -1.6976206 ,\n",
       "           1.3469263 , -1.5882549 ],\n",
       "         [ 0.5319456 ,  1.1570402 , -0.2477222 , ..., -1.9658478 ,\n",
       "           0.6109733 , -1.5882549 ],\n",
       "         [ 0.7679294 ,  1.2885116 , -0.362972  , ..., -1.9669015 ,\n",
       "           0.5413632 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.0423845 , -0.11361935,  0.51154596, ..., -0.61837435,\n",
       "          -0.72307956,  0.60708004],\n",
       "         [ 1.9068193 , -0.01136441,  0.47339132, ..., -0.10370702,\n",
       "          -0.7680617 ,  0.60846305],\n",
       "         [ 1.3718673 , -0.37730694,  0.41628996, ...,  0.4352751 ,\n",
       "          -0.82911956,  0.6085289 ]],\n",
       "\n",
       "        [[-1.1314641 ,  1.3619165 ,  0.28881046, ..., -1.4127597 ,\n",
       "           1.9133856 , -1.5882549 ],\n",
       "         [ 0.71841073,  1.3142242 ,  0.20471646, ..., -2.255275  ,\n",
       "           2.074327  , -1.5882549 ],\n",
       "         [ 0.34093875,  1.3806069 ,  0.06552371, ..., -1.6197774 ,\n",
       "           2.395184  , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.18806082, -0.07490955,  0.8205622 , ..., -0.31062362,\n",
       "          -0.6450894 ,  0.6040813 ],\n",
       "         [-0.0733876 , -0.28615922,  0.7928203 , ..., -0.04285748,\n",
       "          -0.68049264,  0.6000079 ],\n",
       "         [ 0.07011276, -0.67910314,  0.7436807 , ...,  0.0178189 ,\n",
       "          -0.76498246,  0.59647983]],\n",
       "\n",
       "        [[-2.2932813 ,  0.77748924,  0.8988365 , ..., -1.4134598 ,\n",
       "           1.1827351 , -1.5882549 ],\n",
       "         [-0.22785147,  0.8926288 ,  0.8168112 , ..., -1.9391317 ,\n",
       "           2.6602843 , -1.5882549 ],\n",
       "         [ 1.1291623 ,  1.1381904 ,  0.7885331 , ..., -1.7031996 ,\n",
       "           2.4892519 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.6367741 , -0.6566135 ,  0.9117203 , ..., -0.20893301,\n",
       "          -0.5062108 ,  0.6015705 ],\n",
       "         [ 0.36823073, -0.7069152 ,  0.93604106, ..., -0.04055723,\n",
       "          -0.4774769 ,  0.59968436],\n",
       "         [ 0.46265805, -1.1785263 ,  0.90355897, ..., -0.2498763 ,\n",
       "          -0.45866397,  0.5948006 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.3699198 ,  1.4375393 , -0.5122167 , ..., -1.479522  ,\n",
       "           1.014268  , -1.5882549 ],\n",
       "         [ 0.5395018 ,  1.3120407 , -0.53472614, ..., -1.4367177 ,\n",
       "           1.0395807 , -1.5882549 ],\n",
       "         [ 0.69605756,  1.2094198 , -0.5475988 , ..., -1.5780278 ,\n",
       "           0.6318392 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.056734  ,  1.0967445 , -1.7741865 , ..., -0.258732  ,\n",
       "           0.6202094 ,  0.64691883],\n",
       "         [ 0.77006793,  0.88277596, -1.7575761 , ..., -0.59422547,\n",
       "           0.37340927,  0.6470593 ],\n",
       "         [ 0.6897662 ,  0.6141815 , -1.7871565 , ..., -0.9833871 ,\n",
       "           0.01475467,  0.6485754 ]],\n",
       "\n",
       "        [[-0.00547387,  1.2520872 , -0.75133353, ..., -1.2649589 ,\n",
       "           1.4598074 , -1.5882549 ],\n",
       "         [ 0.1731918 ,  1.1778677 , -0.6965681 , ..., -1.3496872 ,\n",
       "           1.0308584 , -1.5882549 ],\n",
       "         [ 0.2974    ,  1.2267771 , -0.6779615 , ..., -1.3143802 ,\n",
       "           1.3000633 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-0.2796858 ,  1.1767899 , -1.4940785 , ..., -0.1472969 ,\n",
       "           1.6638489 ,  0.64618814],\n",
       "         [-0.35191372,  1.1909208 , -1.616141  , ..., -0.73146605,\n",
       "           1.253029  ,  0.64675516],\n",
       "         [ 0.08551692,  1.120073  , -1.6485579 , ..., -1.353379  ,\n",
       "           0.556414  ,  0.64832795]],\n",
       "\n",
       "        [[-0.03236887,  1.1032389 , -0.84543836, ..., -0.8039201 ,\n",
       "           1.5978309 , -1.5882549 ],\n",
       "         [-0.10388847,  1.0822607 , -0.8415235 , ..., -1.0835985 ,\n",
       "           1.7835716 , -1.5882549 ],\n",
       "         [-0.0706263 ,  1.0551329 , -0.78412914, ..., -0.8383038 ,\n",
       "           1.6768476 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-1.5780797 ,  0.8127803 , -1.4838691 , ...,  0.10041277,\n",
       "           0.8516161 ,  0.6452373 ],\n",
       "         [-1.3558266 ,  1.0484176 , -1.4596366 , ..., -0.70004815,\n",
       "           1.3301649 ,  0.64397085],\n",
       "         [-1.0309364 ,  1.2628572 , -1.3829755 , ..., -1.6003219 ,\n",
       "           1.4892248 ,  0.64502007]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9014507 ,  1.265258  , -0.02086635, ..., -1.6976206 ,\n",
       "           1.3469263 , -1.5882549 ],\n",
       "         [ 0.5319456 ,  1.1570402 , -0.2477222 , ..., -1.9658478 ,\n",
       "           0.6109733 , -1.5882549 ],\n",
       "         [ 0.7679294 ,  1.2885116 , -0.362972  , ..., -1.9669015 ,\n",
       "           0.5413632 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.0423845 , -0.11361935,  0.51154596, ..., -0.61837435,\n",
       "          -0.72307956,  0.60708004],\n",
       "         [ 1.9068193 , -0.01136441,  0.47339132, ..., -0.10370702,\n",
       "          -0.7680617 ,  0.60846305],\n",
       "         [ 1.3718673 , -0.37730694,  0.41628996, ...,  0.4352751 ,\n",
       "          -0.82911956,  0.6085289 ]],\n",
       "\n",
       "        [[-1.1314641 ,  1.3619165 ,  0.28881046, ..., -1.4127597 ,\n",
       "           1.9133856 , -1.5882549 ],\n",
       "         [ 0.71841073,  1.3142242 ,  0.20471646, ..., -2.255275  ,\n",
       "           2.074327  , -1.5882549 ],\n",
       "         [ 0.34093875,  1.3806069 ,  0.06552371, ..., -1.6197774 ,\n",
       "           2.395184  , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.18806082, -0.07490955,  0.8205622 , ..., -0.31062362,\n",
       "          -0.6450894 ,  0.6040813 ],\n",
       "         [-0.0733876 , -0.28615922,  0.7928203 , ..., -0.04285748,\n",
       "          -0.68049264,  0.6000079 ],\n",
       "         [ 0.07011276, -0.67910314,  0.7436807 , ...,  0.0178189 ,\n",
       "          -0.76498246,  0.59647983]],\n",
       "\n",
       "        [[-2.2932813 ,  0.77748924,  0.8988365 , ..., -1.4134598 ,\n",
       "           1.1827351 , -1.5882549 ],\n",
       "         [-0.22785147,  0.8926288 ,  0.8168112 , ..., -1.9391317 ,\n",
       "           2.6602843 , -1.5882549 ],\n",
       "         [ 1.1291623 ,  1.1381904 ,  0.7885331 , ..., -1.7031996 ,\n",
       "           2.4892519 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.6367741 , -0.6566135 ,  0.9117203 , ..., -0.20893301,\n",
       "          -0.5062108 ,  0.6015705 ],\n",
       "         [ 0.36823073, -0.7069152 ,  0.93604106, ..., -0.04055723,\n",
       "          -0.4774769 ,  0.59968436],\n",
       "         [ 0.46265805, -1.1785263 ,  0.90355897, ..., -0.2498763 ,\n",
       "          -0.45866397,  0.5948006 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.3699198 ,  1.4375393 , -0.5122167 , ..., -1.479522  ,\n",
       "           1.014268  , -1.5882549 ],\n",
       "         [ 0.5395018 ,  1.3120407 , -0.53472614, ..., -1.4367177 ,\n",
       "           1.0395807 , -1.5882549 ],\n",
       "         [ 0.69605756,  1.2094198 , -0.5475988 , ..., -1.5780278 ,\n",
       "           0.6318392 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.056734  ,  1.0967445 , -1.7741865 , ..., -0.258732  ,\n",
       "           0.6202094 ,  0.64691883],\n",
       "         [ 0.77006793,  0.88277596, -1.7575761 , ..., -0.59422547,\n",
       "           0.37340927,  0.6470593 ],\n",
       "         [ 0.6897662 ,  0.6141815 , -1.7871565 , ..., -0.9833871 ,\n",
       "           0.01475467,  0.6485754 ]],\n",
       "\n",
       "        [[-0.00547387,  1.2520872 , -0.75133353, ..., -1.2649589 ,\n",
       "           1.4598074 , -1.5882549 ],\n",
       "         [ 0.1731918 ,  1.1778677 , -0.6965681 , ..., -1.3496872 ,\n",
       "           1.0308584 , -1.5882549 ],\n",
       "         [ 0.2974    ,  1.2267771 , -0.6779615 , ..., -1.3143802 ,\n",
       "           1.3000633 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-0.2796858 ,  1.1767899 , -1.4940785 , ..., -0.1472969 ,\n",
       "           1.6638489 ,  0.64618814],\n",
       "         [-0.35191372,  1.1909208 , -1.616141  , ..., -0.73146605,\n",
       "           1.253029  ,  0.64675516],\n",
       "         [ 0.08551692,  1.120073  , -1.6485579 , ..., -1.353379  ,\n",
       "           0.556414  ,  0.64832795]],\n",
       "\n",
       "        [[-0.03236887,  1.1032389 , -0.84543836, ..., -0.8039201 ,\n",
       "           1.5978309 , -1.5882549 ],\n",
       "         [-0.10388847,  1.0822607 , -0.8415235 , ..., -1.0835985 ,\n",
       "           1.7835716 , -1.5882549 ],\n",
       "         [-0.0706263 ,  1.0551329 , -0.78412914, ..., -0.8383038 ,\n",
       "           1.6768476 , -1.5882549 ],\n",
       "         ...,\n",
       "         [-1.5780797 ,  0.8127803 , -1.4838691 , ...,  0.10041277,\n",
       "           0.8516161 ,  0.6452373 ],\n",
       "         [-1.3558266 ,  1.0484176 , -1.4596366 , ..., -0.70004815,\n",
       "           1.3301649 ,  0.64397085],\n",
       "         [-1.0309364 ,  1.2628572 , -1.3829755 , ..., -1.6003219 ,\n",
       "           1.4892248 ,  0.64502007]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9014507 ,  1.265258  , -0.02086635, ..., -1.6976206 ,\n",
       "           1.3469263 , -1.5882549 ],\n",
       "         [ 0.5319456 ,  1.1570402 , -0.2477222 , ..., -1.9658478 ,\n",
       "           0.6109733 , -1.5882549 ],\n",
       "         [ 0.7679294 ,  1.2885116 , -0.362972  , ..., -1.9669015 ,\n",
       "           0.5413632 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 1.0423845 , -0.11361935,  0.51154596, ..., -0.61837435,\n",
       "          -0.72307956,  0.60708004],\n",
       "         [ 1.9068193 , -0.01136441,  0.47339132, ..., -0.10370702,\n",
       "          -0.7680617 ,  0.60846305],\n",
       "         [ 1.3718673 , -0.37730694,  0.41628996, ...,  0.4352751 ,\n",
       "          -0.82911956,  0.6085289 ]],\n",
       "\n",
       "        [[-1.1314641 ,  1.3619165 ,  0.28881046, ..., -1.4127597 ,\n",
       "           1.9133856 , -1.5882549 ],\n",
       "         [ 0.71841073,  1.3142242 ,  0.20471646, ..., -2.255275  ,\n",
       "           2.074327  , -1.5882549 ],\n",
       "         [ 0.34093875,  1.3806069 ,  0.06552371, ..., -1.6197774 ,\n",
       "           2.395184  , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.18806082, -0.07490955,  0.8205622 , ..., -0.31062362,\n",
       "          -0.6450894 ,  0.6040813 ],\n",
       "         [-0.0733876 , -0.28615922,  0.7928203 , ..., -0.04285748,\n",
       "          -0.68049264,  0.6000079 ],\n",
       "         [ 0.07011276, -0.67910314,  0.7436807 , ...,  0.0178189 ,\n",
       "          -0.76498246,  0.59647983]],\n",
       "\n",
       "        [[-2.2932813 ,  0.77748924,  0.8988365 , ..., -1.4134598 ,\n",
       "           1.1827351 , -1.5882549 ],\n",
       "         [-0.22785147,  0.8926288 ,  0.8168112 , ..., -1.9391317 ,\n",
       "           2.6602843 , -1.5882549 ],\n",
       "         [ 1.1291623 ,  1.1381904 ,  0.7885331 , ..., -1.7031996 ,\n",
       "           2.4892519 , -1.5882549 ],\n",
       "         ...,\n",
       "         [ 0.6367741 , -0.6566135 ,  0.9117203 , ..., -0.20893301,\n",
       "          -0.5062108 ,  0.6015705 ],\n",
       "         [ 0.36823073, -0.7069152 ,  0.93604106, ..., -0.04055723,\n",
       "          -0.4774769 ,  0.59968436],\n",
       "         [ 0.46265805, -1.1785263 ,  0.90355897, ..., -0.2498763 ,\n",
       "          -0.45866397,  0.5948006 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_images_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150bd816",
   "metadata": {},
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da502411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting y for training\n",
    "df1=training_set_wt.query(\"latitude == -15.0 and longitude == 55\")\n",
    "y_train = df1['Real_tom_lsm']\n",
    "\n",
    "#extracting y for validation\n",
    "df2=validation_set_wt.query(\"latitude == -15.0 and longitude == 55\")\n",
    "y_validation = df2['Real_tom_lsm'].values\n",
    "y_validation = y_validation.reshape(-1,1)\n",
    "\n",
    "#extracting y for test\n",
    "df3=test_set_wt.query(\"latitude == -15.0 and longitude == 55\")\n",
    "y_test = df3['Real_tom_lsm'].values\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bbc3fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (11323, 13, 29, 8)\n",
      "Shape of y_train:  (11323,)\n",
      "Shape of X_valid:  (1826, 13, 29, 8)\n",
      "Shape of y_valid:  (1826, 1)\n",
      "Shape of X_test:  (1431, 13, 29, 8)\n",
      "Shape of y_test:  (1431, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes\n",
    "# Note, model input must have a four-dimensional shape [samples, rows, columns, channels]\n",
    "\n",
    "X_train = data_images_training_set\n",
    "X_valid = data_images_validation_set\n",
    "X_test = data_images_test_set\n",
    "\n",
    "\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(\"Shape of X_valid: \", X_valid.shape)\n",
    "print(\"Shape of y_valid: \", y_validation.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_test: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "041da787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "22481    1.0\n",
       "22482    1.0\n",
       "22483    1.0\n",
       "22484    1.0\n",
       "22485    1.0\n",
       "Name: Real_tom_lsm, Length: 22486, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_traning_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1f3e894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 4.27113295e-01,  1.37508893e+00, -3.67069572e-01, ...,\n",
       "          -7.21641243e-01,  4.60972577e-01, -1.58825493e+00],\n",
       "         [ 2.19114333e-01,  1.37282574e+00, -4.08893734e-01, ...,\n",
       "          -7.67529309e-01,  6.78440511e-01, -1.58825493e+00],\n",
       "         [ 4.21189815e-01,  1.27558076e+00, -5.48175693e-01, ...,\n",
       "          -7.51221001e-01,  1.14706922e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 1.88732874e+00,  1.32007051e+00, -3.25875938e-01, ...,\n",
       "          -5.68113208e-01,  2.52456450e+00,  6.46089315e-01],\n",
       "         [ 1.96499169e+00,  1.20571399e+00, -3.74403417e-01, ...,\n",
       "          -2.85604950e-02,  1.87900269e+00,  6.49339259e-01],\n",
       "         [ 1.03588498e+00,  1.09053159e+00, -1.85300335e-01, ...,\n",
       "           2.47285187e-01,  1.26525283e+00,  6.50301874e-01]],\n",
       "\n",
       "        [[ 6.46842480e-01,  1.32579172e+00, -4.02925611e-01, ...,\n",
       "          -5.52261889e-01,  8.38184416e-01, -1.58825493e+00],\n",
       "         [ 6.71090961e-01,  1.25446832e+00, -6.58915281e-01, ...,\n",
       "          -4.84310299e-01,  1.75637233e+00, -1.58825493e+00],\n",
       "         [ 5.96856773e-01,  1.19152451e+00, -7.87169874e-01, ...,\n",
       "          -9.67979357e-02,  1.77835000e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 9.45954800e-01,  1.23102462e+00, -2.59749830e-01, ...,\n",
       "          -4.53708172e-01,  3.50569248e+00,  6.49078548e-01],\n",
       "         [ 6.66033447e-01,  1.16572154e+00, -2.91817546e-01, ...,\n",
       "           1.29427150e-01,  3.18962455e+00,  6.49988651e-01],\n",
       "         [-4.15342003e-01,  1.19090319e+00, -2.85085943e-02, ...,\n",
       "           3.13134760e-01,  2.10869956e+00,  6.50447190e-01]],\n",
       "\n",
       "        [[ 4.63812023e-01,  1.20367706e+00, -8.23771775e-01, ...,\n",
       "          -7.11365759e-01,  1.21958697e+00, -1.58825493e+00],\n",
       "         [ 5.30848145e-01,  1.20294666e+00, -8.93117011e-01, ...,\n",
       "          -5.43753624e-01,  1.67761183e+00, -1.58825493e+00],\n",
       "         [ 7.59386599e-01,  1.05065799e+00, -9.10637975e-01, ...,\n",
       "          -2.94779569e-01,  1.38497555e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [-1.50597632e+00,  8.91696274e-01, -1.66849032e-01, ...,\n",
       "          -4.33458745e-01,  2.13486743e+00,  6.50749385e-01],\n",
       "         [-9.63658869e-01,  9.23220098e-01, -1.05626456e-01, ...,\n",
       "          -1.75609201e-01,  1.42123461e+00,  6.51378810e-01],\n",
       "         [-5.54950476e-01,  8.96376967e-01,  2.18122657e-02, ...,\n",
       "           5.96572421e-02,  3.62030238e-01,  6.51008844e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.33807674e-01, -6.23997450e-01,  1.59199208e-01, ...,\n",
       "           2.00288153e+00, -1.42200959e+00, -1.58825493e+00],\n",
       "         [-3.78119564e+00, -6.10704243e-01,  8.23082104e-02, ...,\n",
       "           7.29950428e-01, -1.29476166e+00, -1.58825493e+00],\n",
       "         [-8.10280859e-01, -2.34572157e-01,  2.53526587e-02, ...,\n",
       "          -2.06627941e+00, -5.06130815e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 1.84982330e-01, -9.73996341e-01,  1.82874843e-01, ...,\n",
       "           1.85975596e-01, -7.16586530e-01,  6.15046442e-01],\n",
       "         [ 1.90568082e-02, -5.68407476e-01, -1.75897330e-01, ...,\n",
       "           5.04916668e-01, -7.15987325e-01,  6.17965698e-01],\n",
       "         [ 4.73395824e-01, -3.04126382e-01, -3.46181512e-01, ...,\n",
       "           9.09602106e-01, -7.20862091e-01,  6.14986420e-01]],\n",
       "\n",
       "        [[ 1.32216382e+00, -9.58585858e-01,  8.14006865e-01, ...,\n",
       "           2.34344912e+00, -1.33512485e+00, -1.58825493e+00],\n",
       "         [-1.76974630e+00, -7.89016485e-01,  7.77857423e-01, ...,\n",
       "           1.99827790e+00, -1.22275710e+00, -1.58825493e+00],\n",
       "         [-1.05889177e+00, -6.53286397e-01,  6.70857310e-01, ...,\n",
       "          -3.07730824e-01, -7.51818001e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 1.00085783e+00, -1.29801691e-01,  4.38337386e-01, ...,\n",
       "          -8.97660386e-03, -5.29305935e-01,  6.12930775e-01],\n",
       "         [ 1.22295904e+00, -1.21599965e-01,  1.61812231e-01, ...,\n",
       "           5.15378892e-01, -5.08353770e-01,  6.14116371e-01],\n",
       "         [ 1.14441466e+00, -2.41200507e-01,  5.79273850e-02, ...,\n",
       "           1.07054412e+00, -6.47659481e-01,  6.11086965e-01]],\n",
       "\n",
       "        [[ 9.94230032e-01, -1.38003683e+00,  1.38564277e+00, ...,\n",
       "           2.33718991e+00, -1.18692470e+00, -1.58825493e+00],\n",
       "         [-8.03096414e-01, -9.05332506e-01,  1.42078114e+00, ...,\n",
       "           1.64000630e+00, -1.38754582e+00, -1.58825493e+00],\n",
       "         [-2.53572559e+00, -7.96238124e-01,  1.41301668e+00, ...,\n",
       "           7.94063091e-01, -1.16699970e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 1.10579920e+00,  1.57185137e-01,  7.00525939e-01, ...,\n",
       "           4.77263689e-01, -4.82698858e-01,  6.09229624e-01],\n",
       "         [ 7.32551932e-01, -2.39112929e-01,  5.37922263e-01, ...,\n",
       "           7.26356626e-01, -4.87573892e-01,  6.08566225e-01],\n",
       "         [ 1.00112247e+00, -5.41559756e-01,  4.65082079e-01, ...,\n",
       "           1.06078398e+00, -5.43073833e-01,  6.06301129e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 7.39637986e-02,  1.07186341e+00, -3.39835912e-01, ...,\n",
       "          -9.47439611e-01,  2.32109755e-01, -1.58825493e+00],\n",
       "         [ 3.50217044e-01,  1.06886423e+00, -1.63316369e-01, ...,\n",
       "          -9.17616785e-01,  1.09992601e-01, -1.58825493e+00],\n",
       "         [ 1.05198279e-01,  1.10864103e+00, -2.01395109e-01, ...,\n",
       "          -8.62653971e-01,  3.79026622e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 2.24125838e+00,  1.07553220e+00, -5.45194626e-01, ...,\n",
       "          -7.73552656e-01,  2.40832639e+00,  6.45680189e-01],\n",
       "         [ 2.23954606e+00,  1.00334752e+00, -4.25380975e-01, ...,\n",
       "          -2.05492556e-01,  2.32896805e+00,  6.48462117e-01],\n",
       "         [ 1.87936974e+00,  9.86330330e-01, -3.19070101e-01, ...,\n",
       "           5.75696409e-01,  1.23076797e+00,  6.49759412e-01]],\n",
       "\n",
       "        [[ 1.27744094e-01,  1.17931187e+00, -4.09069598e-01, ...,\n",
       "          -6.79640114e-01,  1.39974844e+00, -1.58825493e+00],\n",
       "         [ 2.96535999e-01,  1.08354998e+00, -4.53083903e-01, ...,\n",
       "          -7.66668618e-01,  1.48543572e+00, -1.58825493e+00],\n",
       "         [ 7.93394089e-01,  1.20815909e+00, -4.95316833e-01, ...,\n",
       "          -5.61550498e-01,  1.75395632e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 1.71933270e+00,  1.08850193e+00, -3.23776752e-01, ...,\n",
       "          -5.91233552e-01,  3.21919155e+00,  6.48979545e-01],\n",
       "         [ 1.52416337e+00,  1.07360804e+00, -3.15353394e-01, ...,\n",
       "           2.04253405e-01,  3.48651552e+00,  6.49898529e-01],\n",
       "         [-2.95047134e-01,  9.88487124e-01, -1.38661414e-01, ...,\n",
       "           7.54738808e-01,  2.54652071e+00,  6.50493145e-01]],\n",
       "\n",
       "        [[ 6.17149174e-01,  1.22552419e+00, -6.79395854e-01, ...,\n",
       "          -7.59021997e-01,  1.24770033e+00, -1.58825493e+00],\n",
       "         [ 9.20970738e-01,  1.09668434e+00, -6.41435087e-01, ...,\n",
       "          -6.05746448e-01,  1.00825500e+00, -1.58825493e+00],\n",
       "         [ 7.58104205e-01,  1.11674225e+00, -6.27085626e-01, ...,\n",
       "          -3.88623267e-01,  1.52477312e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [-1.59078085e+00,  1.03494823e+00, -2.12157398e-01, ...,\n",
       "          -2.38535747e-01,  3.43400860e+00,  6.50763035e-01],\n",
       "         [-1.49112093e+00,  1.08478153e+00, -6.72907829e-02, ...,\n",
       "          -2.56551970e-02,  2.97376013e+00,  6.51515663e-01],\n",
       "         [-9.06111181e-01,  9.26234066e-01,  6.59277737e-02, ...,\n",
       "           2.26988792e-01,  1.14388382e+00,  6.51389003e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.07594633e+00, -4.95685607e-01,  2.88699776e-01, ...,\n",
       "           8.06239247e-01, -1.19618189e+00, -1.58825493e+00],\n",
       "         [ 7.59005249e-01, -6.01784050e-01,  2.13320374e-01, ...,\n",
       "           1.52606428e+00, -1.41955030e+00, -1.58825493e+00],\n",
       "         [-2.96225691e+00, -5.61628878e-01,  1.18096456e-01, ...,\n",
       "           4.35568243e-01, -9.95218813e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 8.78860295e-01, -7.48639345e-01,  7.09445596e-01, ...,\n",
       "           4.07253541e-02, -6.10396683e-01,  6.16189718e-01],\n",
       "         [ 9.71036196e-01, -1.05466688e+00,  4.26599264e-01, ...,\n",
       "           4.56783682e-01, -7.82626212e-01,  6.19007409e-01],\n",
       "         [ 1.17337632e+00, -1.22597301e+00,  1.47950888e-01, ...,\n",
       "           8.45966160e-01, -8.00242245e-01,  6.15826666e-01]],\n",
       "\n",
       "        [[ 2.19313312e+00, -1.07896578e+00,  6.86314642e-01, ...,\n",
       "           1.05835342e+00, -1.59776688e+00, -1.58825493e+00],\n",
       "         [-9.77587104e-02, -1.24879694e+00,  7.51142383e-01, ...,\n",
       "           1.42651129e+00, -1.50609326e+00, -1.58825493e+00],\n",
       "         [ 2.65896976e-01, -9.62336123e-01,  7.58625507e-01, ...,\n",
       "           9.04126346e-01, -1.34002030e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 1.07907939e+00, -1.04775310e+00,  8.54303658e-01, ...,\n",
       "           1.26701280e-01, -6.33998394e-01,  6.14046335e-01],\n",
       "         [ 1.09635162e+00, -1.32890821e+00,  7.76625574e-01, ...,\n",
       "           1.97366238e-01, -6.30578279e-01,  6.15190148e-01],\n",
       "         [ 8.78056645e-01, -1.50943744e+00,  5.75568616e-01, ...,\n",
       "           3.28340352e-01, -6.29381061e-01,  6.11866176e-01]],\n",
       "\n",
       "        [[ 5.20195961e-01, -1.39114177e+00,  4.36086357e-01, ...,\n",
       "           8.36488783e-01, -1.56526971e+00, -1.58825493e+00],\n",
       "         [-8.75872150e-02, -1.29832911e+00,  6.74860060e-01, ...,\n",
       "           7.32452035e-01, -1.58853078e+00, -1.58825493e+00],\n",
       "         [-1.55939472e+00, -1.02735531e+00,  9.14879799e-01, ...,\n",
       "           5.26187420e-01, -1.48522747e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 8.59970927e-01, -1.17260325e+00,  6.51727378e-01, ...,\n",
       "           7.27324724e-01, -4.25167918e-01,  6.10255957e-01],\n",
       "         [-5.95665693e-01, -1.55416834e+00,  7.61725366e-01, ...,\n",
       "           5.56615293e-01, -4.70662653e-01,  6.09373212e-01],\n",
       "         [-8.46911430e-01, -1.69065237e+00,  7.84269154e-01, ...,\n",
       "           2.55732983e-01, -4.19010550e-01,  6.07070386e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 6.56662583e-02,  1.13634849e+00, -5.11023819e-01, ...,\n",
       "          -1.80034429e-01,  9.84769940e-01, -1.58825493e+00],\n",
       "         [-1.27033621e-01,  1.11973822e+00, -2.03999564e-01, ...,\n",
       "          -3.05694520e-01,  7.41048813e-01, -1.58825493e+00],\n",
       "         [ 4.36225124e-02,  1.08493328e+00, -4.18715067e-02, ...,\n",
       "          -3.32007021e-01,  8.75138640e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 2.55127597e+00,  1.22397590e+00, -6.40706301e-01, ...,\n",
       "          -1.21205223e+00,  3.43805957e+00,  6.45779788e-01],\n",
       "         [ 2.33397722e+00,  1.16280496e+00, -4.42349911e-01, ...,\n",
       "          -5.08806586e-01,  2.99371743e+00,  6.47845805e-01],\n",
       "         [ 2.78455496e+00,  1.15942478e+00, -3.11117709e-01, ...,\n",
       "           3.92247498e-01,  2.33455825e+00,  6.49262369e-01]],\n",
       "\n",
       "        [[-1.02041751e-01,  1.17360878e+00, -6.61649287e-01, ...,\n",
       "          -1.09945320e-01,  2.47908092e+00, -1.58825493e+00],\n",
       "         [ 2.48482645e-01,  1.22177851e+00, -6.04346275e-01, ...,\n",
       "          -2.13912174e-01,  1.76365221e+00, -1.58825493e+00],\n",
       "         [ 9.26503062e-01,  1.25612557e+00, -5.88348448e-01, ...,\n",
       "          -7.98272416e-02,  1.88662422e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 1.10981572e+00,  1.31629944e+00, -5.03019989e-01, ...,\n",
       "          -7.42551029e-01,  4.08558893e+00,  6.49023414e-01],\n",
       "         [ 1.92885733e+00,  1.29066062e+00, -3.00003678e-01, ...,\n",
       "           4.80882265e-02,  3.80458236e+00,  6.49829566e-01],\n",
       "         [ 6.57990813e-01,  1.23635864e+00, -1.57995045e-01, ...,\n",
       "           7.66928554e-01,  3.30362821e+00,  6.50432110e-01]],\n",
       "\n",
       "        [[ 6.05037510e-01,  1.21011436e+00, -9.30229366e-01, ...,\n",
       "          -5.77063188e-02,  2.31112719e+00, -1.58825493e+00],\n",
       "         [ 7.09978878e-01,  1.22356522e+00, -9.35228586e-01, ...,\n",
       "          -6.24132082e-02,  1.95982623e+00, -1.58825493e+00],\n",
       "         [ 5.32128572e-01,  1.17079544e+00, -7.62960553e-01, ...,\n",
       "           1.38557954e-02,  1.87003386e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [-1.44225025e+00,  1.24635601e+00, -3.46093565e-01, ...,\n",
       "           4.80715334e-02,  3.43344188e+00,  6.50926471e-01],\n",
       "         [-2.00763893e+00,  1.39377594e+00, -2.15994611e-01, ...,\n",
       "           1.99150100e-01,  3.84751177e+00,  6.51695549e-01],\n",
       "         [-1.91858828e+00,  1.36851954e+00,  8.25484395e-02, ...,\n",
       "           2.94540852e-01,  3.01680684e+00,  6.51708663e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.53321490e-01,  2.01737195e-01,  3.86682123e-01, ...,\n",
       "          -1.13590217e+00,  4.48754251e-01, -1.58825493e+00],\n",
       "         [ 2.17327952e-01,  8.75083953e-02,  3.17397386e-01, ...,\n",
       "          -1.04671943e+00,  4.33361709e-01, -1.58825493e+00],\n",
       "         [-4.65456128e-01, -5.05421571e-02,  3.03013653e-01, ...,\n",
       "          -1.51794815e+00, -1.55332103e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 1.62869418e+00, -1.25595546e+00,  1.02546072e+00, ...,\n",
       "           2.82233238e-01, -5.76755464e-01,  6.17188990e-01],\n",
       "         [ 1.27226186e+00, -1.36894953e+00,  9.89893317e-01, ...,\n",
       "           6.31981969e-01, -6.27040088e-01,  6.19709194e-01],\n",
       "         [ 1.27646124e+00, -1.26488411e+00,  8.70921671e-01, ...,\n",
       "           5.67481220e-01, -6.17291749e-01,  6.16409183e-01]],\n",
       "\n",
       "        [[-9.58869874e-01, -2.74059534e-01,  1.60032615e-01, ...,\n",
       "          -1.01080537e+00, -4.79780942e-01, -1.58825493e+00],\n",
       "         [ 1.18287444e+00, -3.55226994e-01,  2.10085377e-01, ...,\n",
       "          -1.23842418e+00, -1.99117079e-01, -1.58825493e+00],\n",
       "         [ 8.09058964e-01, -6.79641485e-01,  1.93556964e-01, ...,\n",
       "          -6.50382698e-01, -6.52181268e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [-6.18299007e-01, -1.60577607e+00,  8.84484887e-01, ...,\n",
       "           3.39385688e-01, -6.26184046e-01,  6.14703715e-01],\n",
       "         [-7.95711517e-01, -1.75256777e+00,  1.06086159e+00, ...,\n",
       "           4.44614828e-01, -6.19514704e-01,  6.15650415e-01],\n",
       "         [-1.19026887e+00, -1.69244337e+00,  1.07318056e+00, ...,\n",
       "           3.73178929e-01, -5.46482980e-01,  6.12309217e-01]],\n",
       "\n",
       "        [[ 8.13234985e-01, -8.21421266e-01, -6.88542277e-02, ...,\n",
       "          -6.17111363e-02, -1.35957217e+00, -1.58825493e+00],\n",
       "         [ 7.59836957e-02, -8.10563147e-01, -6.79996051e-03, ...,\n",
       "          -4.31058347e-01, -1.17194951e+00, -1.58825493e+00],\n",
       "         [-3.46406668e-01, -9.44908857e-01, -1.37259131e-02, ...,\n",
       "          -4.86109793e-01, -1.01528347e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 1.28998160e-02, -1.62523031e+00,  6.93312585e-01, ...,\n",
       "           1.70050174e-01, -2.89421678e-01,  6.10966504e-01],\n",
       "         [ 7.57158458e-01, -1.71645272e+00,  7.47041821e-01, ...,\n",
       "           1.49980923e-02, -3.14392269e-01,  6.09679878e-01],\n",
       "         [ 9.47278023e-01, -1.64428234e+00,  7.88925171e-01, ...,\n",
       "          -5.17204590e-02, -3.17813247e-01,  6.07370257e-01]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 3.31183702e-01,  6.99372530e-01, -1.16651499e+00, ...,\n",
       "          -7.93060303e-01,  1.55875087e+00, -1.58825493e+00],\n",
       "         [ 3.10555756e-01,  6.72960281e-01, -1.25468791e+00, ...,\n",
       "          -4.71270621e-01,  1.55005920e+00, -1.58825493e+00],\n",
       "         [ 2.31167465e-01,  7.79531002e-01, -1.30074942e+00, ...,\n",
       "          -5.05822957e-01,  1.86468709e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 9.77807462e-01,  3.19439054e-01, -8.74890268e-01, ...,\n",
       "          -9.09898579e-01,  6.62766874e-01,  6.53237939e-01],\n",
       "         [ 8.37934375e-01,  5.06113291e-01, -8.08067262e-01, ...,\n",
       "          -3.70272726e-01,  7.44846642e-01,  6.52005553e-01],\n",
       "         [ 5.04029632e-01,  5.97306609e-01, -7.95150578e-01, ...,\n",
       "          -2.13459089e-01,  9.25477922e-01,  6.49879992e-01]],\n",
       "\n",
       "        [[ 7.71210074e-01,  7.60127544e-01, -1.32369232e+00, ...,\n",
       "          -7.57373929e-01,  2.36908317e+00, -1.58825493e+00],\n",
       "         [ 4.77306664e-01,  7.27714300e-01, -1.30835021e+00, ...,\n",
       "          -5.95850468e-01,  2.15117145e+00, -1.58825493e+00],\n",
       "         [ 3.68685275e-01,  7.05031395e-01, -1.31360912e+00, ...,\n",
       "          -2.61020690e-01,  2.48538423e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 5.90505838e-01,  8.48873079e-01, -8.03113699e-01, ...,\n",
       "          -3.86487991e-01,  2.42958856e+00,  6.53157055e-01],\n",
       "         [ 4.46363539e-01,  9.62325215e-01, -7.10020483e-01, ...,\n",
       "           2.51784950e-01,  2.60295033e+00,  6.51726186e-01],\n",
       "         [-1.17435470e-01,  9.75375414e-01, -6.84117854e-01, ...,\n",
       "           2.90392846e-01,  2.61942291e+00,  6.50660276e-01]],\n",
       "\n",
       "        [[ 7.84630775e-01,  9.44345713e-01, -1.43909216e+00, ...,\n",
       "          -8.47352564e-01,  1.35936856e+00, -1.58825493e+00],\n",
       "         [ 8.79322112e-01,  7.67707825e-01, -1.40553021e+00, ...,\n",
       "          -6.79550469e-01,  1.73011994e+00, -1.58825493e+00],\n",
       "         [ 6.44104242e-01,  7.47064590e-01, -1.34810293e+00, ...,\n",
       "          -4.59277987e-01,  2.13960624e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 5.50238416e-02,  1.03221655e+00, -7.22962141e-01, ...,\n",
       "          -1.95370883e-01,  2.76435781e+00,  6.47889435e-01],\n",
       "         [-4.23468977e-01,  1.07683229e+00, -8.34803045e-01, ...,\n",
       "           2.58397251e-01,  1.74838257e+00,  6.47688448e-01],\n",
       "         [-1.03477573e+00,  9.46723700e-01, -9.91056621e-01, ...,\n",
       "           4.80095357e-01,  1.37411904e+00,  6.48108959e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 7.04621732e-01,  1.30435050e+00,  2.04490125e-01, ...,\n",
       "          -8.81684780e-01,  1.19021523e+00, -1.58825493e+00],\n",
       "         [ 1.16173375e+00,  1.32630873e+00,  1.95654020e-01, ...,\n",
       "          -8.72977495e-01,  4.02110815e-01, -1.58825493e+00],\n",
       "         [ 1.18237782e+00,  1.07846403e+00,  1.27302110e-01, ...,\n",
       "          -5.05705059e-01,  9.47857276e-02, -1.58825493e+00],\n",
       "         ...,\n",
       "         [-3.74078840e-01, -6.44643545e-01,  4.44641054e-01, ...,\n",
       "          -1.28503248e-01, -3.83399367e-01,  6.16619289e-01],\n",
       "         [-3.40110511e-01, -3.50518256e-01,  6.37233496e-01, ...,\n",
       "          -2.39075303e-01, -4.99216437e-01,  6.13325715e-01],\n",
       "         [-6.48568124e-02,  5.58904529e-01,  8.08848560e-01, ...,\n",
       "          -3.36119324e-01, -4.79481429e-01,  6.11610293e-01]],\n",
       "\n",
       "        [[-3.03707451e-01,  1.15502071e+00,  7.29626775e-01, ...,\n",
       "          -8.58255446e-01,  6.62481844e-01, -1.58825493e+00],\n",
       "         [ 1.63547933e+00,  1.24906766e+00,  6.63279772e-01, ...,\n",
       "          -8.21003377e-01,  6.66854739e-01, -1.58825493e+00],\n",
       "         [ 4.85953152e-01,  1.24664211e+00,  5.31630516e-01, ...,\n",
       "          -4.83832121e-01,  6.25439763e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 4.32462931e-01, -9.49659467e-01,  2.76976645e-01, ...,\n",
       "           7.45602231e-03, -5.10567665e-01,  6.09726608e-01],\n",
       "         [ 1.29681319e-01, -7.97358513e-01,  2.78709769e-01, ...,\n",
       "           2.96754800e-02, -5.14276862e-01,  6.08455479e-01],\n",
       "         [-1.84395209e-01, -6.29251778e-01,  4.45331037e-01, ...,\n",
       "          -1.20020255e-01, -5.10157585e-01,  6.04196370e-01]],\n",
       "\n",
       "        [[-1.09069729e+00,  3.55704278e-01,  1.21074426e+00, ...,\n",
       "           4.43533063e-01, -1.13005269e+00, -1.58825493e+00],\n",
       "         [-1.14703739e+00,  7.49574244e-01,  1.12733674e+00, ...,\n",
       "          -9.21677947e-01, -5.38043380e-01, -1.58825493e+00],\n",
       "         [-3.51022512e-01,  1.03610492e+00,  1.00901353e+00, ...,\n",
       "          -7.00711846e-01,  1.58163562e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 8.99698257e-01, -1.18382442e+00,  8.64404589e-02, ...,\n",
       "           6.78861067e-02, -2.04366669e-01,  5.97914994e-01],\n",
       "         [ 2.11253241e-01, -8.20660591e-01, -1.10832155e-02, ...,\n",
       "           3.24886711e-03, -3.70316207e-01,  5.96682489e-01],\n",
       "         [ 7.21319020e-01, -6.45090461e-01, -1.16339587e-02, ...,\n",
       "          -1.76981315e-01, -3.85990083e-01,  5.96086562e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 4.25702810e-01,  9.83912587e-01, -1.01000905e+00, ...,\n",
       "          -5.83898306e-01,  4.92110014e-01, -1.58825493e+00],\n",
       "         [ 2.75297135e-01,  9.03731048e-01, -1.05955064e+00, ...,\n",
       "          -3.53461593e-01,  5.55158973e-01, -1.58825493e+00],\n",
       "         [ 1.34693995e-01,  1.11934280e+00, -1.18015695e+00, ...,\n",
       "          -4.45082963e-01,  8.08353186e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [-1.70076162e-01,  1.07184875e+00, -9.19201136e-01, ...,\n",
       "           1.58828914e-01,  9.98613298e-01,  6.52594328e-01],\n",
       "         [ 3.14340331e-02,  1.12068737e+00, -8.97174835e-01, ...,\n",
       "          -5.43377280e-01,  1.02084172e+00,  6.53509617e-01],\n",
       "         [ 6.02089763e-01,  1.18700469e+00, -8.03412199e-01, ...,\n",
       "          -6.48584425e-01,  1.26572609e+00,  6.52934790e-01]],\n",
       "\n",
       "        [[ 7.62671769e-01,  1.05523717e+00, -1.14048314e+00, ...,\n",
       "          -3.95409852e-01,  7.17140555e-01, -1.58825493e+00],\n",
       "         [ 5.71628273e-01,  1.13300359e+00, -1.27096140e+00, ...,\n",
       "          -1.25950262e-01,  1.04208362e+00, -1.58825493e+00],\n",
       "         [ 5.83906412e-01,  1.21751595e+00, -1.34589601e+00, ...,\n",
       "          -3.27240646e-01,  1.75453615e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [-1.68610573e+00,  1.06395423e+00, -7.49476314e-01, ...,\n",
       "           2.31831193e-01,  1.09659517e+00,  6.50304079e-01],\n",
       "         [-5.87778032e-01,  1.11656880e+00, -7.68388152e-01, ...,\n",
       "          -7.58177996e-01,  6.93119586e-01,  6.50374115e-01],\n",
       "         [ 3.66270155e-01,  1.19776952e+00, -7.23757863e-01, ...,\n",
       "          -5.75930774e-01,  1.33897138e+00,  6.51645541e-01]],\n",
       "\n",
       "        [[ 7.38707483e-01,  1.04153764e+00, -1.17158818e+00, ...,\n",
       "          -1.89043075e-01,  1.73303437e+00, -1.58825493e+00],\n",
       "         [ 3.09191287e-01,  9.91670787e-01, -1.26097965e+00, ...,\n",
       "          -3.40444557e-02,  1.73031771e+00, -1.58825493e+00],\n",
       "         [ 1.12827413e-01,  1.12502885e+00, -1.34106827e+00, ...,\n",
       "          -2.80460149e-01,  2.04784369e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [-2.28600597e+00,  1.15379834e+00, -6.43378615e-01, ...,\n",
       "          -2.55139798e-01,  8.97907555e-01,  6.47785008e-01],\n",
       "         [-1.26843429e+00,  1.23618174e+00, -6.23730958e-01, ...,\n",
       "          -7.73343742e-01,  1.50540745e+00,  6.48231983e-01],\n",
       "         [-6.82995260e-01,  1.21087837e+00, -6.74233973e-01, ...,\n",
       "          -5.04117489e-01,  1.66911793e+00,  6.49851739e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-6.35834932e-01, -2.21130341e-01, -1.42694280e-01, ...,\n",
       "           1.77831262e-01, -1.20826805e+00, -1.58825493e+00],\n",
       "         [ 2.77052879e-01,  1.68766677e-01, -5.40834144e-02, ...,\n",
       "          -3.51555228e-01, -7.54083812e-01, -1.58825493e+00],\n",
       "         [ 8.41409445e-01,  1.42587170e-01, -1.10238813e-01, ...,\n",
       "          -6.90128863e-01, -5.16613685e-02, -1.58825493e+00],\n",
       "         ...,\n",
       "         [-1.22243755e-01, -1.05568683e+00,  2.13122189e-01, ...,\n",
       "          -2.80667841e-01, -7.51280129e-01,  6.20389104e-01],\n",
       "         [-5.49827278e-01, -9.15053248e-01,  3.88866186e-01, ...,\n",
       "          -5.40790915e-01, -6.75516486e-01,  6.19882345e-01],\n",
       "         [ 1.80476770e-01, -1.08149576e+00,  5.51472306e-01, ...,\n",
       "          -2.84569144e-01, -7.24487722e-01,  6.18412554e-01]],\n",
       "\n",
       "        [[ 1.07848585e+00, -6.74187422e-01,  1.70573860e-01, ...,\n",
       "           1.33997965e+00, -1.19934237e+00, -1.58825493e+00],\n",
       "         [-1.28528726e+00, -6.50111735e-01,  1.76565424e-01, ...,\n",
       "           5.26856840e-01, -1.08383334e+00, -1.58825493e+00],\n",
       "         [ 2.11733267e-01, -1.53008312e-01,  2.24308372e-01, ...,\n",
       "          -6.49135411e-01, -6.55530810e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [-2.91930497e-01, -1.42259908e+00,  3.12111527e-01, ...,\n",
       "          -5.62212467e-01, -5.41835010e-01,  6.12980783e-01],\n",
       "         [ 4.50360715e-01, -1.15018904e+00,  3.78146350e-01, ...,\n",
       "          -6.81206346e-01, -4.54804003e-01,  6.10433280e-01],\n",
       "         [ 1.29859829e+00, -9.61553097e-01,  4.79998142e-01, ...,\n",
       "          -4.69980597e-01, -4.09091562e-01,  6.12480164e-01]],\n",
       "\n",
       "        [[ 7.10876212e-02, -1.03721440e+00,  8.03565085e-01, ...,\n",
       "           1.29764903e+00, -9.97400582e-01, -1.58825493e+00],\n",
       "         [-1.42838287e+00, -6.50399983e-01,  6.36915922e-01, ...,\n",
       "           8.14515948e-01, -8.42697620e-01, -1.58825493e+00],\n",
       "         [-2.25822544e+00, -4.92104650e-01,  5.89838386e-01, ...,\n",
       "          -1.14820383e-01, -6.08133137e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 1.08249450e+00, -7.30253935e-01,  5.26821256e-01, ...,\n",
       "          -7.07721710e-01, -2.00509250e-01,  6.07220650e-01],\n",
       "         [ 2.62458414e-01, -2.69809574e-01,  5.35285890e-01, ...,\n",
       "          -4.48039740e-01, -2.47394294e-01,  6.02649510e-01],\n",
       "         [-9.27536905e-01, -5.35632312e-01,  5.91276705e-01, ...,\n",
       "          -1.28539264e-01, -3.34419698e-01,  6.02934122e-01]]],\n",
       "\n",
       "\n",
       "       [[[-1.36141762e-01,  2.85867125e-01, -8.59666348e-01, ...,\n",
       "           1.97742343e-01,  3.86104941e-01, -1.58825493e+00],\n",
       "         [ 1.01572432e-01,  5.13291538e-01, -8.27907860e-01, ...,\n",
       "           2.13830635e-01,  5.42351902e-01, -1.58825493e+00],\n",
       "         [ 2.06479475e-01,  8.05045426e-01, -6.45957530e-01, ...,\n",
       "           4.25498456e-01,  9.28238571e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 7.86849618e-01,  9.74244058e-01, -1.09547627e+00, ...,\n",
       "          -3.23991239e-01,  1.25259459e+00,  6.50487840e-01],\n",
       "         [ 5.52813888e-01,  1.08413517e+00, -9.75924313e-01, ...,\n",
       "          -2.02672109e-01,  2.09548283e+00,  6.51307702e-01],\n",
       "         [ 1.21425204e-01,  1.16297603e+00, -8.46582890e-01, ...,\n",
       "          -2.25742772e-01,  2.18936896e+00,  6.51800454e-01]],\n",
       "\n",
       "        [[-1.19463526e-01,  5.38709402e-01, -8.22926939e-01, ...,\n",
       "           2.34253526e-01,  8.11333776e-01, -1.58825493e+00],\n",
       "         [ 1.76989902e-02,  6.47151828e-01, -8.00944984e-01, ...,\n",
       "           3.14289153e-01,  7.98300624e-01, -1.58825493e+00],\n",
       "         [-1.98994160e-01,  7.19655454e-01, -6.78736746e-01, ...,\n",
       "           4.79699492e-01,  8.67163956e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [-4.22874779e-01,  8.66985500e-01, -1.11907685e+00, ...,\n",
       "          -5.09759597e-02,  6.92045808e-01,  6.48671269e-01],\n",
       "         [-7.71627724e-01,  8.94198239e-01, -9.96479869e-01, ...,\n",
       "           5.68070933e-02,  1.01462376e+00,  6.49965823e-01],\n",
       "         [-1.00655162e+00,  1.09798956e+00, -9.28610981e-01, ...,\n",
       "          -2.53854729e-02,  9.92916822e-01,  6.49857581e-01]],\n",
       "\n",
       "        [[ 2.50452280e-01,  5.35625637e-01, -8.28130662e-01, ...,\n",
       "           1.80209816e-01,  1.21119452e+00, -1.58825493e+00],\n",
       "         [-2.04066455e-01,  5.60768723e-01, -7.36774266e-01, ...,\n",
       "           1.42398849e-01,  1.14024699e+00, -1.58825493e+00],\n",
       "         [-2.83527911e-01,  6.45477057e-01, -6.60888612e-01, ...,\n",
       "           2.73741633e-01,  1.17255926e+00, -1.58825493e+00],\n",
       "         ...,\n",
       "         [-4.88157034e-01,  5.64926684e-01, -1.05737293e+00, ...,\n",
       "          -3.34825248e-01,  5.31591736e-02,  6.47374153e-01],\n",
       "         [-3.82722437e-01,  7.44871676e-01, -9.80832160e-01, ...,\n",
       "          -2.02208608e-01,  3.39479983e-01,  6.48217201e-01],\n",
       "         [-6.09542787e-01,  1.02091408e+00, -9.28605974e-01, ...,\n",
       "          -2.03098327e-01,  4.56118077e-01,  6.48987412e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-8.17812204e-01,  5.64211428e-01,  5.91784239e-01, ...,\n",
       "          -6.76685691e-01, -2.71620095e-01, -1.58825493e+00],\n",
       "         [-4.58343849e-02,  8.07738960e-01,  6.95686817e-01, ...,\n",
       "          -9.47667658e-01, -2.12662131e-01, -1.58825493e+00],\n",
       "         [ 5.52975416e-01,  9.09121394e-01,  7.49558449e-01, ...,\n",
       "          -6.75555170e-01, -4.96627465e-02, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 2.52286881e-01, -1.54029214e+00,  1.16276868e-01, ...,\n",
       "           2.68222779e-01, -8.42117369e-01,  6.11636281e-01],\n",
       "         [ 1.46392226e-01, -1.51878953e+00,  2.82720536e-01, ...,\n",
       "           2.94035345e-01, -8.22567284e-01,  6.09703064e-01],\n",
       "         [ 8.28833729e-02, -1.50055373e+00,  4.16955322e-01, ...,\n",
       "           2.79258639e-01, -8.06774437e-01,  6.08221710e-01]],\n",
       "\n",
       "        [[-2.27172628e-01, -5.99763930e-01,  8.03648353e-01, ...,\n",
       "          -6.00478888e-01, -5.60899496e-01, -1.58825493e+00],\n",
       "         [ 3.08226019e-01,  2.11592048e-01,  8.71343851e-01, ...,\n",
       "          -8.92387033e-01, -3.02418947e-01, -1.58825493e+00],\n",
       "         [ 1.65760681e-01,  4.95082051e-01,  9.43731725e-01, ...,\n",
       "          -6.80251122e-01, -2.03786477e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 5.60378969e-01, -1.46571660e+00, -1.64334029e-01, ...,\n",
       "           1.97018813e-02, -8.74857843e-01,  6.05948508e-01],\n",
       "         [ 4.33263153e-01, -1.48981607e+00, -3.17736045e-02, ...,\n",
       "           1.99501887e-01, -8.39963377e-01,  6.04894102e-01],\n",
       "         [ 5.46334565e-01, -1.56257915e+00,  6.73143938e-02, ...,\n",
       "           3.20704043e-01, -8.11595619e-01,  5.99722981e-01]],\n",
       "\n",
       "        [[-1.10262275e+00, -6.73059285e-01,  9.07198727e-01, ...,\n",
       "          -8.48897636e-01, -8.21372092e-01, -1.58825493e+00],\n",
       "         [-6.73873842e-01,  2.09894791e-01,  8.37129712e-01, ...,\n",
       "          -2.48723775e-01, -4.92747515e-01, -1.58825493e+00],\n",
       "         [-7.71184638e-03,  2.51126587e-01,  6.74704552e-01, ...,\n",
       "          -2.39660870e-02, -4.06228364e-01, -1.58825493e+00],\n",
       "         ...,\n",
       "         [ 8.71753216e-01, -1.22870767e+00, -2.70695657e-01, ...,\n",
       "          -7.13081881e-02, -7.51572371e-01,  5.95489502e-01],\n",
       "         [ 7.91313171e-01, -1.32530117e+00, -2.77789176e-01, ...,\n",
       "           1.50090680e-01, -7.40362465e-01,  5.94540715e-01],\n",
       "         [ 9.94059145e-01, -1.50444853e+00, -2.42994383e-01, ...,\n",
       "           3.23909134e-01, -7.31321573e-01,  5.91574311e-01]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t_smote = X_training_sm.reshape(22486,13, 29, 8)\n",
    "x_t_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b15e113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 10:05:16.692374: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "##### Step 1 - Specify the structure of a Neural Network\n",
    "#--- Define a Model\n",
    "model = Sequential(name=\"DCN-Model\") # Model\n",
    "\n",
    "\n",
    "#--- Input Layer \n",
    "# Specify input shape [rows, columns, channels]\n",
    "model.add(Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3]), name='Input-Layer')) # Input Layer - need to speicfy the shape of inputs\n",
    "\n",
    "\n",
    "#--- First Set of Convolution, Max Pooling and Droput Layers (all parameters shown)\n",
    "model.add(Conv2D(filters=16, # Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "                 kernel_size=(3,3), # An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "                 strides=(1,1), # Default=(1,1), An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n",
    "                 padding='valid', # Default='valid', \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input. When padding=\"same\" and strides=1, the output has the same size as the input.\n",
    "                 data_format=None, # Default=None, A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch_size, height, width, channels) while channels_first corresponds to inputs with shape (batch_size, channels,height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last.\n",
    "                 dilation_rate=(1, 1), # Default=(1, 1), an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n",
    "                 groups=1, # Default=1, A positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with filters / groups filters. The output is the concatenation of all the groups results along the channel axis. Input channels and filters must both be divisible by groups.\n",
    "                 activation='relu', # Default=None, Activation function to use. If you don't specify anything, no activation is applied (see keras.activations).\n",
    "                 use_bias=True, # Default=True. \n",
    "                 kernel_initializer='glorot_uniform', # Default='glorot_uniform', Initializer for the kernel weights matrix (see keras.initializers).\n",
    "                 bias_initializer='zeros', # Default='zeros', Initializer for the bias vector (see keras.initializers).\n",
    "                 kernel_regularizer=None, # Default=None, Regularizer function applied to the kernel weights matrix (see keras.regularizers).\n",
    "                 bias_regularizer=None, # Default=None, Regularizer function applied to the bias vector (see keras.regularizers).\n",
    "                 activity_regularizer=None, # Default=None, Regularizer function applied to the output of the layer (its \"activation\") (see keras.regularizers).\n",
    "                 kernel_constraint=None, # Default=None, Constraint function applied to the kernel matrix (see keras.constraints).\n",
    "                 bias_constraint=None, # Default=None, Constraint function applied to the bias vector (see keras.constraints).\n",
    "                 name='2D-Convolutional-Layer-1')\n",
    "         ) # Convolutional Layer, relu activation used\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2), # Default=(2,2), integer or tuple of 2 integers, window size over which to take the maximum. (2, 2) will take the max value over a 2x2 pooling window. If only one integer is specified, the same window length will be used for both dimensions.\n",
    "                    strides=(2,2), # Default=None, Integer, tuple of 2 integers, or None. Strides values. Specifies how far the pooling window moves for each pooling step. If None, it will default to pool_size.\n",
    "                    padding='valid', # Default='valid', One of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n",
    "                    data_format=None, # Default=None, A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). \n",
    "                    name='2D-MaxPool-Layer-1')\n",
    "         ) # Max Pooling Layer,\n",
    "\n",
    "model.add(Dropout(0.2, name='Dropout-Layer-1')) # Dropout Layer\n",
    "\n",
    "\n",
    "#--- Second Set of Convolution, Max Pooling and Droput Layers \n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', name='2D-Convolutional-Layer-2')) # Convolutional Layer\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='valid', name='2D-MaxPool-Layer-2')) # Second Max Pooling Layer,\n",
    "model.add(Dropout(0.2, name='Dropout-Layer-2')) # Dropout Layer\n",
    "\n",
    "\n",
    "#--- Third Set of Convolution, Max Pooling and Droput Layers\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', name='2D-Convolutional-Layer-3')) # Convolutional Layer\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same', name='2D-MaxPool-Layer-3')) # Second Max Pooling Layer,\n",
    "model.add(Dropout(0.2, name='Dropout-Layer-3')) # Dropout Layer\n",
    "\n",
    "\n",
    "#--- Feed-Forward Densely Connected Layer and Output Layer (note, flattening is required to convert from 2D to 1D shape)\n",
    "model.add(Flatten(name='Flatten-Layer')) # Flatten the shape so we can feed it into a regular densely connected layer\n",
    "model.add(Dense(16, activation='relu', name='Hidden-Layer-1', kernel_initializer='HeNormal')) # Hidden Layer, relu(x) = max(x, 0)\n",
    "model.add(Dense(1, activation='softmax', name='Output-Layer')) # Output Layer, softmax(x) = exp(x) / tf.reduce_sum(exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27bcd6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 0.0426 - Accuracy: 0.0071 - val_loss: 0.0413 - val_Accuracy: 0.0066\n",
      "Epoch 2/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0242 - Accuracy: 0.0071 - val_loss: 0.0457 - val_Accuracy: 0.0066\n",
      "Epoch 3/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0210 - Accuracy: 0.0071 - val_loss: 0.0411 - val_Accuracy: 0.0066\n",
      "Epoch 4/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0197 - Accuracy: 0.0071 - val_loss: 0.0463 - val_Accuracy: 0.0066\n",
      "Epoch 5/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0169 - Accuracy: 0.0071 - val_loss: 0.0457 - val_Accuracy: 0.0066\n",
      "Epoch 6/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0172 - Accuracy: 0.0071 - val_loss: 0.0629 - val_Accuracy: 0.0066\n",
      "Epoch 7/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0156 - Accuracy: 0.0071 - val_loss: 0.0601 - val_Accuracy: 0.0066\n",
      "Epoch 8/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0142 - Accuracy: 0.0071 - val_loss: 0.0523 - val_Accuracy: 0.0066\n",
      "Epoch 9/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0131 - Accuracy: 0.0071 - val_loss: 0.0489 - val_Accuracy: 0.0066\n",
      "Epoch 10/20\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 0.0113 - Accuracy: 0.0071 - val_loss: 0.0680 - val_Accuracy: 0.0066\n",
      "Epoch 11/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0117 - Accuracy: 0.0071 - val_loss: 0.0583 - val_Accuracy: 0.0066\n",
      "Epoch 12/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0107 - Accuracy: 0.0071 - val_loss: 0.0556 - val_Accuracy: 0.0066\n",
      "Epoch 13/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0104 - Accuracy: 0.0071 - val_loss: 0.0685 - val_Accuracy: 0.0066\n",
      "Epoch 14/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0100 - Accuracy: 0.0071 - val_loss: 0.0811 - val_Accuracy: 0.0066\n",
      "Epoch 15/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0079 - Accuracy: 0.0071 - val_loss: 0.0883 - val_Accuracy: 0.0066\n",
      "Epoch 16/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0092 - Accuracy: 0.0071 - val_loss: 0.0765 - val_Accuracy: 0.0066\n",
      "Epoch 17/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0089 - Accuracy: 0.0071 - val_loss: 0.0681 - val_Accuracy: 0.0066\n",
      "Epoch 18/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0064 - Accuracy: 0.0071 - val_loss: 0.0745 - val_Accuracy: 0.0066\n",
      "Epoch 19/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0094 - Accuracy: 0.0071 - val_loss: 0.0547 - val_Accuracy: 0.0066\n",
      "Epoch 20/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0085 - Accuracy: 0.0071 - val_loss: 0.0684 - val_Accuracy: 0.0066\n"
     ]
    }
   ],
   "source": [
    "##### Step 2 - Compile keras model\n",
    "model.compile(optimizer='adam', # default='rmsprop', an algorithm to be used in backpropagation\n",
    "              loss='binary_crossentropy', # Loss function to be optimized. A string (name of loss function), or a tf.keras.losses.Loss instance.\n",
    "              metrics=['Accuracy'], # List of metrics to be evaluated by the model during training and testing. Each of this can be a string (name of a built-in function), function or a tf.keras.metrics.Metric instance. \n",
    "              loss_weights=None, # default=None, Optional list or dictionary specifying scalar coefficients (Python floats) to weight the loss contributions of different model outputs.\n",
    "              weighted_metrics=None, # default=None, List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing.\n",
    "              run_eagerly=None, # Defaults to False. If True, this Model's logic will not be wrapped in a tf.function. Recommended to leave this as None unless your Model cannot be run inside a tf.function.\n",
    "              steps_per_execution=None # Defaults to 1. The number of batches to run during each tf.function call. Running multiple batches inside a single tf.function call can greatly improve performance on TPUs or small models with a large Python overhead.\n",
    "             )\n",
    "\n",
    "\n",
    "##### Step 3 - Fit keras model on the dataset\n",
    "history = model.fit(X_train, # input data\n",
    "                    y_train, # target data\n",
    "                    #batch_size=1, # Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "                    epochs=20, # default=1, Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided\n",
    "                    #verbose=0, # default='auto', ('auto', 0, 1, or 2). Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 'auto' defaults to 1 for most cases, but 2 when used with ParameterServerStrategy.\n",
    "                    callbacks=None, # default=None, list of callbacks to apply during training. See tf.keras.callbacks\n",
    "                    #validation_split=0.0, # default=0.0, Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. \n",
    "                    validation_data=(X_valid, y_validation), # default=None, Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "                    #shuffle=True, # default=True, Boolean (whether to shuffle the training data before each epoch) or str (for 'batch').\n",
    "                    #class_weight=None, # default=None, Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "                    #sample_weight=None, # default=None, Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only).\n",
    "                    #initial_epoch=0, # Integer, default=0, Epoch at which to start training (useful for resuming a previous training run).\n",
    "                    #steps_per_epoch=None, # Integer or None, default=None, Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. \n",
    "                    #validation_steps=None, # Only relevant if validation_data is provided and is a tf.data dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch.\n",
    "                    #validation_batch_size=None, # Integer or None, default=None, Number of samples per validation batch. If unspecified, will default to batch_size.\n",
    "                    #validation_freq=1, # default=1, Only relevant if validation data is provided. If an integer, specifies how many training epochs to run before a new validation run is performed, e.g. validation_freq=2 runs validation every 2 epochs.\n",
    "                    #max_queue_size=10, # default=10, Used for generator or keras.utils.Sequence input only. Maximum size for the generator queue. If unspecified, max_queue_size will default to 10.\n",
    "                    #workers=1, # default=1, Used for generator or keras.utils.Sequence input only. Maximum number of processes to spin up when using process-based threading. If unspecified, workers will default to 1.\n",
    "                    #use_multiprocessing=False, # default=False, Used for generator or keras.utils.Sequence input only. If True, use process-based threading. If unspecified, use_multiprocessing will default to False. \n",
    "                   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e34c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 1s 2ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "\n",
      "------------------------- Model Summary -------------------------\n",
      "Model: \"DCN-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " 2D-Convolutional-Layer-1 (C  (None, 11, 27, 16)       1168      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-1 (MaxPool  (None, 5, 13, 16)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-1 (Dropout)   (None, 5, 13, 16)         0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-2 (C  (None, 3, 11, 64)        9280      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-2 (MaxPool  (None, 1, 5, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-2 (Dropout)   (None, 1, 5, 64)          0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-3 (C  (None, 1, 5, 64)         36928     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-3 (MaxPool  (None, 1, 3, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-3 (Dropout)   (None, 1, 3, 64)          0         \n",
      "                                                                 \n",
      " Flatten-Layer (Flatten)     (None, 192)               0         \n",
      "                                                                 \n",
      " Hidden-Layer-1 (Dense)      (None, 16)                3088      \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,481\n",
      "Trainable params: 50,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "------------------ Evaluation on Training Data ------------------\n",
      "Final loss : 0.008513246662914753\n",
      "Final Accuracy : 0.007065265439450741\n",
      "Final val_loss : 0.06835295259952545\n",
      "Final val_Accuracy : 0.006571741309016943\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00     11243\n",
      "         1.0       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.99     11323\n",
      "   macro avg       0.50      0.50      0.50     11323\n",
      "weighted avg       0.99      0.99      0.99     11323\n",
      "\n",
      "\n",
      "-------------------- Evaluation on Test Data --------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      1416\n",
      "         1.0       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.99      1431\n",
      "   macro avg       0.49      0.50      0.50      1431\n",
      "weighted avg       0.98      0.99      0.98      1431\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "##### Step 4 - Use model to make predictions\n",
    "# Note, we need to pass model output through argmax to convert from probability to label\n",
    "# Also, we convert output from tensor to numpy array\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = np.array(tf.math.argmax(model.predict(X_train),axis=1))\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = np.array(tf.math.argmax(model.predict(X_test),axis=1))\n",
    "\n",
    "\n",
    "##### Step 5 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('------------------------- Model Summary -------------------------')\n",
    "model.summary() # print model summary\n",
    "print(\"\")\n",
    "    \n",
    "\n",
    "\n",
    "print('------------------ Evaluation on Training Data ------------------')\n",
    "# Print the last value in the evaluation metrics contained within history file\n",
    "for item in history.history:\n",
    "    print(\"Final\", item, \":\", history.history[item][-1])\n",
    "print(\"\")\n",
    "# Print classification report\n",
    "print(classification_report(y_train, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('-------------------- Evaluation on Test Data --------------------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7fcf084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels_tr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "205c4e9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 1s 2ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "\n",
      "-------------------- Model Summary --------------------\n",
      "Model: \"DCN-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " 2D-Convolutional-Layer-1 (C  (None, 11, 27, 16)       1168      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-1 (MaxPool  (None, 5, 13, 16)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-1 (Dropout)   (None, 5, 13, 16)         0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-2 (C  (None, 3, 11, 64)        9280      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-2 (MaxPool  (None, 1, 5, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-2 (Dropout)   (None, 1, 5, 64)          0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-3 (C  (None, 1, 5, 64)         36928     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-3 (MaxPool  (None, 1, 3, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-3 (Dropout)   (None, 1, 3, 64)          0         \n",
      "                                                                 \n",
      " Flatten-Layer (Flatten)     (None, 192)               0         \n",
      "                                                                 \n",
      " Hidden-Layer-1 (Dense)      (None, 16)                3088      \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,481\n",
      "Trainable params: 50,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "-------------------- Weights and Biases --------------------\n",
      "Layer:  2D-Convolutional-Layer-1\n",
      "Layer:  2D-MaxPool-Layer-1\n",
      "Layer:  Dropout-Layer-1\n",
      "Layer:  2D-Convolutional-Layer-2\n",
      "Layer:  2D-MaxPool-Layer-2\n",
      "Layer:  Dropout-Layer-2\n",
      "Layer:  2D-Convolutional-Layer-3\n",
      "Layer:  2D-MaxPool-Layer-3\n",
      "Layer:  Dropout-Layer-3\n",
      "Layer:  Flatten-Layer\n",
      "Layer:  Hidden-Layer-1\n",
      "Layer:  Output-Layer\n",
      "\n",
      "---------- Evaluation on Training Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     11243\n",
      "         1.0       0.01      1.00      0.01        80\n",
      "\n",
      "    accuracy                           0.01     11323\n",
      "   macro avg       0.00      0.50      0.01     11323\n",
      "weighted avg       0.00      0.01      0.00     11323\n",
      "\n",
      "\n",
      "---------- Evaluation on Test Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      1416\n",
      "         1.0       0.01      1.00      0.02        15\n",
      "\n",
      "    accuracy                           0.01      1431\n",
      "   macro avg       0.01      0.50      0.01      1431\n",
      "weighted avg       0.00      0.01      0.00      1431\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f82f80b1990>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Step 6 - Use model to make predictions\n",
    "modelz = model\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = (modelz.predict(X_train)> 0.5).astype(int)\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = (modelz.predict(X_test)> 0.5).astype(int)\n",
    "#> 0.01).astype(int)\n",
    "\n",
    "\n",
    "##### Step 7 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('-------------------- Model Summary --------------------')\n",
    "modelz.summary() # print model summary\n",
    "print(\"\")\n",
    "print('-------------------- Weights and Biases --------------------')\n",
    "for layer in modelz.layers:\n",
    "    print(\"Layer: \", layer.name) # print layer name\n",
    "    \n",
    "print(\"\")\n",
    "print('---------- Evaluation on Training Data ----------')\n",
    "print(classification_report(y_train, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('---------- Evaluation on Test Data ----------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te)).plot(colorbar=False,cmap=plt.cm.Blues)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te,normalize='true')).plot(colorbar=False,cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "702c88cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61f82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37f0eaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0031 - Accuracy: 0.0071 - val_loss: 0.0798 - val_Accuracy: 0.0066\n",
      "Epoch 2/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0035 - Accuracy: 0.0071 - val_loss: 0.0801 - val_Accuracy: 0.0066\n",
      "Epoch 3/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0026 - Accuracy: 0.0071 - val_loss: 0.0803 - val_Accuracy: 0.0066\n",
      "Epoch 4/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0041 - Accuracy: 0.0071 - val_loss: 0.0804 - val_Accuracy: 0.0066\n",
      "Epoch 5/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0035 - Accuracy: 0.0071 - val_loss: 0.0805 - val_Accuracy: 0.0066\n",
      "Epoch 6/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0035 - Accuracy: 0.0071 - val_loss: 0.0806 - val_Accuracy: 0.0066\n",
      "Epoch 7/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0041 - Accuracy: 0.0071 - val_loss: 0.0806 - val_Accuracy: 0.0066\n",
      "Epoch 8/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0031 - Accuracy: 0.0071 - val_loss: 0.0807 - val_Accuracy: 0.0066\n",
      "Epoch 9/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0034 - Accuracy: 0.0071 - val_loss: 0.0807 - val_Accuracy: 0.0066\n",
      "Epoch 10/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0043 - Accuracy: 0.0071 - val_loss: 0.0806 - val_Accuracy: 0.0066\n",
      "Epoch 11/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0031 - Accuracy: 0.0071 - val_loss: 0.0807 - val_Accuracy: 0.0066\n",
      "Epoch 12/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0028 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 13/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0035 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 14/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0042 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 15/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0030 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 16/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0040 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 17/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0038 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 18/20\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 0.0025 - Accuracy: 0.0071 - val_loss: 0.0808 - val_Accuracy: 0.0066\n",
      "Epoch 19/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0031 - Accuracy: 0.0071 - val_loss: 0.0809 - val_Accuracy: 0.0066\n",
      "Epoch 20/20\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 0.0044 - Accuracy: 0.0071 - val_loss: 0.0809 - val_Accuracy: 0.0066\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# lrate = initial_lrate * (1 / (1 + decay * iteration))\n",
    "opt = SGD(lr=0.001, momentum=0.9, decay=0.01)\n",
    "\n",
    "##### Step 2 - Compile keras model\n",
    "model.compile(optimizer=opt, # default='rmsprop', an algorithm to be used in backpropagation\n",
    "              loss='binary_crossentropy', # Loss function to be optimized. A string (name of loss function), or a tf.keras.losses.Loss instance.\n",
    "              metrics=['Accuracy'], # List of metrics to be evaluated by the model during training and testing. Each of this can be a string (name of a built-in function), function or a tf.keras.metrics.Metric instance. \n",
    "              loss_weights=None, # default=None, Optional list or dictionary specifying scalar coefficients (Python floats) to weight the loss contributions of different model outputs.\n",
    "              weighted_metrics=None, # default=None, List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing.\n",
    "              run_eagerly=None, # Defaults to False. If True, this Model's logic will not be wrapped in a tf.function. Recommended to leave this as None unless your Model cannot be run inside a tf.function.\n",
    "              steps_per_execution=None # Defaults to 1. The number of batches to run during each tf.function call. Running multiple batches inside a single tf.function call can greatly improve performance on TPUs or small models with a large Python overhead.\n",
    "             )\n",
    "\n",
    "\n",
    "##### Step 3 - Fit keras model on the dataset\n",
    "history = model.fit(X_train, # input data\n",
    "                    y_train, # target data\n",
    "                    #batch_size=1, # Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "                    epochs=20, # default=1, Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided\n",
    "                    #verbose=0, # default='auto', ('auto', 0, 1, or 2). Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 'auto' defaults to 1 for most cases, but 2 when used with ParameterServerStrategy.\n",
    "                    callbacks=None, # default=None, list of callbacks to apply during training. See tf.keras.callbacks\n",
    "                    #validation_split=0.0, # default=0.0, Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. \n",
    "                    validation_data=(X_valid, y_validation), # default=None, Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "                    #shuffle=True, # default=True, Boolean (whether to shuffle the training data before each epoch) or str (for 'batch').\n",
    "                    #class_weight=None, # default=None, Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "                    #sample_weight=None, # default=None, Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only).\n",
    "                    #initial_epoch=0, # Integer, default=0, Epoch at which to start training (useful for resuming a previous training run).\n",
    "                    #steps_per_epoch=None, # Integer or None, default=None, Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. \n",
    "                    #validation_steps=None, # Only relevant if validation_data is provided and is a tf.data dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch.\n",
    "                    #validation_batch_size=None, # Integer or None, default=None, Number of samples per validation batch. If unspecified, will default to batch_size.\n",
    "                    #validation_freq=1, # default=1, Only relevant if validation data is provided. If an integer, specifies how many training epochs to run before a new validation run is performed, e.g. validation_freq=2 runs validation every 2 epochs.\n",
    "                    #max_queue_size=10, # default=10, Used for generator or keras.utils.Sequence input only. Maximum size for the generator queue. If unspecified, max_queue_size will default to 10.\n",
    "                    #workers=1, # default=1, Used for generator or keras.utils.Sequence input only. Maximum number of processes to spin up when using process-based threading. If unspecified, workers will default to 1.\n",
    "                    #use_multiprocessing=False, # default=False, Used for generator or keras.utils.Sequence input only. If True, use process-based threading. If unspecified, use_multiprocessing will default to False. \n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "858b92b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 1s 2ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "\n",
      "-------------------- Model Summary --------------------\n",
      "Model: \"DCN-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " 2D-Convolutional-Layer-1 (C  (None, 11, 27, 16)       1168      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-1 (MaxPool  (None, 5, 13, 16)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-1 (Dropout)   (None, 5, 13, 16)         0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-2 (C  (None, 3, 11, 64)        9280      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-2 (MaxPool  (None, 1, 5, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-2 (Dropout)   (None, 1, 5, 64)          0         \n",
      "                                                                 \n",
      " 2D-Convolutional-Layer-3 (C  (None, 1, 5, 64)         36928     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " 2D-MaxPool-Layer-3 (MaxPool  (None, 1, 3, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " Dropout-Layer-3 (Dropout)   (None, 1, 3, 64)          0         \n",
      "                                                                 \n",
      " Flatten-Layer (Flatten)     (None, 192)               0         \n",
      "                                                                 \n",
      " Hidden-Layer-1 (Dense)      (None, 16)                3088      \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,481\n",
      "Trainable params: 50,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "-------------------- Weights and Biases --------------------\n",
      "Layer:  2D-Convolutional-Layer-1\n",
      "Layer:  2D-MaxPool-Layer-1\n",
      "Layer:  Dropout-Layer-1\n",
      "Layer:  2D-Convolutional-Layer-2\n",
      "Layer:  2D-MaxPool-Layer-2\n",
      "Layer:  Dropout-Layer-2\n",
      "Layer:  2D-Convolutional-Layer-3\n",
      "Layer:  2D-MaxPool-Layer-3\n",
      "Layer:  Dropout-Layer-3\n",
      "Layer:  Flatten-Layer\n",
      "Layer:  Hidden-Layer-1\n",
      "Layer:  Output-Layer\n",
      "\n",
      "---------- Evaluation on Training Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     11243\n",
      "         1.0       0.01      1.00      0.01        80\n",
      "\n",
      "    accuracy                           0.01     11323\n",
      "   macro avg       0.00      0.50      0.01     11323\n",
      "weighted avg       0.00      0.01      0.00     11323\n",
      "\n",
      "\n",
      "---------- Evaluation on Test Data ----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      1416\n",
      "         1.0       0.01      1.00      0.02        15\n",
      "\n",
      "    accuracy                           0.01      1431\n",
      "   macro avg       0.01      0.50      0.01      1431\n",
      "weighted avg       0.00      0.01      0.00      1431\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/3rfanian/opt/anaconda3/envs/SHAP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f835a1d7dc0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Step 6 - Use model to make predictions\n",
    "modelz = model\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = (modelz.predict(X_train)> 0.1).astype(int)\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = (modelz.predict(X_test)> 0.1).astype(int)\n",
    "#> 0.01).astype(int)\n",
    "\n",
    "\n",
    "##### Step 7 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('-------------------- Model Summary --------------------')\n",
    "modelz.summary() # print model summary\n",
    "print(\"\")\n",
    "print('-------------------- Weights and Biases --------------------')\n",
    "for layer in modelz.layers:\n",
    "    print(\"Layer: \", layer.name) # print layer name\n",
    "    \n",
    "print(\"\")\n",
    "print('---------- Evaluation on Training Data ----------')\n",
    "print(classification_report(y_train, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('---------- Evaluation on Test Data ----------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te)).plot(colorbar=False,cmap=plt.cm.Blues)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_labels_te,normalize='true')).plot(colorbar=False,cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1984527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelz.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b3494a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
